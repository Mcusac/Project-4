{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>engine string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Chevrolet Suburban</td>\n",
       "      <td>$17,000</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>60069</td>\n",
       "      <td>5.7L Vortec V8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Porsche 964 911</td>\n",
       "      <td>$225,000</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>84790</td>\n",
       "      <td>3.8-Liter Flat-Six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Toyota Pickup</td>\n",
       "      <td>$24,750</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>90027</td>\n",
       "      <td>3.4-Liter DOHC V6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Volkswagen Golf/Rabbit Cabriolet</td>\n",
       "      <td>$10,750</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>98208</td>\n",
       "      <td>1.8-Liter Inline-Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Toyota FJ Cruiser</td>\n",
       "      <td>$32,500</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>57108</td>\n",
       "      <td>4.0-Liter V6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year        make                             model final_price  \\\n",
       "0           1  1997   Chevrolet                Chevrolet Suburban     $17,000   \n",
       "1           2  1990     Porsche                   Porsche 964 911    $225,000   \n",
       "2           3  2003      Toyota                     Toyota Pickup     $24,750   \n",
       "3           5  1992  Volkswagen  Volkswagen Golf/Rabbit Cabriolet     $10,750   \n",
       "4           6  2008      Toyota                 Toyota FJ Cruiser     $32,500   \n",
       "\n",
       "   mileage  engine  zipcode          engine string  \n",
       "0    67000  5700.0    60069         5.7L Vortec V8  \n",
       "1     1000  3800.0    84790    3.8-Liter Flat-Six   \n",
       "2   116000  3400.0    90027      3.4-Liter DOHC V6  \n",
       "3   100000  1800.0    98208  1.8-Liter Inline-Four  \n",
       "4     9000  4000.0    57108           4.0-Liter V6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = \"data.sqlite\"\n",
    "\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "train_df = pd.read_sql(\"select * from new_table_name\", con=conn)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['final_price']=(train_df['final_price'].replace( '[\\$,)]','', regex=True )\n",
    "               .replace( '[(]','-',   regex=True ).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>1983</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>39962.0</td>\n",
       "      <td>24000</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>1997</td>\n",
       "      <td>Ford</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>75000</td>\n",
       "      <td>7300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>1972</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>2005</td>\n",
       "      <td>Ford</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>22000</td>\n",
       "      <td>3900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>1974</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>98000</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7105 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        make  final_price  mileage  engine\n",
       "0     1997   Chevrolet      17000.0    67000  5700.0\n",
       "1     1990     Porsche     225000.0     1000  3800.0\n",
       "2     2003      Toyota      24750.0   116000  3400.0\n",
       "3     1992  Volkswagen      10750.0   100000  1800.0\n",
       "4     2008      Toyota      32500.0     9000  4000.0\n",
       "...    ...         ...          ...      ...     ...\n",
       "7100  1983        Jeep      39962.0    24000  4200.0\n",
       "7101  1997        Ford      24900.0    75000  7300.0\n",
       "7102  1972       Honda       2400.0     5000   174.0\n",
       "7103  2005        Ford      17750.0    22000  3900.0\n",
       "7104  1974  Volkswagen       9900.0    98000  1600.0\n",
       "\n",
       "[7105 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(['model', 'engine string', 'Unnamed: 0', 'zipcode'], axis='columns')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year  make           final_price  mileage  engine  \n",
       "1999  BMW            29250.0      82000    3200.000    2\n",
       "2002  Ford           33500.0      14000    5400.000    2\n",
       "2003  Chevrolet      30000.0      7000     5700.000    2\n",
       "2008  BMW            31000.0      36000    4000.000    2\n",
       "2009  Mercedes-Benz  28750.0      33000    6200.000    2\n",
       "                                                      ..\n",
       "1984  Jeep           35000.0      137000   4200.000    1\n",
       "                     26000.0      139000   4200.000    1\n",
       "                     25000.0      70000    4200.000    1\n",
       "                     24250.0      42000    4981.648    1\n",
       "2022  Porsche        307307.0     25000    4000.000    1\n",
       "Length: 7100, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>make_AMC</th>\n",
       "      <th>make_Acura</th>\n",
       "      <th>make_Alfa Romeo</th>\n",
       "      <th>make_Alpine</th>\n",
       "      <th>make_Amphicar</th>\n",
       "      <th>make_Ariel</th>\n",
       "      <th>...</th>\n",
       "      <th>make_Saab</th>\n",
       "      <th>make_Shelby</th>\n",
       "      <th>make_Studebaker</th>\n",
       "      <th>make_Subaru</th>\n",
       "      <th>make_Sunbeam</th>\n",
       "      <th>make_Toyota</th>\n",
       "      <th>make_Triumph</th>\n",
       "      <th>make_Volkswagen</th>\n",
       "      <th>make_Volvo</th>\n",
       "      <th>make_Willys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  final_price  mileage  engine  make_AMC  make_Acura  make_Alfa Romeo  \\\n",
       "0  1997      17000.0    67000  5700.0         0           0                0   \n",
       "1  1990     225000.0     1000  3800.0         0           0                0   \n",
       "2  2003      24750.0   116000  3400.0         0           0                0   \n",
       "3  1992      10750.0   100000  1800.0         0           0                0   \n",
       "4  2008      32500.0     9000  4000.0         0           0                0   \n",
       "\n",
       "   make_Alpine  make_Amphicar  make_Ariel  ...  make_Saab  make_Shelby  \\\n",
       "0            0              0           0  ...          0            0   \n",
       "1            0              0           0  ...          0            0   \n",
       "2            0              0           0  ...          0            0   \n",
       "3            0              0           0  ...          0            0   \n",
       "4            0              0           0  ...          0            0   \n",
       "\n",
       "   make_Studebaker  make_Subaru  make_Sunbeam  make_Toyota  make_Triumph  \\\n",
       "0                0            0             0            0             0   \n",
       "1                0            0             0            0             0   \n",
       "2                0            0             0            1             0   \n",
       "3                0            0             0            0             0   \n",
       "4                0            0             0            1             0   \n",
       "\n",
       "   make_Volkswagen  make_Volvo  make_Willys  \n",
       "0                0           0            0  \n",
       "1                0           0            0  \n",
       "2                0           0            0  \n",
       "3                1           0            0  \n",
       "4                0           0            0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "train_df1 = pd.get_dummies(train_df)\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df1.drop(columns='final_price')\n",
    "train_y = train_df1['final_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.26766515342975683\n",
      "Model Score: -1.8699450895005813e+23\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(f'Model Score: {model.score(X_train_scaled, y_train)}')\n",
    "print(f'Model Score: {model.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_train_scaled)\n",
    "# Plot Residuals\n",
    "plt.scatter(predictions, predictions - y_train)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 71 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10028/999395656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_min_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_max_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Actual Min Value: {y_min_actual}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Predicted Min Value: {y_min_predicted}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Actual Max Value: {y_max_actual}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ProgramFiles\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ProgramFiles\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[0;32m    222\u001b[0m                                dense_output=True) + self.intercept_\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ProgramFiles\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ProgramFiles\\anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 71 is different from 1)"
     ]
    }
   ],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)\n",
    "print(f\"True output: {train_y[0]}\")\n",
    "print(f\"Predicted output: {predictions[0]}\")\n",
    "print(f\"Prediction Error: {predictions[0]-y_train[0]}\")\n",
    "\n",
    "x_min = X_train_scaled.min()\n",
    "x_max = X_train_scaled.max()\n",
    "y_min_actual = y_train.min()\n",
    "y_max_actual = y_train.max()\n",
    "\n",
    "y_min = 101.896225057 + (model.coef_ * x_min)\n",
    "y_max = 101.896225057 + (model.coef_ * x_max)\n",
    "print(f\"Actual Min Value: {y_min_actual}\")\n",
    "print(f\"Calculated Min Value: {y_min}\")\n",
    "print(f\"Actual Max Value: {y_max_actual}\")\n",
    "print(f\"Calculated Max Value: {y_max}\")\n",
    "\n",
    "y_min_predicted = model.predict([[x_min]])\n",
    "y_max_predicted = model.predict([[x_max]])\n",
    "print(f\"Actual Min Value: {y_min_actual}\")\n",
    "print(f\"Predicted Min Value: {y_min_predicted}\")\n",
    "print(f\"Actual Max Value: {y_max_actual}\")\n",
    "print(f\"Predicted Max Value: {y_max_predicted}\")\n",
    "\n",
    "plt.scatter(X, y, c='blue')\n",
    "plt.plot([x_min, x_max], [y_min, y_max], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.26804787330373536\n",
      "Test Score: 0.06990602541123325\n"
     ]
    }
   ],
   "source": [
    "reg = Lasso(max_iter=10000).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.2679359935686625\n",
      "Test Score: 0.07191953465417777\n"
     ]
    }
   ],
   "source": [
    "reg = Ridge(alpha=100).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.08950727765164945\n",
      "Test Score: 0.03896535884460828\n"
     ]
    }
   ],
   "source": [
    "reg = ElasticNet(alpha=10).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "    print(mean_absolute_error(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsRegressor\n",
      "Train score: 0.6052034645832656\n",
      "Test Score: 0.23028774481921122\n",
      "\n",
      "21344.75171637591\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9077175539438057\n",
      "Test Score: 0.42131359165946747\n",
      "\n",
      "18334.223974636225\n",
      "Model: ExtraTreesRegressor\n",
      "Train score: 0.9932828423680392\n",
      "Test Score: 0.44610491658436\n",
      "\n",
      "18082.87561151754\n",
      "Model: AdaBoostRegressor\n",
      "Train score: -3.6476076729915494\n",
      "Test Score: -2.553222051537058\n",
      "\n",
      "111645.55040308763\n",
      "Model: SVR\n",
      "Train score: -0.08710783142007417\n",
      "Test Score: -0.0732446822790187\n",
      "\n",
      "29266.79350581873\n"
     ]
    }
   ],
   "source": [
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 729)               52488     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 486)               354780    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 324)               157788    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 216)               70200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 217       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 635,473\n",
      "Trainable params: 635,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = tf.keras.models.Sequential()\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=729, activation=\"sigmoid\", input_dim=71))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=486, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=324, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=216, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1))\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5193209856.0000 - mae: 46290.5000\n",
      "Epoch 2/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5190952448.0000 - mae: 46266.1562\n",
      "Epoch 3/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5187587072.0000 - mae: 46229.9609\n",
      "Epoch 4/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5184314368.0000 - mae: 46194.2422\n",
      "Epoch 5/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5180999680.0000 - mae: 46158.8594\n",
      "Epoch 6/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5177766400.0000 - mae: 46123.5039\n",
      "Epoch 7/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5174479872.0000 - mae: 46088.2031\n",
      "Epoch 8/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5171207680.0000 - mae: 46052.7852\n",
      "Epoch 9/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5167950336.0000 - mae: 46017.5859\n",
      "Epoch 10/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5164712448.0000 - mae: 45982.1758\n",
      "Epoch 11/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5161428992.0000 - mae: 45946.8359\n",
      "Epoch 12/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5158167552.0000 - mae: 45911.5391\n",
      "Epoch 13/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5154934784.0000 - mae: 45876.1719\n",
      "Epoch 14/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5151682560.0000 - mae: 45840.7969\n",
      "Epoch 15/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5148462080.0000 - mae: 45805.4609\n",
      "Epoch 16/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5145221632.0000 - mae: 45770.1523\n",
      "Epoch 17/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5141975552.0000 - mae: 45734.7852\n",
      "Epoch 18/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5138710528.0000 - mae: 45699.4102\n",
      "Epoch 19/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5135490048.0000 - mae: 45664.0586\n",
      "Epoch 20/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5132268544.0000 - mae: 45628.9141\n",
      "Epoch 21/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5129025024.0000 - mae: 45593.5273\n",
      "Epoch 22/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5125814784.0000 - mae: 45558.2227\n",
      "Epoch 23/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5122584064.0000 - mae: 45522.9180\n",
      "Epoch 24/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5119364096.0000 - mae: 45487.6914\n",
      "Epoch 25/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5116169728.0000 - mae: 45452.3359\n",
      "Epoch 26/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 5112968704.0000 - mae: 45417.0469\n",
      "Epoch 27/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5109696000.0000 - mae: 45381.6133\n",
      "Epoch 28/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5106520576.0000 - mae: 45346.3086\n",
      "Epoch 29/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5103291392.0000 - mae: 45311.0469\n",
      "Epoch 30/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5100108288.0000 - mae: 45275.8125\n",
      "Epoch 31/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5096869376.0000 - mae: 45240.3906\n",
      "Epoch 32/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5093697024.0000 - mae: 45205.0508\n",
      "Epoch 33/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5090478080.0000 - mae: 45169.7070\n",
      "Epoch 34/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5087271936.0000 - mae: 45134.3555\n",
      "Epoch 35/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5084094976.0000 - mae: 45098.9531\n",
      "Epoch 36/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5080925696.0000 - mae: 45063.7344\n",
      "Epoch 37/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5077697024.0000 - mae: 45028.4883\n",
      "Epoch 38/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5074536960.0000 - mae: 44993.1250\n",
      "Epoch 39/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5071320064.0000 - mae: 44957.7812\n",
      "Epoch 40/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5068173312.0000 - mae: 44922.4727\n",
      "Epoch 41/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5064968192.0000 - mae: 44887.1797\n",
      "Epoch 42/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5061786624.0000 - mae: 44851.7461\n",
      "Epoch 43/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5058620416.0000 - mae: 44816.4688\n",
      "Epoch 44/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5055415296.0000 - mae: 44781.0234\n",
      "Epoch 45/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5052280832.0000 - mae: 44745.7578\n",
      "Epoch 46/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5049101312.0000 - mae: 44710.3828\n",
      "Epoch 47/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5045927424.0000 - mae: 44674.9844\n",
      "Epoch 48/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5042746880.0000 - mae: 44639.5000\n",
      "Epoch 49/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5039577088.0000 - mae: 44604.1719\n",
      "Epoch 50/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5036464128.0000 - mae: 44569.0117\n",
      "Epoch 51/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5033306624.0000 - mae: 44533.6914\n",
      "Epoch 52/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5030174208.0000 - mae: 44498.5273\n",
      "Epoch 53/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5026996224.0000 - mae: 44463.1367\n",
      "Epoch 54/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5023864832.0000 - mae: 44427.9141\n",
      "Epoch 55/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5020758016.0000 - mae: 44392.6680\n",
      "Epoch 56/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5017591296.0000 - mae: 44357.4453\n",
      "Epoch 57/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5014458368.0000 - mae: 44322.1250\n",
      "Epoch 58/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5011330048.0000 - mae: 44286.9141\n",
      "Epoch 59/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5008198656.0000 - mae: 44251.7852\n",
      "Epoch 60/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5005103616.0000 - mae: 44216.6914\n",
      "Epoch 61/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5001980928.0000 - mae: 44181.5664\n",
      "Epoch 62/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4998906880.0000 - mae: 44146.4805\n",
      "Epoch 63/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4995749888.0000 - mae: 44111.2539\n",
      "Epoch 64/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4992657920.0000 - mae: 44075.9609\n",
      "Epoch 65/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4989535232.0000 - mae: 44040.5664\n",
      "Epoch 66/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4986397184.0000 - mae: 44005.3398\n",
      "Epoch 67/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4983271424.0000 - mae: 43970.0312\n",
      "Epoch 68/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4980212736.0000 - mae: 43934.8750\n",
      "Epoch 69/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4977099264.0000 - mae: 43899.7070\n",
      "Epoch 70/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4973978112.0000 - mae: 43864.5273\n",
      "Epoch 71/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4970892800.0000 - mae: 43829.4453\n",
      "Epoch 72/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4967797248.0000 - mae: 43794.2344\n",
      "Epoch 73/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 4964705280.0000 - mae: 43758.9492\n",
      "Epoch 74/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4961620992.0000 - mae: 43723.8594\n",
      "Epoch 75/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4958542336.0000 - mae: 43688.6797\n",
      "Epoch 76/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4955428352.0000 - mae: 43653.4336\n",
      "Epoch 77/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4952382976.0000 - mae: 43618.3242\n",
      "Epoch 78/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4949272576.0000 - mae: 43583.0859\n",
      "Epoch 79/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4946203648.0000 - mae: 43547.8555\n",
      "Epoch 80/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4943136256.0000 - mae: 43512.6797\n",
      "Epoch 81/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4940045312.0000 - mae: 43477.5352\n",
      "Epoch 82/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4936996864.0000 - mae: 43442.4336\n",
      "Epoch 83/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4933931520.0000 - mae: 43407.3164\n",
      "Epoch 84/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4930832384.0000 - mae: 43372.2031\n",
      "Epoch 85/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4927828480.0000 - mae: 43337.0859\n",
      "Epoch 86/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4924736512.0000 - mae: 43301.9570\n",
      "Epoch 87/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 4921698304.0000 - mae: 43266.8242\n",
      "Epoch 88/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4918639616.0000 - mae: 43231.7578\n",
      "Epoch 89/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4915591168.0000 - mae: 43196.6641\n",
      "Epoch 90/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4912555520.0000 - mae: 43161.6641\n",
      "Epoch 91/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4909523968.0000 - mae: 43126.5156\n",
      "Epoch 92/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4906478592.0000 - mae: 43091.3320\n",
      "Epoch 93/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4903403520.0000 - mae: 43056.2031\n",
      "Epoch 94/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4900344832.0000 - mae: 43021.1406\n",
      "Epoch 95/100000\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 4897353728.0000 - mae: 42986.3008\n",
      "Epoch 96/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4894334976.0000 - mae: 42951.1602\n",
      "Epoch 97/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4891286016.0000 - mae: 42916.0859\n",
      "Epoch 98/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4888251392.0000 - mae: 42880.9375\n",
      "Epoch 99/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4885190144.0000 - mae: 42845.8164\n",
      "Epoch 100/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4882160640.0000 - mae: 42810.7734\n",
      "Epoch 101/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4879169536.0000 - mae: 42775.5898\n",
      "Epoch 102/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4876157952.0000 - mae: 42740.4570\n",
      "Epoch 103/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4873152512.0000 - mae: 42705.5078\n",
      "Epoch 104/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4870113792.0000 - mae: 42670.4062\n",
      "Epoch 105/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4867116032.0000 - mae: 42635.3984\n",
      "Epoch 106/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4864071680.0000 - mae: 42600.2930\n",
      "Epoch 107/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4861075968.0000 - mae: 42565.1758\n",
      "Epoch 108/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4858023424.0000 - mae: 42530.1797\n",
      "Epoch 109/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4855058432.0000 - mae: 42495.2031\n",
      "Epoch 110/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4852026368.0000 - mae: 42460.3359\n",
      "Epoch 111/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4849072640.0000 - mae: 42425.5547\n",
      "Epoch 112/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4846080000.0000 - mae: 42390.6406\n",
      "Epoch 113/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4843095040.0000 - mae: 42355.7930\n",
      "Epoch 114/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4840105984.0000 - mae: 42321.0586\n",
      "Epoch 115/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4837104128.0000 - mae: 42286.0820\n",
      "Epoch 116/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4834145792.0000 - mae: 42251.1172\n",
      "Epoch 117/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4831144960.0000 - mae: 42216.3203\n",
      "Epoch 118/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4828143616.0000 - mae: 42181.6328\n",
      "Epoch 119/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4825183744.0000 - mae: 42146.8516\n",
      "Epoch 120/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4822244864.0000 - mae: 42112.1641\n",
      "Epoch 121/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4819283456.0000 - mae: 42077.4219\n",
      "Epoch 122/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4816261632.0000 - mae: 42042.7188\n",
      "Epoch 123/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4813373440.0000 - mae: 42008.0586\n",
      "Epoch 124/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4810402816.0000 - mae: 41973.4219\n",
      "Epoch 125/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4807436800.0000 - mae: 41938.8086\n",
      "Epoch 126/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4804458496.0000 - mae: 41904.1484\n",
      "Epoch 127/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4801510400.0000 - mae: 41869.5078\n",
      "Epoch 128/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4798582272.0000 - mae: 41835.0508\n",
      "Epoch 129/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4795620864.0000 - mae: 41800.6055\n",
      "Epoch 130/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4792670720.0000 - mae: 41765.8633\n",
      "Epoch 131/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4789744640.0000 - mae: 41731.4258\n",
      "Epoch 132/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4786830336.0000 - mae: 41696.8906\n",
      "Epoch 133/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4783871488.0000 - mae: 41662.2617\n",
      "Epoch 134/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4780928000.0000 - mae: 41627.7188\n",
      "Epoch 135/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4778007552.0000 - mae: 41593.0898\n",
      "Epoch 136/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4775078400.0000 - mae: 41558.5781\n",
      "Epoch 137/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4772168704.0000 - mae: 41524.2070\n",
      "Epoch 138/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4769273344.0000 - mae: 41489.7227\n",
      "Epoch 139/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4766308352.0000 - mae: 41455.2031\n",
      "Epoch 140/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4763403264.0000 - mae: 41420.7188\n",
      "Epoch 141/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4760495104.0000 - mae: 41386.2188\n",
      "Epoch 142/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4757587968.0000 - mae: 41351.8945\n",
      "Epoch 143/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4754666496.0000 - mae: 41317.4961\n",
      "Epoch 144/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4751764480.0000 - mae: 41283.0859\n",
      "Epoch 145/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 4748844544.0000 - mae: 41248.6250\n",
      "Epoch 146/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4745949184.0000 - mae: 41214.2773\n",
      "Epoch 147/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4743048704.0000 - mae: 41179.8633\n",
      "Epoch 148/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4740119040.0000 - mae: 41145.4961\n",
      "Epoch 149/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4737238016.0000 - mae: 41111.3164\n",
      "Epoch 150/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4734386688.0000 - mae: 41076.9688\n",
      "Epoch 151/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4731469312.0000 - mae: 41042.4727\n",
      "Epoch 152/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4728574464.0000 - mae: 41008.2969\n",
      "Epoch 153/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4725688832.0000 - mae: 40973.9336\n",
      "Epoch 154/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4722818048.0000 - mae: 40939.6680\n",
      "Epoch 155/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4719915520.0000 - mae: 40905.5898\n",
      "Epoch 156/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4717031424.0000 - mae: 40871.2461\n",
      "Epoch 157/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4714143232.0000 - mae: 40837.0078\n",
      "Epoch 158/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4711324672.0000 - mae: 40802.8867\n",
      "Epoch 159/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4708453888.0000 - mae: 40768.8516\n",
      "Epoch 160/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4705597952.0000 - mae: 40734.7070\n",
      "Epoch 161/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4702708224.0000 - mae: 40700.6562\n",
      "Epoch 162/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4699851264.0000 - mae: 40666.4648\n",
      "Epoch 163/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4697001472.0000 - mae: 40632.1914\n",
      "Epoch 164/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4694113280.0000 - mae: 40598.0078\n",
      "Epoch 165/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4691273216.0000 - mae: 40563.9531\n",
      "Epoch 166/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4688430592.0000 - mae: 40530.0430\n",
      "Epoch 167/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4685575680.0000 - mae: 40495.8242\n",
      "Epoch 168/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4682716160.0000 - mae: 40461.8164\n",
      "Epoch 169/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4679897600.0000 - mae: 40427.8906\n",
      "Epoch 170/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4677089280.0000 - mae: 40394.0234\n",
      "Epoch 171/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4674216960.0000 - mae: 40360.0547\n",
      "Epoch 172/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4671408640.0000 - mae: 40326.2148\n",
      "Epoch 173/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4668576768.0000 - mae: 40292.3555\n",
      "Epoch 174/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4665746944.0000 - mae: 40258.5000\n",
      "Epoch 175/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4662913024.0000 - mae: 40224.5508\n",
      "Epoch 176/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4660097536.0000 - mae: 40190.7500\n",
      "Epoch 177/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4657261056.0000 - mae: 40157.0469\n",
      "Epoch 178/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4654472192.0000 - mae: 40123.2461\n",
      "Epoch 179/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4651655680.0000 - mae: 40089.5664\n",
      "Epoch 180/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4648854016.0000 - mae: 40055.9648\n",
      "Epoch 181/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4646047744.0000 - mae: 40022.2266\n",
      "Epoch 182/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4643249664.0000 - mae: 39988.5586\n",
      "Epoch 183/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4640393728.0000 - mae: 39954.7930\n",
      "Epoch 184/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4637603840.0000 - mae: 39920.9570\n",
      "Epoch 185/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4634788864.0000 - mae: 39887.2500\n",
      "Epoch 186/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4632007680.0000 - mae: 39853.6523\n",
      "Epoch 187/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4629215232.0000 - mae: 39819.9102\n",
      "Epoch 188/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4626408960.0000 - mae: 39786.1914\n",
      "Epoch 189/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4623628800.0000 - mae: 39752.6953\n",
      "Epoch 190/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4620808704.0000 - mae: 39718.9297\n",
      "Epoch 191/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4618025984.0000 - mae: 39685.3320\n",
      "Epoch 192/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4615261184.0000 - mae: 39651.8125\n",
      "Epoch 193/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4612489216.0000 - mae: 39618.3828\n",
      "Epoch 194/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4609712640.0000 - mae: 39584.7109\n",
      "Epoch 195/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4606917120.0000 - mae: 39551.1094\n",
      "Epoch 196/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4604146176.0000 - mae: 39517.6562\n",
      "Epoch 197/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4601376256.0000 - mae: 39484.1094\n",
      "Epoch 198/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4598638080.0000 - mae: 39450.7109\n",
      "Epoch 199/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4595836416.0000 - mae: 39417.1680\n",
      "Epoch 200/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4593090560.0000 - mae: 39383.9258\n",
      "Epoch 201/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4590372864.0000 - mae: 39350.6641\n",
      "Epoch 202/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4587634688.0000 - mae: 39317.5312\n",
      "Epoch 203/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4584871936.0000 - mae: 39284.3438\n",
      "Epoch 204/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4582111232.0000 - mae: 39251.0078\n",
      "Epoch 205/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4579357696.0000 - mae: 39217.7070\n",
      "Epoch 206/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4576612352.0000 - mae: 39184.4336\n",
      "Epoch 207/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4573860352.0000 - mae: 39151.1875\n",
      "Epoch 208/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4571154432.0000 - mae: 39117.9805\n",
      "Epoch 209/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4568375808.0000 - mae: 39084.7773\n",
      "Epoch 210/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4565653504.0000 - mae: 39051.7305\n",
      "Epoch 211/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4562939904.0000 - mae: 39018.7109\n",
      "Epoch 212/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4560240640.0000 - mae: 38986.0078\n",
      "Epoch 213/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4557517824.0000 - mae: 38953.0391\n",
      "Epoch 214/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4554791936.0000 - mae: 38920.0742\n",
      "Epoch 215/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4552043008.0000 - mae: 38886.9531\n",
      "Epoch 216/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4549344256.0000 - mae: 38854.0703\n",
      "Epoch 217/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 4546652160.0000 - mae: 38821.3984\n",
      "Epoch 218/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4543931904.0000 - mae: 38788.6680\n",
      "Epoch 219/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4541197824.0000 - mae: 38755.5625\n",
      "Epoch 220/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4538478080.0000 - mae: 38722.6289\n",
      "Epoch 221/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4535757824.0000 - mae: 38689.8516\n",
      "Epoch 222/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4533057024.0000 - mae: 38656.8438\n",
      "Epoch 223/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4530399232.0000 - mae: 38624.1680\n",
      "Epoch 224/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4527646720.0000 - mae: 38591.3594\n",
      "Epoch 225/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4524931584.0000 - mae: 38558.5117\n",
      "Epoch 226/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4522259968.0000 - mae: 38525.8438\n",
      "Epoch 227/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4519559680.0000 - mae: 38493.2578\n",
      "Epoch 228/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4516859392.0000 - mae: 38460.4688\n",
      "Epoch 229/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4514143744.0000 - mae: 38427.8633\n",
      "Epoch 230/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4511468544.0000 - mae: 38395.3164\n",
      "Epoch 231/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4508850688.0000 - mae: 38362.8594\n",
      "Epoch 232/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4506132992.0000 - mae: 38330.4570\n",
      "Epoch 233/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4503511040.0000 - mae: 38298.1172\n",
      "Epoch 234/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4500851712.0000 - mae: 38266.1719\n",
      "Epoch 235/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4498169344.0000 - mae: 38233.6836\n",
      "Epoch 236/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4495493120.0000 - mae: 38201.4570\n",
      "Epoch 237/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4492840960.0000 - mae: 38169.3945\n",
      "Epoch 238/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4490155008.0000 - mae: 38137.1562\n",
      "Epoch 239/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4487499264.0000 - mae: 38105.0234\n",
      "Epoch 240/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4484835328.0000 - mae: 38073.0586\n",
      "Epoch 241/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4482171904.0000 - mae: 38040.7812\n",
      "Epoch 242/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4479561728.0000 - mae: 38008.8867\n",
      "Epoch 243/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4476891648.0000 - mae: 37977.0078\n",
      "Epoch 244/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4474278912.0000 - mae: 37945.2344\n",
      "Epoch 245/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4471618560.0000 - mae: 37913.4766\n",
      "Epoch 246/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4468961792.0000 - mae: 37881.6172\n",
      "Epoch 247/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4466319360.0000 - mae: 37849.8359\n",
      "Epoch 248/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4463673344.0000 - mae: 37818.1758\n",
      "Epoch 249/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4461076992.0000 - mae: 37786.3672\n",
      "Epoch 250/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4458432000.0000 - mae: 37754.5508\n",
      "Epoch 251/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4455801856.0000 - mae: 37722.9141\n",
      "Epoch 252/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4453170688.0000 - mae: 37691.4023\n",
      "Epoch 253/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4450598912.0000 - mae: 37660.0469\n",
      "Epoch 254/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4447961600.0000 - mae: 37628.4570\n",
      "Epoch 255/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4445345280.0000 - mae: 37596.5625\n",
      "Epoch 256/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4442726912.0000 - mae: 37564.9688\n",
      "Epoch 257/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4440077824.0000 - mae: 37533.4844\n",
      "Epoch 258/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4437489152.0000 - mae: 37502.2031\n",
      "Epoch 259/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4434855936.0000 - mae: 37470.5195\n",
      "Epoch 260/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4432266752.0000 - mae: 37439.4180\n",
      "Epoch 261/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4429615616.0000 - mae: 37407.8867\n",
      "Epoch 262/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4427040768.0000 - mae: 37376.5430\n",
      "Epoch 263/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4424404992.0000 - mae: 37345.3438\n",
      "Epoch 264/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4421817344.0000 - mae: 37314.1211\n",
      "Epoch 265/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4419271680.0000 - mae: 37283.1680\n",
      "Epoch 266/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4416655360.0000 - mae: 37252.1641\n",
      "Epoch 267/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4414104064.0000 - mae: 37221.3711\n",
      "Epoch 268/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4411540480.0000 - mae: 37190.6953\n",
      "Epoch 269/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4408946176.0000 - mae: 37159.6992\n",
      "Epoch 270/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4406372352.0000 - mae: 37128.7930\n",
      "Epoch 271/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4403800064.0000 - mae: 37097.8906\n",
      "Epoch 272/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4401211904.0000 - mae: 37067.1484\n",
      "Epoch 273/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4398644224.0000 - mae: 37036.4453\n",
      "Epoch 274/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4396070912.0000 - mae: 37005.7500\n",
      "Epoch 275/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4393546240.0000 - mae: 36975.2656\n",
      "Epoch 276/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4390986752.0000 - mae: 36944.5938\n",
      "Epoch 277/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4388407808.0000 - mae: 36913.8867\n",
      "Epoch 278/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4385848832.0000 - mae: 36883.2969\n",
      "Epoch 279/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4383269888.0000 - mae: 36852.5586\n",
      "Epoch 280/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4380731904.0000 - mae: 36822.1211\n",
      "Epoch 281/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4378164736.0000 - mae: 36791.6680\n",
      "Epoch 282/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4375645184.0000 - mae: 36761.4375\n",
      "Epoch 283/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4373142528.0000 - mae: 36731.2266\n",
      "Epoch 284/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4370577408.0000 - mae: 36700.8281\n",
      "Epoch 285/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4368050176.0000 - mae: 36670.7148\n",
      "Epoch 286/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4365523968.0000 - mae: 36640.7109\n",
      "Epoch 287/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4362956288.0000 - mae: 36610.6133\n",
      "Epoch 288/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4360442880.0000 - mae: 36580.6055\n",
      "Epoch 289/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 4357945856.0000 - mae: 36550.6641\n",
      "Epoch 290/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4355392512.0000 - mae: 36520.7891\n",
      "Epoch 291/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4352879616.0000 - mae: 36490.9766\n",
      "Epoch 292/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4350341120.0000 - mae: 36460.8945\n",
      "Epoch 293/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4347853312.0000 - mae: 36431.3320\n",
      "Epoch 294/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4345339904.0000 - mae: 36401.6836\n",
      "Epoch 295/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4342803456.0000 - mae: 36372.0078\n",
      "Epoch 296/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4340269568.0000 - mae: 36342.1562\n",
      "Epoch 297/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4337781248.0000 - mae: 36312.4648\n",
      "Epoch 298/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4335308288.0000 - mae: 36282.9453\n",
      "Epoch 299/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4332802048.0000 - mae: 36253.2422\n",
      "Epoch 300/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4330258944.0000 - mae: 36223.7227\n",
      "Epoch 301/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4327776256.0000 - mae: 36194.4102\n",
      "Epoch 302/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4325312000.0000 - mae: 36165.2969\n",
      "Epoch 303/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4322821120.0000 - mae: 36135.8516\n",
      "Epoch 304/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4320297472.0000 - mae: 36106.4766\n",
      "Epoch 305/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4317818368.0000 - mae: 36076.9688\n",
      "Epoch 306/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4315319808.0000 - mae: 36047.7031\n",
      "Epoch 307/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4312827904.0000 - mae: 36018.5234\n",
      "Epoch 308/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4310433280.0000 - mae: 35989.5000\n",
      "Epoch 309/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4307910656.0000 - mae: 35960.4297\n",
      "Epoch 310/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4305439232.0000 - mae: 35931.0469\n",
      "Epoch 311/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4302944768.0000 - mae: 35902.1289\n",
      "Epoch 312/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4300481536.0000 - mae: 35873.1523\n",
      "Epoch 313/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4298059776.0000 - mae: 35844.5000\n",
      "Epoch 314/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4295606784.0000 - mae: 35815.7930\n",
      "Epoch 315/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4293132288.0000 - mae: 35786.7578\n",
      "Epoch 316/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4290667776.0000 - mae: 35757.9922\n",
      "Epoch 317/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4288270080.0000 - mae: 35729.3828\n",
      "Epoch 318/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4285793792.0000 - mae: 35700.3555\n",
      "Epoch 319/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4283345920.0000 - mae: 35671.6680\n",
      "Epoch 320/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4280878336.0000 - mae: 35642.7617\n",
      "Epoch 321/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4278456064.0000 - mae: 35614.0703\n",
      "Epoch 322/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4275988736.0000 - mae: 35585.4727\n",
      "Epoch 323/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4273562368.0000 - mae: 35556.7344\n",
      "Epoch 324/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4271112960.0000 - mae: 35528.1602\n",
      "Epoch 325/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4268686336.0000 - mae: 35499.7344\n",
      "Epoch 326/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4266263296.0000 - mae: 35471.3086\n",
      "Epoch 327/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4263855616.0000 - mae: 35442.7422\n",
      "Epoch 328/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4261410816.0000 - mae: 35414.2500\n",
      "Epoch 329/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4259002112.0000 - mae: 35385.9180\n",
      "Epoch 330/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4256588032.0000 - mae: 35357.5859\n",
      "Epoch 331/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4254147584.0000 - mae: 35329.3555\n",
      "Epoch 332/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4251740416.0000 - mae: 35301.0273\n",
      "Epoch 333/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4249311744.0000 - mae: 35272.8477\n",
      "Epoch 334/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4246890752.0000 - mae: 35244.2695\n",
      "Epoch 335/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4244534528.0000 - mae: 35216.1367\n",
      "Epoch 336/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4242081792.0000 - mae: 35187.8711\n",
      "Epoch 337/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4239723520.0000 - mae: 35159.9219\n",
      "Epoch 338/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4237294080.0000 - mae: 35131.7734\n",
      "Epoch 339/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4234908416.0000 - mae: 35103.7109\n",
      "Epoch 340/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4232547840.0000 - mae: 35075.7344\n",
      "Epoch 341/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4230130432.0000 - mae: 35047.4961\n",
      "Epoch 342/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4227736064.0000 - mae: 35019.5430\n",
      "Epoch 343/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4225362432.0000 - mae: 34991.6406\n",
      "Epoch 344/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4222974208.0000 - mae: 34964.1094\n",
      "Epoch 345/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4220614912.0000 - mae: 34936.3711\n",
      "Epoch 346/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4218254080.0000 - mae: 34908.4766\n",
      "Epoch 347/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4215864320.0000 - mae: 34880.8125\n",
      "Epoch 348/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4213490432.0000 - mae: 34852.8125\n",
      "Epoch 349/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4211078912.0000 - mae: 34825.0156\n",
      "Epoch 350/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4208673792.0000 - mae: 34797.2773\n",
      "Epoch 351/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4206356224.0000 - mae: 34769.7070\n",
      "Epoch 352/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4203976960.0000 - mae: 34742.3789\n",
      "Epoch 353/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4201585664.0000 - mae: 34714.8203\n",
      "Epoch 354/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4199218944.0000 - mae: 34687.1875\n",
      "Epoch 355/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4196895488.0000 - mae: 34659.7969\n",
      "Epoch 356/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4194488320.0000 - mae: 34632.4102\n",
      "Epoch 357/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4192189184.0000 - mae: 34605.1836\n",
      "Epoch 358/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4189851392.0000 - mae: 34578.1484\n",
      "Epoch 359/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4187493376.0000 - mae: 34551.0078\n",
      "Epoch 360/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4185162496.0000 - mae: 34524.1445\n",
      "Epoch 361/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 4182841600.0000 - mae: 34497.0781\n",
      "Epoch 362/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4180537856.0000 - mae: 34470.0859\n",
      "Epoch 363/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4178127360.0000 - mae: 34442.7148\n",
      "Epoch 364/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4175840512.0000 - mae: 34416.0898\n",
      "Epoch 365/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4173460480.0000 - mae: 34389.0195\n",
      "Epoch 366/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4171181312.0000 - mae: 34362.5000\n",
      "Epoch 367/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4168815360.0000 - mae: 34335.5703\n",
      "Epoch 368/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4166529792.0000 - mae: 34308.8828\n",
      "Epoch 369/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4164209664.0000 - mae: 34282.3594\n",
      "Epoch 370/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4161916672.0000 - mae: 34255.5508\n",
      "Epoch 371/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4159587328.0000 - mae: 34229.2539\n",
      "Epoch 372/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4157310720.0000 - mae: 34202.8438\n",
      "Epoch 373/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4154978816.0000 - mae: 34176.8516\n",
      "Epoch 374/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4152689920.0000 - mae: 34150.4844\n",
      "Epoch 375/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4150371584.0000 - mae: 34124.1758\n",
      "Epoch 376/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4148041472.0000 - mae: 34098.0312\n",
      "Epoch 377/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4145794048.0000 - mae: 34071.7734\n",
      "Epoch 378/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4143470080.0000 - mae: 34045.5195\n",
      "Epoch 379/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4141227264.0000 - mae: 34019.7344\n",
      "Epoch 380/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4138905088.0000 - mae: 33993.7539\n",
      "Epoch 381/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4136634624.0000 - mae: 33967.8750\n",
      "Epoch 382/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4134312704.0000 - mae: 33941.8828\n",
      "Epoch 383/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4132037632.0000 - mae: 33916.0469\n",
      "Epoch 384/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4129768960.0000 - mae: 33890.3711\n",
      "Epoch 385/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4127500544.0000 - mae: 33864.4883\n",
      "Epoch 386/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4125185792.0000 - mae: 33838.6836\n",
      "Epoch 387/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4122931968.0000 - mae: 33813.2148\n",
      "Epoch 388/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4120670720.0000 - mae: 33787.6836\n",
      "Epoch 389/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4118382336.0000 - mae: 33762.2773\n",
      "Epoch 390/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4116097024.0000 - mae: 33736.7109\n",
      "Epoch 391/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4113846272.0000 - mae: 33711.3867\n",
      "Epoch 392/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4111582976.0000 - mae: 33685.7070\n",
      "Epoch 393/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4109313792.0000 - mae: 33660.3633\n",
      "Epoch 394/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4107088896.0000 - mae: 33635.1875\n",
      "Epoch 395/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4104818432.0000 - mae: 33609.7578\n",
      "Epoch 396/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4102546176.0000 - mae: 33584.4492\n",
      "Epoch 397/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4100301824.0000 - mae: 33559.1094\n",
      "Epoch 398/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4098074624.0000 - mae: 33533.7734\n",
      "Epoch 399/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4095784704.0000 - mae: 33508.5781\n",
      "Epoch 400/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4093563136.0000 - mae: 33483.5781\n",
      "Epoch 401/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4091299584.0000 - mae: 33458.7773\n",
      "Epoch 402/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4089103104.0000 - mae: 33434.1797\n",
      "Epoch 403/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4086873344.0000 - mae: 33409.6992\n",
      "Epoch 404/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4084650240.0000 - mae: 33384.9648\n",
      "Epoch 405/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4082440448.0000 - mae: 33360.3828\n",
      "Epoch 406/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4080198656.0000 - mae: 33335.8008\n",
      "Epoch 407/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4077995776.0000 - mae: 33311.3555\n",
      "Epoch 408/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4075800832.0000 - mae: 33286.9805\n",
      "Epoch 409/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4073553920.0000 - mae: 33262.7461\n",
      "Epoch 410/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4071349760.0000 - mae: 33238.6016\n",
      "Epoch 411/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4069166080.0000 - mae: 33214.3203\n",
      "Epoch 412/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4066977536.0000 - mae: 33190.0156\n",
      "Epoch 413/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4064763136.0000 - mae: 33165.8125\n",
      "Epoch 414/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4062554112.0000 - mae: 33141.8281\n",
      "Epoch 415/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4060398848.0000 - mae: 33118.1055\n",
      "Epoch 416/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4058183680.0000 - mae: 33094.2227\n",
      "Epoch 417/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4056016640.0000 - mae: 33070.6797\n",
      "Epoch 418/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4053829120.0000 - mae: 33046.9531\n",
      "Epoch 419/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4051600384.0000 - mae: 33022.7891\n",
      "Epoch 420/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4049435904.0000 - mae: 32999.2773\n",
      "Epoch 421/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4047252224.0000 - mae: 32975.5664\n",
      "Epoch 422/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4045084672.0000 - mae: 32952.0156\n",
      "Epoch 423/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4042868992.0000 - mae: 32928.3086\n",
      "Epoch 424/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4040712704.0000 - mae: 32904.9492\n",
      "Epoch 425/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4038520832.0000 - mae: 32881.2031\n",
      "Epoch 426/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4036329472.0000 - mae: 32857.5391\n",
      "Epoch 427/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4034171136.0000 - mae: 32834.2031\n",
      "Epoch 428/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4031984896.0000 - mae: 32810.4609\n",
      "Epoch 429/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4029860864.0000 - mae: 32787.3828\n",
      "Epoch 430/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4027666944.0000 - mae: 32764.4512\n",
      "Epoch 431/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4025514752.0000 - mae: 32741.4863\n",
      "Epoch 432/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4023328768.0000 - mae: 32718.3633\n",
      "Epoch 433/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 4021203968.0000 - mae: 32695.5918\n",
      "Epoch 434/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4019036672.0000 - mae: 32672.8203\n",
      "Epoch 435/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4016891136.0000 - mae: 32650.1055\n",
      "Epoch 436/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4014775808.0000 - mae: 32627.4121\n",
      "Epoch 437/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4012605184.0000 - mae: 32604.6270\n",
      "Epoch 438/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4010438656.0000 - mae: 32582.1211\n",
      "Epoch 439/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4008331008.0000 - mae: 32559.6660\n",
      "Epoch 440/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4006167552.0000 - mae: 32536.7637\n",
      "Epoch 441/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4004020224.0000 - mae: 32514.2969\n",
      "Epoch 442/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4001912064.0000 - mae: 32491.8438\n",
      "Epoch 443/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3999754240.0000 - mae: 32469.1289\n",
      "Epoch 444/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3997647616.0000 - mae: 32447.0430\n",
      "Epoch 445/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3995503104.0000 - mae: 32425.1406\n",
      "Epoch 446/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3993421312.0000 - mae: 32403.0898\n",
      "Epoch 447/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3991287296.0000 - mae: 32381.3281\n",
      "Epoch 448/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3989162240.0000 - mae: 32359.3613\n",
      "Epoch 449/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3987076864.0000 - mae: 32337.6816\n",
      "Epoch 450/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3984949248.0000 - mae: 32315.9219\n",
      "Epoch 451/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3982844672.0000 - mae: 32294.1172\n",
      "Epoch 452/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3980734464.0000 - mae: 32272.4141\n",
      "Epoch 453/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3978684928.0000 - mae: 32251.1074\n",
      "Epoch 454/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3976541440.0000 - mae: 32229.5703\n",
      "Epoch 455/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3974490624.0000 - mae: 32207.9961\n",
      "Epoch 456/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3972361216.0000 - mae: 32186.1660\n",
      "Epoch 457/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3970286080.0000 - mae: 32164.8418\n",
      "Epoch 458/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3968195328.0000 - mae: 32143.3027\n",
      "Epoch 459/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3966078976.0000 - mae: 32122.1621\n",
      "Epoch 460/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3963984128.0000 - mae: 32101.3477\n",
      "Epoch 461/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3961937408.0000 - mae: 32080.4531\n",
      "Epoch 462/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3959822848.0000 - mae: 32059.3008\n",
      "Epoch 463/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3957780736.0000 - mae: 32038.4805\n",
      "Epoch 464/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3955688448.0000 - mae: 32017.5684\n",
      "Epoch 465/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3953635072.0000 - mae: 31996.7988\n",
      "Epoch 466/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3951561728.0000 - mae: 31976.2520\n",
      "Epoch 467/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3949495040.0000 - mae: 31955.7324\n",
      "Epoch 468/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3947435264.0000 - mae: 31935.2246\n",
      "Epoch 469/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3945374720.0000 - mae: 31914.5742\n",
      "Epoch 470/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3943309312.0000 - mae: 31894.0996\n",
      "Epoch 471/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3941294080.0000 - mae: 31873.7422\n",
      "Epoch 472/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3939262720.0000 - mae: 31853.7656\n",
      "Epoch 473/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3937173760.0000 - mae: 31833.3457\n",
      "Epoch 474/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3935107328.0000 - mae: 31813.3281\n",
      "Epoch 475/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3933092096.0000 - mae: 31793.5527\n",
      "Epoch 476/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3931049216.0000 - mae: 31773.5020\n",
      "Epoch 477/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3929021440.0000 - mae: 31753.6543\n",
      "Epoch 478/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3926944768.0000 - mae: 31733.4922\n",
      "Epoch 479/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3924924160.0000 - mae: 31713.7207\n",
      "Epoch 480/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3922896384.0000 - mae: 31694.1289\n",
      "Epoch 481/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3920875264.0000 - mae: 31674.6270\n",
      "Epoch 482/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3918818304.0000 - mae: 31654.9121\n",
      "Epoch 483/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3916825856.0000 - mae: 31635.2637\n",
      "Epoch 484/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3914811648.0000 - mae: 31615.7930\n",
      "Epoch 485/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3912792064.0000 - mae: 31596.3184\n",
      "Epoch 486/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3910787840.0000 - mae: 31577.0332\n",
      "Epoch 487/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3908754688.0000 - mae: 31557.7988\n",
      "Epoch 488/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3906769920.0000 - mae: 31539.1504\n",
      "Epoch 489/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3904770560.0000 - mae: 31520.2246\n",
      "Epoch 490/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3902780160.0000 - mae: 31501.5703\n",
      "Epoch 491/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3900750848.0000 - mae: 31482.4258\n",
      "Epoch 492/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3898725120.0000 - mae: 31463.3223\n",
      "Epoch 493/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3896746496.0000 - mae: 31444.3672\n",
      "Epoch 494/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3894705408.0000 - mae: 31425.6973\n",
      "Epoch 495/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3892792064.0000 - mae: 31407.1797\n",
      "Epoch 496/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3890785792.0000 - mae: 31388.6309\n",
      "Epoch 497/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3888790528.0000 - mae: 31369.9277\n",
      "Epoch 498/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3886821376.0000 - mae: 31351.5234\n",
      "Epoch 499/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3884834048.0000 - mae: 31332.7637\n",
      "Epoch 500/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3882810112.0000 - mae: 31314.0742\n",
      "Epoch 501/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3880811264.0000 - mae: 31295.4297\n",
      "Epoch 502/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3878884608.0000 - mae: 31277.2969\n",
      "Epoch 503/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3876862976.0000 - mae: 31258.9121\n",
      "Epoch 504/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3874934784.0000 - mae: 31241.3359\n",
      "Epoch 505/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 3872929280.0000 - mae: 31223.2129\n",
      "Epoch 506/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3871042304.0000 - mae: 31205.5195\n",
      "Epoch 507/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3869055744.0000 - mae: 31187.5801\n",
      "Epoch 508/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3867100160.0000 - mae: 31169.5098\n",
      "Epoch 509/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3865116416.0000 - mae: 31151.7246\n",
      "Epoch 510/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3863176448.0000 - mae: 31134.0156\n",
      "Epoch 511/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3861227264.0000 - mae: 31116.2305\n",
      "Epoch 512/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3859238656.0000 - mae: 31098.5625\n",
      "Epoch 513/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3857325824.0000 - mae: 31081.0781\n",
      "Epoch 514/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3855399424.0000 - mae: 31063.5820\n",
      "Epoch 515/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3853434112.0000 - mae: 31045.7539\n",
      "Epoch 516/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3851479808.0000 - mae: 31028.2441\n",
      "Epoch 517/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3849547520.0000 - mae: 31011.1504\n",
      "Epoch 518/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3847628800.0000 - mae: 30993.9160\n",
      "Epoch 519/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3845696256.0000 - mae: 30976.9824\n",
      "Epoch 520/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3843758848.0000 - mae: 30959.8320\n",
      "Epoch 521/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3841819904.0000 - mae: 30942.7656\n",
      "Epoch 522/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3839919872.0000 - mae: 30925.8418\n",
      "Epoch 523/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3838005504.0000 - mae: 30908.5195\n",
      "Epoch 524/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3836103168.0000 - mae: 30891.6816\n",
      "Epoch 525/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3834160640.0000 - mae: 30874.8828\n",
      "Epoch 526/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3832238336.0000 - mae: 30858.1914\n",
      "Epoch 527/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3830326784.0000 - mae: 30841.5371\n",
      "Epoch 528/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3828443392.0000 - mae: 30824.2461\n",
      "Epoch 529/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3826567424.0000 - mae: 30808.1074\n",
      "Epoch 530/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3824640512.0000 - mae: 30791.2969\n",
      "Epoch 531/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3822741248.0000 - mae: 30774.7246\n",
      "Epoch 532/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3820818944.0000 - mae: 30758.3340\n",
      "Epoch 533/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3818951936.0000 - mae: 30742.2227\n",
      "Epoch 534/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3817076736.0000 - mae: 30725.7148\n",
      "Epoch 535/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3815214592.0000 - mae: 30709.5312\n",
      "Epoch 536/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3813319424.0000 - mae: 30693.1348\n",
      "Epoch 537/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3811414272.0000 - mae: 30676.7324\n",
      "Epoch 538/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3809527808.0000 - mae: 30660.4746\n",
      "Epoch 539/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3807629824.0000 - mae: 30644.2969\n",
      "Epoch 540/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3805764096.0000 - mae: 30628.6035\n",
      "Epoch 541/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3803904000.0000 - mae: 30612.4355\n",
      "Epoch 542/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3802025984.0000 - mae: 30596.7051\n",
      "Epoch 543/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3800189696.0000 - mae: 30580.9160\n",
      "Epoch 544/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3798288640.0000 - mae: 30564.9219\n",
      "Epoch 545/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3796444160.0000 - mae: 30548.9492\n",
      "Epoch 546/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3794611456.0000 - mae: 30533.9883\n",
      "Epoch 547/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3792739584.0000 - mae: 30518.5645\n",
      "Epoch 548/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3790902528.0000 - mae: 30503.2676\n",
      "Epoch 549/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3789008640.0000 - mae: 30487.8594\n",
      "Epoch 550/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3787186176.0000 - mae: 30472.9062\n",
      "Epoch 551/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3785347584.0000 - mae: 30457.5410\n",
      "Epoch 552/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3783446016.0000 - mae: 30442.2402\n",
      "Epoch 553/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3781638656.0000 - mae: 30427.2461\n",
      "Epoch 554/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3779755520.0000 - mae: 30411.8867\n",
      "Epoch 555/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3777929472.0000 - mae: 30397.2617\n",
      "Epoch 556/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3776096512.0000 - mae: 30381.9180\n",
      "Epoch 557/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3774260480.0000 - mae: 30367.2969\n",
      "Epoch 558/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3772448512.0000 - mae: 30352.1855\n",
      "Epoch 559/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3770600960.0000 - mae: 30337.2500\n",
      "Epoch 560/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3768769024.0000 - mae: 30322.0840\n",
      "Epoch 561/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3766923520.0000 - mae: 30307.4902\n",
      "Epoch 562/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3765139712.0000 - mae: 30292.9941\n",
      "Epoch 563/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3763288576.0000 - mae: 30278.3906\n",
      "Epoch 564/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3761516032.0000 - mae: 30264.0879\n",
      "Epoch 565/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3759681024.0000 - mae: 30249.2305\n",
      "Epoch 566/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3757888512.0000 - mae: 30234.6973\n",
      "Epoch 567/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3756079616.0000 - mae: 30220.1113\n",
      "Epoch 568/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3754300416.0000 - mae: 30206.0273\n",
      "Epoch 569/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3752468224.0000 - mae: 30191.6465\n",
      "Epoch 570/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3750683648.0000 - mae: 30177.5430\n",
      "Epoch 571/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3748932352.0000 - mae: 30163.3672\n",
      "Epoch 572/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3747141120.0000 - mae: 30149.1836\n",
      "Epoch 573/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3745334016.0000 - mae: 30135.0566\n",
      "Epoch 574/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3743559168.0000 - mae: 30120.5488\n",
      "Epoch 575/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3741764608.0000 - mae: 30106.6250\n",
      "Epoch 576/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3739996928.0000 - mae: 30093.1270\n",
      "Epoch 577/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 3738217984.0000 - mae: 30079.7148\n",
      "Epoch 578/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3736441856.0000 - mae: 30066.3535\n",
      "Epoch 579/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3734656512.0000 - mae: 30052.6641\n",
      "Epoch 580/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3732873472.0000 - mae: 30039.0449\n",
      "Epoch 581/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3731099392.0000 - mae: 30025.6875\n",
      "Epoch 582/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3729365248.0000 - mae: 30012.2969\n",
      "Epoch 583/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3727571200.0000 - mae: 29999.3457\n",
      "Epoch 584/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3725853440.0000 - mae: 29986.1836\n",
      "Epoch 585/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3724112640.0000 - mae: 29973.2793\n",
      "Epoch 586/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3722316032.0000 - mae: 29960.4688\n",
      "Epoch 587/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3720535808.0000 - mae: 29946.8438\n",
      "Epoch 588/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3718755072.0000 - mae: 29933.7031\n",
      "Epoch 589/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3717023232.0000 - mae: 29920.9668\n",
      "Epoch 590/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3715293696.0000 - mae: 29908.1777\n",
      "Epoch 591/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3713561344.0000 - mae: 29895.4238\n",
      "Epoch 592/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3711822080.0000 - mae: 29882.8926\n",
      "Epoch 593/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3710118912.0000 - mae: 29870.3691\n",
      "Epoch 594/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3708359168.0000 - mae: 29857.4062\n",
      "Epoch 595/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3706639360.0000 - mae: 29845.0488\n",
      "Epoch 596/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3704956672.0000 - mae: 29832.6758\n",
      "Epoch 597/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3703204096.0000 - mae: 29820.0547\n",
      "Epoch 598/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3701476352.0000 - mae: 29807.4629\n",
      "Epoch 599/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3699750144.0000 - mae: 29794.9160\n",
      "Epoch 600/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3698061568.0000 - mae: 29782.4688\n",
      "Epoch 601/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3696323584.0000 - mae: 29769.5645\n",
      "Epoch 602/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3694625536.0000 - mae: 29757.2891\n",
      "Epoch 603/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3692904704.0000 - mae: 29744.8555\n",
      "Epoch 604/100000\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 3691178752.0000 - mae: 29732.1465\n",
      "Epoch 605/100000\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 3689476096.0000 - mae: 29720.3125\n",
      "Epoch 606/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3687781888.0000 - mae: 29708.3242\n",
      "Epoch 607/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3686088192.0000 - mae: 29696.2578\n",
      "Epoch 608/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3684406016.0000 - mae: 29684.7246\n",
      "Epoch 609/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3682715136.0000 - mae: 29672.5801\n",
      "Epoch 610/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3681033472.0000 - mae: 29660.8984\n",
      "Epoch 611/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3679345408.0000 - mae: 29648.3926\n",
      "Epoch 612/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3677664512.0000 - mae: 29636.6484\n",
      "Epoch 613/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3675988736.0000 - mae: 29624.9570\n",
      "Epoch 614/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3674290688.0000 - mae: 29613.2070\n",
      "Epoch 615/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3672594432.0000 - mae: 29601.2969\n",
      "Epoch 616/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3670890496.0000 - mae: 29589.4590\n",
      "Epoch 617/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3669183232.0000 - mae: 29577.5918\n",
      "Epoch 618/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3667554816.0000 - mae: 29565.7363\n",
      "Epoch 619/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3665866496.0000 - mae: 29554.0117\n",
      "Epoch 620/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3664223744.0000 - mae: 29542.7305\n",
      "Epoch 621/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3662521344.0000 - mae: 29530.9785\n",
      "Epoch 622/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3660890112.0000 - mae: 29519.6914\n",
      "Epoch 623/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3659224832.0000 - mae: 29508.1582\n",
      "Epoch 624/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3657537792.0000 - mae: 29496.6426\n",
      "Epoch 625/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3655910912.0000 - mae: 29484.9766\n",
      "Epoch 626/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3654217216.0000 - mae: 29473.3809\n",
      "Epoch 627/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3652569344.0000 - mae: 29462.1074\n",
      "Epoch 628/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3650934528.0000 - mae: 29450.5547\n",
      "Epoch 629/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3649269504.0000 - mae: 29439.4453\n",
      "Epoch 630/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3647628288.0000 - mae: 29428.0820\n",
      "Epoch 631/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3645990912.0000 - mae: 29416.5430\n",
      "Epoch 632/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3644350976.0000 - mae: 29405.3691\n",
      "Epoch 633/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3642727168.0000 - mae: 29394.1113\n",
      "Epoch 634/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3641078528.0000 - mae: 29382.7305\n",
      "Epoch 635/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3639447552.0000 - mae: 29372.1016\n",
      "Epoch 636/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3637821184.0000 - mae: 29361.4316\n",
      "Epoch 637/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3636206592.0000 - mae: 29350.6816\n",
      "Epoch 638/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3634557696.0000 - mae: 29339.6992\n",
      "Epoch 639/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3632937216.0000 - mae: 29329.1660\n",
      "Epoch 640/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3631318784.0000 - mae: 29318.3027\n",
      "Epoch 641/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3629713152.0000 - mae: 29307.5293\n",
      "Epoch 642/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3628142592.0000 - mae: 29297.0391\n",
      "Epoch 643/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3626541056.0000 - mae: 29286.6426\n",
      "Epoch 644/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3624892160.0000 - mae: 29275.8496\n",
      "Epoch 645/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3623330304.0000 - mae: 29265.7871\n",
      "Epoch 646/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3621748480.0000 - mae: 29255.2891\n",
      "Epoch 647/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3620110592.0000 - mae: 29244.3984\n",
      "Epoch 648/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3618495232.0000 - mae: 29233.9180\n",
      "Epoch 649/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 3616934144.0000 - mae: 29223.9902\n",
      "Epoch 650/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3615373824.0000 - mae: 29213.6699\n",
      "Epoch 651/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3613784576.0000 - mae: 29203.6855\n",
      "Epoch 652/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3612230912.0000 - mae: 29193.6211\n",
      "Epoch 653/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3610626304.0000 - mae: 29183.7812\n",
      "Epoch 654/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3609019392.0000 - mae: 29173.2441\n",
      "Epoch 655/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3607463680.0000 - mae: 29163.2051\n",
      "Epoch 656/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3605849344.0000 - mae: 29152.8320\n",
      "Epoch 657/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3604307712.0000 - mae: 29143.0684\n",
      "Epoch 658/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3602724608.0000 - mae: 29132.8945\n",
      "Epoch 659/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3601124864.0000 - mae: 29122.7148\n",
      "Epoch 660/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3599559424.0000 - mae: 29112.6309\n",
      "Epoch 661/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3598001920.0000 - mae: 29102.7930\n",
      "Epoch 662/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3596403456.0000 - mae: 29092.7539\n",
      "Epoch 663/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3594883840.0000 - mae: 29082.9004\n",
      "Epoch 664/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3593339648.0000 - mae: 29073.0293\n",
      "Epoch 665/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3591774720.0000 - mae: 29063.5918\n",
      "Epoch 666/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3590215936.0000 - mae: 29054.1465\n",
      "Epoch 667/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3588648704.0000 - mae: 29044.7109\n",
      "Epoch 668/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3587118592.0000 - mae: 29034.9336\n",
      "Epoch 669/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3585592320.0000 - mae: 29025.9512\n",
      "Epoch 670/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3584061952.0000 - mae: 29016.4258\n",
      "Epoch 671/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3582479104.0000 - mae: 29006.8340\n",
      "Epoch 672/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3580966656.0000 - mae: 28997.6035\n",
      "Epoch 673/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3579418368.0000 - mae: 28988.2578\n",
      "Epoch 674/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3577882112.0000 - mae: 28979.0117\n",
      "Epoch 675/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3576365312.0000 - mae: 28969.8652\n",
      "Epoch 676/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3574874624.0000 - mae: 28960.8672\n",
      "Epoch 677/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3573348608.0000 - mae: 28951.4707\n",
      "Epoch 678/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3571833600.0000 - mae: 28942.6328\n",
      "Epoch 679/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3570331648.0000 - mae: 28933.4121\n",
      "Epoch 680/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3568802560.0000 - mae: 28924.5586\n",
      "Epoch 681/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3567312128.0000 - mae: 28915.8027\n",
      "Epoch 682/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3565812992.0000 - mae: 28907.0625\n",
      "Epoch 683/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3564293120.0000 - mae: 28898.2852\n",
      "Epoch 684/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3562797568.0000 - mae: 28889.2637\n",
      "Epoch 685/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3561318400.0000 - mae: 28880.5098\n",
      "Epoch 686/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3559754496.0000 - mae: 28871.4414\n",
      "Epoch 687/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3558282752.0000 - mae: 28862.9512\n",
      "Epoch 688/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3556792576.0000 - mae: 28854.2363\n",
      "Epoch 689/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3555287040.0000 - mae: 28845.9707\n",
      "Epoch 690/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3553807360.0000 - mae: 28837.1523\n",
      "Epoch 691/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3552275968.0000 - mae: 28828.5918\n",
      "Epoch 692/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3550796800.0000 - mae: 28820.0898\n",
      "Epoch 693/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3549329408.0000 - mae: 28811.6211\n",
      "Epoch 694/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3547898112.0000 - mae: 28803.2676\n",
      "Epoch 695/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3546415872.0000 - mae: 28795.4980\n",
      "Epoch 696/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3544925952.0000 - mae: 28787.3457\n",
      "Epoch 697/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3543504384.0000 - mae: 28779.7754\n",
      "Epoch 698/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3542037504.0000 - mae: 28771.8770\n",
      "Epoch 699/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3540558592.0000 - mae: 28763.5156\n",
      "Epoch 700/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3539086592.0000 - mae: 28755.6387\n",
      "Epoch 701/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3537654528.0000 - mae: 28747.9277\n",
      "Epoch 702/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3536187136.0000 - mae: 28740.0273\n",
      "Epoch 703/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3534688000.0000 - mae: 28732.3301\n",
      "Epoch 704/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3533255936.0000 - mae: 28724.5703\n",
      "Epoch 705/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3531817728.0000 - mae: 28717.0508\n",
      "Epoch 706/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3530358272.0000 - mae: 28709.4023\n",
      "Epoch 707/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3528936960.0000 - mae: 28701.6133\n",
      "Epoch 708/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3527474688.0000 - mae: 28694.0098\n",
      "Epoch 709/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3526077696.0000 - mae: 28686.6641\n",
      "Epoch 710/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3524655616.0000 - mae: 28679.2891\n",
      "Epoch 711/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3523198464.0000 - mae: 28671.7090\n",
      "Epoch 712/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3521742592.0000 - mae: 28664.3984\n",
      "Epoch 713/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3520338176.0000 - mae: 28657.0742\n",
      "Epoch 714/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3518883584.0000 - mae: 28649.6035\n",
      "Epoch 715/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3517491968.0000 - mae: 28642.1504\n",
      "Epoch 716/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3516027136.0000 - mae: 28634.7539\n",
      "Epoch 717/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3514591488.0000 - mae: 28627.1680\n",
      "Epoch 718/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3513209856.0000 - mae: 28620.1465\n",
      "Epoch 719/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3511782912.0000 - mae: 28613.1289\n",
      "Epoch 720/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3510359552.0000 - mae: 28605.7949\n",
      "Epoch 721/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 3508951296.0000 - mae: 28598.6934\n",
      "Epoch 722/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3507562752.0000 - mae: 28591.5410\n",
      "Epoch 723/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3506129920.0000 - mae: 28584.3535\n",
      "Epoch 724/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3504705792.0000 - mae: 28577.0938\n",
      "Epoch 725/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3503328512.0000 - mae: 28570.5469\n",
      "Epoch 726/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3501929728.0000 - mae: 28564.0996\n",
      "Epoch 727/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3500526848.0000 - mae: 28557.4570\n",
      "Epoch 728/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3499114752.0000 - mae: 28551.0723\n",
      "Epoch 729/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3497737728.0000 - mae: 28544.6582\n",
      "Epoch 730/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3496409856.0000 - mae: 28538.4473\n",
      "Epoch 731/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3495057408.0000 - mae: 28532.2363\n",
      "Epoch 732/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3493677824.0000 - mae: 28525.7637\n",
      "Epoch 733/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3492273408.0000 - mae: 28519.5488\n",
      "Epoch 734/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3490860288.0000 - mae: 28513.1465\n",
      "Epoch 735/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3489519616.0000 - mae: 28507.1445\n",
      "Epoch 736/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3488174592.0000 - mae: 28500.8418\n",
      "Epoch 737/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3486797056.0000 - mae: 28494.9551\n",
      "Epoch 738/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3485406720.0000 - mae: 28488.9219\n",
      "Epoch 739/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3484035072.0000 - mae: 28482.3516\n",
      "Epoch 740/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3482685440.0000 - mae: 28476.6016\n",
      "Epoch 741/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3481319936.0000 - mae: 28470.8145\n",
      "Epoch 742/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3479945728.0000 - mae: 28464.9727\n",
      "Epoch 743/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3478563840.0000 - mae: 28459.3574\n",
      "Epoch 744/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3477244416.0000 - mae: 28453.5703\n",
      "Epoch 745/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3475907072.0000 - mae: 28448.0000\n",
      "Epoch 746/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3474517248.0000 - mae: 28442.2246\n",
      "Epoch 747/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3473150208.0000 - mae: 28436.4570\n",
      "Epoch 748/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3471830784.0000 - mae: 28431.1445\n",
      "Epoch 749/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3470501888.0000 - mae: 28425.8223\n",
      "Epoch 750/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3469188096.0000 - mae: 28420.4766\n",
      "Epoch 751/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3467851520.0000 - mae: 28414.9844\n",
      "Epoch 752/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3466518528.0000 - mae: 28409.6367\n",
      "Epoch 753/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3465180672.0000 - mae: 28404.2402\n",
      "Epoch 754/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3463847680.0000 - mae: 28398.7168\n",
      "Epoch 755/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3462533376.0000 - mae: 28393.7305\n",
      "Epoch 756/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3461186816.0000 - mae: 28388.6250\n",
      "Epoch 757/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3459910400.0000 - mae: 28384.0820\n",
      "Epoch 758/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3458546176.0000 - mae: 28379.1914\n",
      "Epoch 759/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3457218816.0000 - mae: 28374.5293\n",
      "Epoch 760/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3455927040.0000 - mae: 28370.0625\n",
      "Epoch 761/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3454604800.0000 - mae: 28365.3457\n",
      "Epoch 762/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3453328128.0000 - mae: 28360.6816\n",
      "Epoch 763/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3451984128.0000 - mae: 28356.0234\n",
      "Epoch 764/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3450695424.0000 - mae: 28351.7109\n",
      "Epoch 765/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3449420544.0000 - mae: 28347.6699\n",
      "Epoch 766/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3448133632.0000 - mae: 28343.1055\n",
      "Epoch 767/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3446814464.0000 - mae: 28339.0215\n",
      "Epoch 768/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3445514752.0000 - mae: 28334.4258\n",
      "Epoch 769/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3444260352.0000 - mae: 28330.4180\n",
      "Epoch 770/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3442926592.0000 - mae: 28325.9512\n",
      "Epoch 771/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3441639680.0000 - mae: 28322.0117\n",
      "Epoch 772/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3440328960.0000 - mae: 28318.0176\n",
      "Epoch 773/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3439059200.0000 - mae: 28314.1445\n",
      "Epoch 774/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3437815552.0000 - mae: 28310.1504\n",
      "Epoch 775/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3436535040.0000 - mae: 28306.2363\n",
      "Epoch 776/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3435255808.0000 - mae: 28302.3418\n",
      "Epoch 777/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3433971456.0000 - mae: 28298.3457\n",
      "Epoch 778/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3432679936.0000 - mae: 28294.3008\n",
      "Epoch 779/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3431431936.0000 - mae: 28290.4980\n",
      "Epoch 780/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3430198784.0000 - mae: 28286.8672\n",
      "Epoch 781/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3428955392.0000 - mae: 28283.4707\n",
      "Epoch 782/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3427678720.0000 - mae: 28279.5820\n",
      "Epoch 783/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3426417664.0000 - mae: 28275.6543\n",
      "Epoch 784/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3425178112.0000 - mae: 28271.9766\n",
      "Epoch 785/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3423928832.0000 - mae: 28268.2246\n",
      "Epoch 786/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3422661376.0000 - mae: 28264.6191\n",
      "Epoch 787/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3421420544.0000 - mae: 28261.4902\n",
      "Epoch 788/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3420139520.0000 - mae: 28257.9785\n",
      "Epoch 789/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3418920704.0000 - mae: 28255.0391\n",
      "Epoch 790/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3417702912.0000 - mae: 28251.8418\n",
      "Epoch 791/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3416465664.0000 - mae: 28248.4238\n",
      "Epoch 792/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3415239680.0000 - mae: 28245.4688\n",
      "Epoch 793/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 3414002176.0000 - mae: 28242.0996\n",
      "Epoch 794/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3412768000.0000 - mae: 28239.0605\n",
      "Epoch 795/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3411537664.0000 - mae: 28236.0234\n",
      "Epoch 796/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3410333184.0000 - mae: 28233.0273\n",
      "Epoch 797/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3409086976.0000 - mae: 28230.3242\n",
      "Epoch 798/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3407881728.0000 - mae: 28227.4414\n",
      "Epoch 799/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3406615552.0000 - mae: 28224.2227\n",
      "Epoch 800/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3405411840.0000 - mae: 28221.5137\n",
      "Epoch 801/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3404207616.0000 - mae: 28218.6309\n",
      "Epoch 802/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3403024384.0000 - mae: 28215.8281\n",
      "Epoch 803/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3401833728.0000 - mae: 28213.3809\n",
      "Epoch 804/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3400642304.0000 - mae: 28210.6484\n",
      "Epoch 805/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3399424000.0000 - mae: 28207.8789\n",
      "Epoch 806/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3398247424.0000 - mae: 28205.3066\n",
      "Epoch 807/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3397089536.0000 - mae: 28202.9492\n",
      "Epoch 808/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3395866624.0000 - mae: 28200.0664\n",
      "Epoch 809/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3394695936.0000 - mae: 28197.5586\n",
      "Epoch 810/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3393495040.0000 - mae: 28194.7656\n",
      "Epoch 811/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3392297216.0000 - mae: 28192.6211\n",
      "Epoch 812/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3391156224.0000 - mae: 28190.0723\n",
      "Epoch 813/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3389999360.0000 - mae: 28187.5645\n",
      "Epoch 814/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3388830720.0000 - mae: 28185.2070\n",
      "Epoch 815/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3387641600.0000 - mae: 28182.7949\n",
      "Epoch 816/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3386480384.0000 - mae: 28180.3223\n",
      "Epoch 817/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3385333248.0000 - mae: 28178.3066\n",
      "Epoch 818/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3384156928.0000 - mae: 28176.3359\n",
      "Epoch 819/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3382962432.0000 - mae: 28174.3848\n",
      "Epoch 820/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3381831168.0000 - mae: 28172.2520\n",
      "Epoch 821/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3380697088.0000 - mae: 28170.7383\n",
      "Epoch 822/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3379503872.0000 - mae: 28168.5859\n",
      "Epoch 823/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3378335488.0000 - mae: 28166.7324\n",
      "Epoch 824/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3377237760.0000 - mae: 28164.9434\n",
      "Epoch 825/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3376075008.0000 - mae: 28162.9219\n",
      "Epoch 826/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3374946560.0000 - mae: 28161.3027\n",
      "Epoch 827/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3373808128.0000 - mae: 28159.5586\n",
      "Epoch 828/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3372659968.0000 - mae: 28158.0234\n",
      "Epoch 829/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3371530752.0000 - mae: 28156.0098\n",
      "Epoch 830/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3370404608.0000 - mae: 28154.5684\n",
      "Epoch 831/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3369266688.0000 - mae: 28152.9375\n",
      "Epoch 832/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3368156672.0000 - mae: 28150.8438\n",
      "Epoch 833/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3367000064.0000 - mae: 28149.4590\n",
      "Epoch 834/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3365840384.0000 - mae: 28148.0879\n",
      "Epoch 835/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3364753664.0000 - mae: 28146.8789\n",
      "Epoch 836/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3363603456.0000 - mae: 28145.3672\n",
      "Epoch 837/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3362473472.0000 - mae: 28144.0664\n",
      "Epoch 838/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3361340672.0000 - mae: 28142.3672\n",
      "Epoch 839/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3360223488.0000 - mae: 28141.3867\n",
      "Epoch 840/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3359129088.0000 - mae: 28139.7715\n",
      "Epoch 841/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3358018304.0000 - mae: 28138.5801\n",
      "Epoch 842/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3356925184.0000 - mae: 28137.5430\n",
      "Epoch 843/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3355816704.0000 - mae: 28136.3750\n",
      "Epoch 844/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3354716672.0000 - mae: 28135.3008\n",
      "Epoch 845/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3353625600.0000 - mae: 28133.9375\n",
      "Epoch 846/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3352553984.0000 - mae: 28132.9707\n",
      "Epoch 847/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3351459072.0000 - mae: 28131.9570\n",
      "Epoch 848/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3350369536.0000 - mae: 28130.9102\n",
      "Epoch 849/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3349310720.0000 - mae: 28129.9551\n",
      "Epoch 850/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3348229632.0000 - mae: 28129.2578\n",
      "Epoch 851/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3347104512.0000 - mae: 28128.4199\n",
      "Epoch 852/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3346020864.0000 - mae: 28127.6699\n",
      "Epoch 853/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3344968192.0000 - mae: 28127.2754\n",
      "Epoch 854/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3343905280.0000 - mae: 28126.4707\n",
      "Epoch 855/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3342852352.0000 - mae: 28125.9902\n",
      "Epoch 856/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3341753088.0000 - mae: 28125.1055\n",
      "Epoch 857/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3340715008.0000 - mae: 28124.7383\n",
      "Epoch 858/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3339583488.0000 - mae: 28124.1680\n",
      "Epoch 859/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3338540544.0000 - mae: 28123.5918\n",
      "Epoch 860/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3337481984.0000 - mae: 28123.1133\n",
      "Epoch 861/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3336433920.0000 - mae: 28122.5371\n",
      "Epoch 862/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3335379712.0000 - mae: 28122.3340\n",
      "Epoch 863/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3334288384.0000 - mae: 28121.3633\n",
      "Epoch 864/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3333250816.0000 - mae: 28120.8652\n",
      "Epoch 865/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 3332173824.0000 - mae: 28120.5293\n",
      "Epoch 866/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3331150336.0000 - mae: 28120.2363\n",
      "Epoch 867/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3330072576.0000 - mae: 28119.8105\n",
      "Epoch 868/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3329057536.0000 - mae: 28119.6699\n",
      "Epoch 869/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3328025088.0000 - mae: 28119.3809\n",
      "Epoch 870/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3326969856.0000 - mae: 28118.9941\n",
      "Epoch 871/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3325954048.0000 - mae: 28118.9180\n",
      "Epoch 872/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3324929280.0000 - mae: 28118.2949\n",
      "Epoch 873/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3323885824.0000 - mae: 28118.0547\n",
      "Epoch 874/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3322844928.0000 - mae: 28118.2168\n",
      "Epoch 875/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3321803264.0000 - mae: 28117.8887\n",
      "Epoch 876/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3320781824.0000 - mae: 28117.6855\n",
      "Epoch 877/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3319776256.0000 - mae: 28117.7949\n",
      "Epoch 878/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3318708736.0000 - mae: 28117.3984\n",
      "Epoch 879/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3317669376.0000 - mae: 28117.2051\n",
      "Epoch 880/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3316630528.0000 - mae: 28117.1836\n",
      "Epoch 881/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3315616512.0000 - mae: 28117.3223\n",
      "Epoch 882/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3314634496.0000 - mae: 28118.0488\n",
      "Epoch 883/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3313618688.0000 - mae: 28118.7754\n",
      "Epoch 884/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3312609792.0000 - mae: 28118.9941\n",
      "Epoch 885/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3311615232.0000 - mae: 28119.7949\n",
      "Epoch 886/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3310592256.0000 - mae: 28120.2441\n",
      "Epoch 887/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3309598208.0000 - mae: 28120.5938\n",
      "Epoch 888/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3308627712.0000 - mae: 28121.2832\n",
      "Epoch 889/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3307618048.0000 - mae: 28122.1504\n",
      "Epoch 890/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3306604032.0000 - mae: 28122.5859\n",
      "Epoch 891/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3305598720.0000 - mae: 28123.1797\n",
      "Epoch 892/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3304612096.0000 - mae: 28124.0840\n",
      "Epoch 893/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3303633920.0000 - mae: 28124.9258\n",
      "Epoch 894/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3302657280.0000 - mae: 28125.3926\n",
      "Epoch 895/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3301657856.0000 - mae: 28126.5156\n",
      "Epoch 896/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3300664320.0000 - mae: 28126.9609\n",
      "Epoch 897/100000\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 3299715840.0000 - mae: 28127.9766\n",
      "Epoch 898/100000\n",
      "154/167 [==========================>...] - ETA: 0s - loss: 3357414144.0000 - mae: 28231.5938"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13500/3840481533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"mae\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: 200-100-50-25-1\n",
    "#7k Epochs - MAE 28117"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "44c84064d006807177f4d43dc2fb94f3cbd405eecc9890b8e78f4aa6080cdef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
