{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>engine string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Chevrolet Suburban</td>\n",
       "      <td>$17,000</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>60069</td>\n",
       "      <td>5.7L Vortec V8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Porsche 964 911</td>\n",
       "      <td>$225,000</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>84790</td>\n",
       "      <td>3.8-Liter Flat-Six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Toyota Pickup</td>\n",
       "      <td>$24,750</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>90027</td>\n",
       "      <td>3.4-Liter DOHC V6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Volkswagen Golf/Rabbit Cabriolet</td>\n",
       "      <td>$10,750</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>98208</td>\n",
       "      <td>1.8-Liter Inline-Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Toyota FJ Cruiser</td>\n",
       "      <td>$32,500</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>57108</td>\n",
       "      <td>4.0-Liter V6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year        make                             model final_price  \\\n",
       "0           1  1997   Chevrolet                Chevrolet Suburban     $17,000   \n",
       "1           2  1990     Porsche                   Porsche 964 911    $225,000   \n",
       "2           3  2003      Toyota                     Toyota Pickup     $24,750   \n",
       "3           5  1992  Volkswagen  Volkswagen Golf/Rabbit Cabriolet     $10,750   \n",
       "4           6  2008      Toyota                 Toyota FJ Cruiser     $32,500   \n",
       "\n",
       "   mileage  engine  zipcode          engine string  \n",
       "0    67000  5700.0    60069         5.7L Vortec V8  \n",
       "1     1000  3800.0    84790    3.8-Liter Flat-Six   \n",
       "2   116000  3400.0    90027      3.4-Liter DOHC V6  \n",
       "3   100000  1800.0    98208  1.8-Liter Inline-Four  \n",
       "4     9000  4000.0    57108           4.0-Liter V6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = \"data.sqlite\"\n",
    "\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "train_df = pd.read_sql(\"select * from new_table_name\", con=conn)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['final_price']=(train_df['final_price'].replace( '[\\$,)]','', regex=True )\n",
    "               .replace( '[(]','-',   regex=True ).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>1983</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>39962.0</td>\n",
       "      <td>24000</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>1997</td>\n",
       "      <td>Ford</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>75000</td>\n",
       "      <td>7300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>1972</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>2005</td>\n",
       "      <td>Ford</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>22000</td>\n",
       "      <td>3900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>1974</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>98000</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7105 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        make  final_price  mileage  engine\n",
       "0     1997   Chevrolet      17000.0    67000  5700.0\n",
       "1     1990     Porsche     225000.0     1000  3800.0\n",
       "2     2003      Toyota      24750.0   116000  3400.0\n",
       "3     1992  Volkswagen      10750.0   100000  1800.0\n",
       "4     2008      Toyota      32500.0     9000  4000.0\n",
       "...    ...         ...          ...      ...     ...\n",
       "7100  1983        Jeep      39962.0    24000  4200.0\n",
       "7101  1997        Ford      24900.0    75000  7300.0\n",
       "7102  1972       Honda       2400.0     5000   174.0\n",
       "7103  2005        Ford      17750.0    22000  3900.0\n",
       "7104  1974  Volkswagen       9900.0    98000  1600.0\n",
       "\n",
       "[7105 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(['model', 'engine string', 'Unnamed: 0', 'zipcode'], axis='columns')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Porsche          1108\n",
       "BMW               796\n",
       "Chevrolet         782\n",
       "Mercedes-Benz     734\n",
       "Ford              697\n",
       "                 ... \n",
       "Alpine              1\n",
       "Nash                1\n",
       "Bricklin            1\n",
       "Opel                1\n",
       "Renault             1\n",
       "Name: make, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.make.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other            1547\n",
       "Porsche          1108\n",
       "BMW               796\n",
       "Chevrolet         782\n",
       "Mercedes-Benz     734\n",
       "Ford              697\n",
       "Toyota            315\n",
       "Honda             200\n",
       "Land Rover        174\n",
       "Volkswagen        168\n",
       "Jaguar            163\n",
       "Jeep              161\n",
       "Ferrari           150\n",
       "Pontiac           110\n",
       "Name: make, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1 = train_df.apply(lambda x: x.mask(x.map(x.value_counts())<100, 'other') if x.name=='make' else x)\n",
    "train_df1.make.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>make_AMC</th>\n",
       "      <th>make_Acura</th>\n",
       "      <th>make_Alfa Romeo</th>\n",
       "      <th>make_Alpine</th>\n",
       "      <th>make_Amphicar</th>\n",
       "      <th>make_Ariel</th>\n",
       "      <th>...</th>\n",
       "      <th>make_Saab</th>\n",
       "      <th>make_Shelby</th>\n",
       "      <th>make_Studebaker</th>\n",
       "      <th>make_Subaru</th>\n",
       "      <th>make_Sunbeam</th>\n",
       "      <th>make_Toyota</th>\n",
       "      <th>make_Triumph</th>\n",
       "      <th>make_Volkswagen</th>\n",
       "      <th>make_Volvo</th>\n",
       "      <th>make_Willys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  final_price  mileage  engine  make_AMC  make_Acura  make_Alfa Romeo  \\\n",
       "0  1997      17000.0    67000  5700.0         0           0                0   \n",
       "1  1990     225000.0     1000  3800.0         0           0                0   \n",
       "2  2003      24750.0   116000  3400.0         0           0                0   \n",
       "3  1992      10750.0   100000  1800.0         0           0                0   \n",
       "4  2008      32500.0     9000  4000.0         0           0                0   \n",
       "\n",
       "   make_Alpine  make_Amphicar  make_Ariel  ...  make_Saab  make_Shelby  \\\n",
       "0            0              0           0  ...          0            0   \n",
       "1            0              0           0  ...          0            0   \n",
       "2            0              0           0  ...          0            0   \n",
       "3            0              0           0  ...          0            0   \n",
       "4            0              0           0  ...          0            0   \n",
       "\n",
       "   make_Studebaker  make_Subaru  make_Sunbeam  make_Toyota  make_Triumph  \\\n",
       "0                0            0             0            0             0   \n",
       "1                0            0             0            0             0   \n",
       "2                0            0             0            1             0   \n",
       "3                0            0             0            0             0   \n",
       "4                0            0             0            1             0   \n",
       "\n",
       "   make_Volkswagen  make_Volvo  make_Willys  \n",
       "0                0           0            0  \n",
       "1                0           0            0  \n",
       "2                0           0            0  \n",
       "3                1           0            0  \n",
       "4                0           0            0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "train_df2 = pd.get_dummies(train_df)\n",
    "train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df2.drop(columns='final_price')\n",
    "train_y = train_df2['final_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.26766515342975683\n",
      "Model Score: -1.8699450895005813e+23\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(f'Model Score: {model.score(X_train_scaled, y_train)}')\n",
    "print(f'Model Score: {model.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_train_scaled)\n",
    "# Plot Residuals\n",
    "plt.scatter(predictions, predictions - y_train)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight coefficients:  [ 1.08379186e+03 -4.53666078e+03  8.70350220e+03 -1.96530209e+16\n",
      " -6.40114788e+16 -7.15129349e+16  3.41018366e+16 -1.60481310e+16\n",
      " -1.13488075e+16 -6.19905497e+16 -7.74668498e+16 -5.06628174e+16\n",
      " -2.59008119e+17 -5.77318425e+16 -1.13488075e+16 -6.19905497e+16\n",
      " -9.09457159e+16 -2.59782496e+17 -4.53312722e+16 -2.26912229e+16\n",
      " -9.09457159e+16 -2.26912229e+16 -3.00092079e+16 -9.82376665e+16\n",
      " -1.19364521e+17 -5.31255998e+16 -2.45229003e+17 -6.69258433e+16\n",
      " -1.60481310e+16 -1.35698281e+17 -4.93846575e+16 -5.88260472e+16\n",
      " -1.60481310e+16 -1.21412206e+17 -1.20903836e+17 -1.60481310e+16\n",
      " -4.38959467e+16 -1.13488075e+16 -1.29721587e+17 -8.59662905e+16\n",
      " -5.19090492e+16 -6.49978266e+16 -7.58150534e+16 -4.24115042e+16\n",
      " -8.81364309e+16 -4.08725933e+16 -2.51252268e+17 -3.20781780e+16\n",
      " -5.88260472e+16 -5.31255998e+16 -1.96530209e+16 -1.60481310e+16\n",
      " -1.13488075e+16 -6.78687813e+16 -6.40114788e+16  2.72848411e-12\n",
      " -5.31255998e+16 -1.04996685e+17 -3.01469332e+17 -1.13488075e+16\n",
      " -3.00092079e+16 -5.54774207e+16 -6.78687813e+16 -2.26912229e+16\n",
      " -3.58577512e+16 -1.96530209e+16 -1.65548700e+17 -9.29942746e+16\n",
      " -1.29249086e+17 -6.49978266e+16 -3.00092079e+16]\n",
      "y-axis intercept:  46341.16803601453\n",
      "True output: 17000.0\n",
      "Predicted output: 36143.91803601453\n",
      "Prediction Error: 19143.918036014533\n",
      "Actual Min Value: 0.0\n",
      "Calculated Min Value: [-4.18608602e+03  1.80510261e+04 -3.43331871e+04  7.77564475e+16\n",
      "  2.53259039e+17  2.82938271e+17 -1.34922650e+17  6.34938345e+16\n",
      "  4.49011356e+16  2.45263308e+17  3.06494715e+17  2.00445556e+17\n",
      "  1.02475601e+18  2.28413891e+17  4.49011356e+16  2.45263308e+17\n",
      "  3.59823348e+17  1.02781980e+18  1.79351495e+17  8.97769808e+16\n",
      "  3.59823348e+17  8.97769808e+16  1.18730317e+17  3.88673680e+17\n",
      "  4.72261297e+17  2.10189463e+17  9.70239445e+17  2.64789614e+17\n",
      "  6.34938345e+16  5.36885210e+17  1.95388564e+17  2.32743071e+17\n",
      "  6.34938345e+16  4.80362885e+17  4.78351539e+17  6.34938345e+16\n",
      "  1.73672683e+17  4.49011356e+16  5.13238644e+17  3.40122436e+17\n",
      "  2.05376226e+17  2.57161487e+17  2.99959444e+17  1.67799542e+17\n",
      "  3.48708516e+17  1.61710898e+17  9.94070267e+17  1.26916120e+17\n",
      "  2.32743071e+17  2.10189463e+17  7.77564475e+16  6.34938345e+16\n",
      "  4.49011356e+16  2.68520313e+17  2.53259039e+17  1.01896225e+02\n",
      "  2.10189463e+17  4.15415487e+17  1.19275222e+18  4.49011356e+16\n",
      "  1.18730317e+17  2.19494355e+17  2.68520313e+17  8.97769808e+16\n",
      "  1.41869861e+17  7.77564475e+16  6.54987285e+17  3.67928395e+17\n",
      "  5.11369208e+17  2.57161487e+17  1.18730317e+17]\n",
      "Actual Max Value: 1300000.0\n",
      "Calculated Max Value: [ 7.92038540e+04 -3.31012189e+05  6.35338320e+05 -1.43440128e+18\n",
      " -4.67196100e+18 -5.21946452e+18  2.48896688e+18 -1.17129371e+18\n",
      " -8.28307473e+17 -4.52446086e+18 -5.65401874e+18 -3.69769159e+18\n",
      " -1.89040443e+19 -4.21363358e+18 -8.28307473e+17 -4.52446086e+18\n",
      " -6.63779131e+18 -1.89605632e+19 -3.30856183e+18 -1.65614840e+18\n",
      " -6.63779131e+18 -1.65614840e+18 -2.19026105e+18 -7.17000380e+18\n",
      " -8.71197478e+18 -3.87744097e+18 -1.78983576e+19 -4.88466968e+18\n",
      " -1.17129371e+18 -9.90411546e+18 -3.60440343e+18 -4.29349553e+18\n",
      " -1.17129371e+18 -8.86142770e+18 -8.82432367e+18 -1.17129371e+18\n",
      " -3.20380274e+18 -8.28307473e+17 -9.46789871e+18 -6.27436148e+18\n",
      " -3.78864944e+18 -4.74395088e+18 -5.53346024e+18 -3.09545877e+18\n",
      " -6.43275199e+18 -2.98313936e+18 -1.83379734e+19 -2.34126752e+18\n",
      " -4.29349553e+18 -3.87744097e+18 -1.43440128e+18 -1.17129371e+18\n",
      " -8.28307473e+17 -4.95349124e+18 -4.67196100e+18  1.01896225e+02\n",
      " -3.87744097e+18 -7.66331958e+18 -2.20031312e+19 -8.28307473e+17\n",
      " -2.19026105e+18 -4.04909168e+18 -4.95349124e+18 -1.65614840e+18\n",
      " -2.61712459e+18 -1.43440128e+18 -1.20827871e+19 -6.78730803e+18\n",
      " -9.43341255e+18 -4.74395088e+18 -2.19026105e+18]\n"
     ]
    }
   ],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)\n",
    "print(f\"True output: {train_y[0]}\")\n",
    "print(f\"Predicted output: {predictions[0]}\")\n",
    "print(f\"Prediction Error: {predictions[0]-y_train[0]}\")\n",
    "\n",
    "x_min = X_train_scaled.min()\n",
    "x_max = X_train_scaled.max()\n",
    "y_min_actual = y_train.min()\n",
    "y_max_actual = y_train.max()\n",
    "\n",
    "y_min = 101.896225057 + (model.coef_ * x_min)\n",
    "y_max = 101.896225057 + (model.coef_ * x_max)\n",
    "print(f\"Actual Min Value: {y_min_actual}\")\n",
    "print(f\"Calculated Min Value: {y_min}\")\n",
    "print(f\"Actual Max Value: {y_max_actual}\")\n",
    "print(f\"Calculated Max Value: {y_max}\")\n",
    "\n",
    "# y_min_predicted = model.predict([[x_min]])\n",
    "# y_max_predicted = model.predict([[x_max]])\n",
    "# print(f\"Actual Min Value: {y_min_actual}\")\n",
    "# print(f\"Predicted Min Value: {y_min_predicted}\")\n",
    "# print(f\"Actual Max Value: {y_max_actual}\")\n",
    "# print(f\"Predicted Max Value: {y_max_predicted}\")\n",
    "\n",
    "# plt.scatter(X, y, c='blue')\n",
    "# plt.plot([x_min, x_max], [y_min, y_max], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.26804787330373536\n",
      "Test Score: 0.06990602541123325\n"
     ]
    }
   ],
   "source": [
    "reg = Lasso(max_iter=10000).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.2679359935686624\n",
      "Test Score: 0.07191953465417744\n"
     ]
    }
   ],
   "source": [
    "reg = Ridge(alpha=100).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.08950727765164945\n",
      "Test Score: 0.03896535884460828\n"
     ]
    }
   ],
   "source": [
    "reg = ElasticNet(alpha=10).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "    print(mean_absolute_error(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsRegressor\n",
      "Train score: 0.6052034645832656\n",
      "Test Score: 0.23028774481921122\n",
      "\n",
      "21344.75171637591\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9077038976420624\n",
      "Test Score: 0.4208723648046665\n",
      "\n",
      "18518.667192459197\n",
      "Model: ExtraTreesRegressor\n",
      "Train score: 0.9932830981738487\n",
      "Test Score: 0.44610637652255036\n",
      "\n",
      "18116.381625398615\n",
      "Model: AdaBoostRegressor\n",
      "Train score: -3.9322222889221097\n",
      "Test Score: -2.729906415227875\n",
      "\n",
      "113990.48609678543\n",
      "Model: SVR\n",
      "Train score: -0.08710783142007417\n",
      "Test Score: -0.0732446822790187\n",
      "\n",
      "29266.79350581873\n"
     ]
    }
   ],
   "source": [
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 729)               52488     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 486)               354780    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 324)               157788    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 216)               70200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 217       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 635,473\n",
      "Trainable params: 635,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = tf.keras.models.Sequential()\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=729, activation=\"sigmoid\", input_dim=71))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=486, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=324, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=216, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1))\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 3198645504.0000 - mae: 31894.5020\n",
      "Epoch 2/100000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2708729600.0000 - mae: 29117.8164\n",
      "Epoch 3/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2604698880.0000 - mae: 28220.8867\n",
      "Epoch 4/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2549538816.0000 - mae: 27788.5625\n",
      "Epoch 5/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2507505408.0000 - mae: 27249.1445\n",
      "Epoch 6/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2487309312.0000 - mae: 27146.2559\n",
      "Epoch 7/100000\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2473211904.0000 - mae: 26771.0215\n",
      "Epoch 8/100000\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2445581312.0000 - mae: 26560.1270\n",
      "Epoch 9/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2427745024.0000 - mae: 26599.7598\n",
      "Epoch 10/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2420159488.0000 - mae: 26239.0059\n",
      "Epoch 11/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2394065152.0000 - mae: 26171.9492\n",
      "Epoch 12/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2399633920.0000 - mae: 25999.7500\n",
      "Epoch 13/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2389658112.0000 - mae: 25886.1973\n",
      "Epoch 14/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2376740096.0000 - mae: 25926.7812\n",
      "Epoch 15/100000\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2375147264.0000 - mae: 25862.6035\n",
      "Epoch 16/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2364637952.0000 - mae: 25730.9883\n",
      "Epoch 17/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2355056128.0000 - mae: 25652.1582\n",
      "Epoch 18/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2357224192.0000 - mae: 25510.7832\n",
      "Epoch 19/100000\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2352128000.0000 - mae: 25652.9160\n",
      "Epoch 20/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2352519424.0000 - mae: 25440.6660\n",
      "Epoch 21/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2339996928.0000 - mae: 25410.5312\n",
      "Epoch 22/100000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2343560448.0000 - mae: 25370.3418\n",
      "Epoch 23/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2334601472.0000 - mae: 25493.9180\n",
      "Epoch 24/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2330361856.0000 - mae: 25277.3281\n",
      "Epoch 25/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2320907264.0000 - mae: 25219.5020\n",
      "Epoch 26/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2319066624.0000 - mae: 25248.6133\n",
      "Epoch 27/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2304464896.0000 - mae: 25170.5059\n",
      "Epoch 28/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2296895232.0000 - mae: 25192.5547\n",
      "Epoch 29/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2299706880.0000 - mae: 25068.4707\n",
      "Epoch 30/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2285024768.0000 - mae: 25041.7402\n",
      "Epoch 31/100000\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2277582336.0000 - mae: 25069.2383\n",
      "Epoch 32/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2271325952.0000 - mae: 24841.4316\n",
      "Epoch 33/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2264042496.0000 - mae: 24933.9746\n",
      "Epoch 34/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2262379264.0000 - mae: 24704.1543\n",
      "Epoch 35/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2254792960.0000 - mae: 24783.6113\n",
      "Epoch 36/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2241150464.0000 - mae: 24627.2754\n",
      "Epoch 37/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2228494336.0000 - mae: 24562.1875\n",
      "Epoch 38/100000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2213626112.0000 - mae: 24465.2578\n",
      "Epoch 39/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2210401024.0000 - mae: 24359.8145\n",
      "Epoch 40/100000\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 2196458240.0000 - mae: 24411.4844\n",
      "Epoch 41/100000\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 2181022720.0000 - mae: 24262.8105\n",
      "Epoch 42/100000\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2168635904.0000 - mae: 23730.2090\n",
      "Epoch 43/100000\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 2139061376.0000 - mae: 23801.5645\n",
      "Epoch 44/100000\n",
      " 13/167 [=>............................] - ETA: 1s - loss: 1678851968.0000 - mae: 22800.3887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12388/3840481533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"mae\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: 200-100-50-25-1\n",
    "#7k Epochs - MAE 28117"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "44c84064d006807177f4d43dc2fb94f3cbd405eecc9890b8e78f4aa6080cdef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
