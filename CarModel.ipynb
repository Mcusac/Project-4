{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow import keras\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>engine string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Chevrolet Suburban</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>60069</td>\n",
       "      <td>5.7L Vortec V8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Porsche 964 911</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>84790</td>\n",
       "      <td>3.8-Liter Flat-Six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Toyota Pickup</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>90027</td>\n",
       "      <td>3.4-Liter DOHC V6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Volkswagen Golf/Rabbit Cabriolet</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>98208</td>\n",
       "      <td>1.8-Liter Inline-Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Toyota FJ Cruiser</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>57108</td>\n",
       "      <td>4.0-Liter V6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year        make                             model  \\\n",
       "0           1  1997   Chevrolet                Chevrolet Suburban   \n",
       "1           2  1990     Porsche                   Porsche 964 911   \n",
       "2           3  2003      Toyota                     Toyota Pickup   \n",
       "3           5  1992  Volkswagen  Volkswagen Golf/Rabbit Cabriolet   \n",
       "4           6  2008      Toyota                 Toyota FJ Cruiser   \n",
       "\n",
       "   final_price  mileage  engine  zipcode          engine string  \n",
       "0      17000.0    67000  5700.0    60069         5.7L Vortec V8  \n",
       "1     225000.0     1000  3800.0    84790    3.8-Liter Flat-Six   \n",
       "2      24750.0   116000  3400.0    90027      3.4-Liter DOHC V6  \n",
       "3      10750.0   100000  1800.0    98208  1.8-Liter Inline-Four  \n",
       "4      32500.0     9000  4000.0    57108           4.0-Liter V6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = \"data.sqlite\"\n",
    "\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "train_df = pd.read_sql(\"select * from new_table_name\", con=conn)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['final_price']=(train_df['final_price'].replace( '[\\$,)]','', regex=True )\n",
    "               .replace( '[(]','-',   regex=True ).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>2009</td>\n",
       "      <td>Ford</td>\n",
       "      <td>115500.0</td>\n",
       "      <td>235000</td>\n",
       "      <td>5424.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>1983</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>39962.0</td>\n",
       "      <td>24000</td>\n",
       "      <td>4200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>1997</td>\n",
       "      <td>Ford</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>75000</td>\n",
       "      <td>7300.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>2005</td>\n",
       "      <td>Ford</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>22000</td>\n",
       "      <td>3900.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>1974</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>98000</td>\n",
       "      <td>1600.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        make  final_price  mileage    engine\n",
       "0     1997   Chevrolet      17000.0    67000  5700.000\n",
       "1     1990     Porsche     225000.0     1000  3800.000\n",
       "2     2003      Toyota      24750.0   116000  3400.000\n",
       "3     1992  Volkswagen      10750.0   100000  1800.000\n",
       "4     2008      Toyota      32500.0     9000  4000.000\n",
       "...    ...         ...          ...      ...       ...\n",
       "6995  2009        Ford     115500.0   235000  5424.097\n",
       "6996  1983        Jeep      39962.0    24000  4200.000\n",
       "6997  1997        Ford      24900.0    75000  7300.000\n",
       "6998  2005        Ford      17750.0    22000  3900.000\n",
       "6999  1974  Volkswagen       9900.0    98000  1600.000\n",
       "\n",
       "[7000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(['model', 'engine string', 'Unnamed: 0', 'zipcode'], axis='columns')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Porsche          1103\n",
       "BMW               785\n",
       "Chevrolet         782\n",
       "Mercedes-Benz     732\n",
       "Ford              691\n",
       "                 ... \n",
       "Alpine              1\n",
       "Nash                1\n",
       "Bricklin            1\n",
       "Opel                1\n",
       "Renault             1\n",
       "Name: make, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.make.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other            1528\n",
       "Porsche          1103\n",
       "BMW               785\n",
       "Chevrolet         782\n",
       "Mercedes-Benz     732\n",
       "Ford              691\n",
       "Toyota            313\n",
       "Land Rover        173\n",
       "Volkswagen        168\n",
       "Jaguar            162\n",
       "Jeep              161\n",
       "Honda             148\n",
       "Ferrari           145\n",
       "Pontiac           109\n",
       "Name: make, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1 = train_df.apply(lambda x: x.mask(x.map(x.value_counts())<100, 'other') if x.name=='make' else x)\n",
    "train_df1.make.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df1 = train_df1.query('make != \"other\"')\n",
    "#train_df1.make.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>final_price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>make_BMW</th>\n",
       "      <th>make_Chevrolet</th>\n",
       "      <th>make_Ferrari</th>\n",
       "      <th>make_Ford</th>\n",
       "      <th>make_Honda</th>\n",
       "      <th>make_Jaguar</th>\n",
       "      <th>make_Jeep</th>\n",
       "      <th>make_Land Rover</th>\n",
       "      <th>make_Mercedes-Benz</th>\n",
       "      <th>make_Pontiac</th>\n",
       "      <th>make_Porsche</th>\n",
       "      <th>make_Toyota</th>\n",
       "      <th>make_Volkswagen</th>\n",
       "      <th>make_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>67000</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>116000</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  final_price  mileage  engine  make_BMW  make_Chevrolet  make_Ferrari  \\\n",
       "0  1997      17000.0    67000  5700.0         0               1             0   \n",
       "1  1990     225000.0     1000  3800.0         0               0             0   \n",
       "2  2003      24750.0   116000  3400.0         0               0             0   \n",
       "3  1992      10750.0   100000  1800.0         0               0             0   \n",
       "4  2008      32500.0     9000  4000.0         0               0             0   \n",
       "\n",
       "   make_Ford  make_Honda  make_Jaguar  make_Jeep  make_Land Rover  \\\n",
       "0          0           0            0          0                0   \n",
       "1          0           0            0          0                0   \n",
       "2          0           0            0          0                0   \n",
       "3          0           0            0          0                0   \n",
       "4          0           0            0          0                0   \n",
       "\n",
       "   make_Mercedes-Benz  make_Pontiac  make_Porsche  make_Toyota  \\\n",
       "0                   0             0             0            0   \n",
       "1                   0             0             1            0   \n",
       "2                   0             0             0            1   \n",
       "3                   0             0             0            0   \n",
       "4                   0             0             0            1   \n",
       "\n",
       "   make_Volkswagen  make_other  \n",
       "0                0           0  \n",
       "1                0           0  \n",
       "2                0           0  \n",
       "3                1           0  \n",
       "4                0           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "train_df2 = pd.get_dummies(train_df1)\n",
    "train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df2.drop(columns='final_price')\n",
    "train_y = train_df2['final_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components = .7, svd_solver='full')\n",
    "#X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "#X_test_scaled = pca.fit_transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.1871078659464892\n",
      "Model Score: 0.19075679060654038\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(f'Model Score: {model.score(X_train_scaled, y_train)}')\n",
    "print(f'Model Score: {model.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_train_scaled)\n",
    "# Plot Residuals\n",
    "plt.scatter(predictions, predictions - y_train)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight coefficients:  [ 2345.84312497 -6448.33704443  7955.23657887 -2924.71790412\n",
      " -3079.68107037 10898.39904769 -2583.13063115 -2058.66430349\n",
      "  1318.01685687 -3063.4069118   -650.18611222 -2716.03201152\n",
      " -2251.25912576 10535.38432998  -743.98850917  -964.15138998\n",
      " -1656.56210124]\n",
      "y-axis intercept:  46027.88152380952\n",
      "True output: 17000.0\n",
      "Predicted output: 54414.3396533634\n",
      "Prediction Error: 37414.3396533634\n",
      "Actual Min Value: 5001.0\n",
      "Calculated Min Value: [ -8360.84252437  23364.57359444 -28596.99166744  10652.95280463\n",
      "  11211.98967194 -39214.58787654   9420.66074702   7528.62394943\n",
      "  -4652.91120785  11153.27988402   2447.47302328   9900.1086903\n",
      "   8223.41877522 -37904.99531021   2785.86955587   3580.11744177\n",
      "   6078.02145517]\n",
      "Actual Max Value: 456000.0\n",
      "Calculated Max Value: [ 19203.98779703 -52406.61271946  64881.01806356 -23713.94577738\n",
      " -24975.80364014  88847.05329942 -20932.41648469 -16661.71154681\n",
      "  10834.4462517  -24843.28392303  -5192.53907721 -22014.62625006\n",
      " -18230.00223603  85891.04131976  -5956.36763727  -7749.14374634\n",
      " -13387.4119967 ]\n"
     ]
    }
   ],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)\n",
    "print(f\"True output: {train_y[0]}\")\n",
    "print(f\"Predicted output: {predictions[0]}\")\n",
    "print(f\"Prediction Error: {predictions[0]-y_train[0]}\")\n",
    "\n",
    "x_min = X_train_scaled.min()\n",
    "x_max = X_train_scaled.max()\n",
    "y_min_actual = y_train.min()\n",
    "y_max_actual = y_train.max()\n",
    "\n",
    "y_min = 101.896225057 + (model.coef_ * x_min)\n",
    "y_max = 101.896225057 + (model.coef_ * x_max)\n",
    "print(f\"Actual Min Value: {y_min_actual}\")\n",
    "print(f\"Calculated Min Value: {y_min}\")\n",
    "print(f\"Actual Max Value: {y_max_actual}\")\n",
    "print(f\"Calculated Max Value: {y_max}\")\n",
    "\n",
    "# y_min_predicted = model.predict([[x_min]])\n",
    "# y_max_predicted = model.predict([[x_max]])\n",
    "# print(f\"Actual Min Value: {y_min_actual}\")\n",
    "# print(f\"Predicted Min Value: {y_min_predicted}\")\n",
    "# print(f\"Actual Max Value: {y_max_actual}\")\n",
    "# print(f\"Predicted Max Value: {y_max_predicted}\")\n",
    "\n",
    "# plt.scatter(X, y, c='blue')\n",
    "# plt.plot([x_min, x_max], [y_min, y_max], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.18710785703974975\n",
      "Test Score: 0.19075964334168272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austi\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1627116875.9433594, tolerance: 1167689835.442431\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "reg = Lasso(max_iter=10000).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.1870354854086308\n",
      "Test Score: 0.19052653081503468\n"
     ]
    }
   ],
   "source": [
    "reg = Ridge(alpha=100).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.06319884738040549\n",
      "Test Score: 0.06319746693197659\n"
     ]
    }
   ],
   "source": [
    "reg = ElasticNet(alpha=10).fit(X_train_scaled, y_train)\n",
    "print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {reg.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}')\n",
    "    plt.show()\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "    print(mean_absolute_error(y_test, y_pred))    \n",
    "    print(mean_squared_error(y_test, y_pred)) \n",
    "    print(np.median(abs(y_test - y_pred)))\n",
    "    print('\\n')\n",
    "    return [\n",
    "        mean_absolute_error(y_test, y_pred),\n",
    "        mean_squared_error(y_test, y_pred),\n",
    "        np.median(abs(y_test - y_pred)),\n",
    "        y_pred,\n",
    "        reg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsRegressor\n",
      "Train score: 0.6280663885287097\n",
      "Test Score: 0.384462354292179\n",
      "19360.708342857142\n",
      "1415707606.6670628\n",
      "9776.0\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9246360191508673\n",
      "Test Score: 0.47530862431035215\n",
      "17686.61953520635\n",
      "1206765462.5124774\n",
      "9200.44\n",
      "\n",
      "\n",
      "Model: ExtraTreesRegressor\n",
      "Train score: 0.9943194395002133\n",
      "Test Score: 0.49651947122202855\n",
      "17265.483067619047\n",
      "1157981513.1860628\n",
      "8728.354999999996\n",
      "\n",
      "\n",
      "Model: AdaBoostRegressor\n",
      "Train score: 0.08091815161308846\n",
      "Test Score: 0.04646273518377886\n",
      "32636.29476255387\n",
      "2193090818.1716714\n",
      "23918.74033149171\n",
      "\n",
      "\n",
      "Model: SVR\n",
      "Train score: -0.1128191395869853\n",
      "Test Score: -0.10426113870596976\n",
      "27036.75895635068\n",
      "2539748632.295571\n",
      "14374.605124445721\n",
      "\n",
      "\n",
      "Model: GradientBoostingRegressor\n",
      "Train score: 0.4807164316628737\n",
      "Test Score: 0.44209678876703407\n",
      "19686.44860167013\n",
      "1283151120.7056227\n",
      "12560.677607564849\n",
      "\n",
      "\n",
      "Model: SGDRegressor\n",
      "Train score: 0.18462034794846383\n",
      "Test Score: 0.19316047477391396\n",
      "26299.754277533502\n",
      "1855692923.3933582\n",
      "19206.580406295492\n",
      "\n",
      "\n",
      "Model: KernelRidge\n",
      "Train score: -0.7654114255096549\n",
      "Test Score: -0.7103644850850186\n",
      "45846.12023792501\n",
      "3933757794.6571546\n",
      "35661.01987854112\n",
      "\n",
      "\n",
      "Model: BayesianRidge\n",
      "Train score: 0.18706722068093617\n",
      "Test Score: 0.19059725347673218\n",
      "26032.950726622777\n",
      "1861588211.704796\n",
      "18338.20126821688\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26032.950726622777,\n",
       " 1861588211.704796,\n",
       " 18338.20126821688,\n",
       " array([25832.52784891, 46771.41332934, 37660.43740975, ...,\n",
       "        64616.85754417, 31967.64435528, 33319.65970014]),\n",
       " BayesianRidge()]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "test_model(SVR(C=1.0, epsilon=0.2), data)\n",
    "test_model(GradientBoostingRegressor(), data)\n",
    "test_model(SGDRegressor(), data)\n",
    "test_model(KernelRidge(), data)\n",
    "test_model(BayesianRidge(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.3927845154259746\n",
      "Test Score: 0.35788033331020574\n",
      "21777.147294054474\n",
      "1476845003.4894598\n",
      "15056.090387472177\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39242927615246226\n",
      "Test Score: 0.358185107855473\n",
      "21813.426325074706\n",
      "1476144036.3836102\n",
      "14775.19917853945\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3939856849667749\n",
      "Test Score: 0.3589618808413697\n",
      "21868.325446276955\n",
      "1474357495.0851932\n",
      "15015.641475843164\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39572957576857437\n",
      "Test Score: 0.3612470355313335\n",
      "21802.0443507964\n",
      "1469101746.8794553\n",
      "14985.733648062866\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3970025769941643\n",
      "Test Score: 0.36269015814714367\n",
      "21779.699345561265\n",
      "1465782632.8028398\n",
      "14990.560607758023\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39676711744672255\n",
      "Test Score: 0.3602583226615689\n",
      "21852.59723955945\n",
      "1471375739.933001\n",
      "15064.648842181658\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3967434427069596\n",
      "Test Score: 0.3596694444666201\n",
      "21850.63633446137\n",
      "1472730132.058004\n",
      "15121.748712676823\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3975451973362446\n",
      "Test Score: 0.3613889240130763\n",
      "21806.680175923244\n",
      "1468775410.0513148\n",
      "15045.001507024563\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39807016265942496\n",
      "Test Score: 0.36137423173306515\n",
      "21809.009177167653\n",
      "1468809201.6036527\n",
      "15028.384227813014\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3976359003190929\n",
      "Test Score: 0.3613867993139218\n",
      "21797.942552520257\n",
      "1468780296.7593427\n",
      "15087.85329423691\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3974497842686885\n",
      "Test Score: 0.3616533822525041\n",
      "21796.190487793876\n",
      "1468167168.5508726\n",
      "15059.171017115437\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39704494230770093\n",
      "Test Score: 0.3614499207635673\n",
      "21815.039098581197\n",
      "1468635120.3968081\n",
      "15109.401004083682\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.396593807802735\n",
      "Test Score: 0.36067663172260334\n",
      "21836.32874740014\n",
      "1470413648.7858984\n",
      "15072.75962060979\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3963923268178523\n",
      "Test Score: 0.36042724834494644\n",
      "21873.924608641497\n",
      "1470987218.8139653\n",
      "15112.833877251063\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3965648827695304\n",
      "Test Score: 0.3607209818630309\n",
      "21877.78936237565\n",
      "1470311645.5508435\n",
      "15132.950609949392\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39641702231305775\n",
      "Test Score: 0.36052551032572977\n",
      "21871.620002452255\n",
      "1470761220.8841698\n",
      "15101.57967027649\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3963560529978979\n",
      "Test Score: 0.36049127656188096\n",
      "21885.913187163897\n",
      "1470839956.9293551\n",
      "15133.354563540643\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39617942016779584\n",
      "Test Score: 0.36016776206811607\n",
      "21902.769392147533\n",
      "1471584025.0345047\n",
      "15164.360510971841\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3959129988127006\n",
      "Test Score: 0.36028839884990216\n",
      "21898.81159659815\n",
      "1471306566.1157703\n",
      "15155.488413993722\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39566832201665225\n",
      "Test Score: 0.3603282805147049\n",
      "21895.310256044195\n",
      "1471214840.1642847\n",
      "15172.514933886252\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39603404446253276\n",
      "Test Score: 0.36060606379904236\n",
      "21889.276540516174\n",
      "1470575951.6878707\n",
      "15177.083530671825\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3956955385971309\n",
      "Test Score: 0.360589567337501\n",
      "21883.942777603614\n",
      "1470613892.7727907\n",
      "15128.333243701287\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3960162728081529\n",
      "Test Score: 0.3608971990950821\n",
      "21868.327179666063\n",
      "1469906354.2131321\n",
      "15166.443735880457\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3959678152377921\n",
      "Test Score: 0.3607599190671513\n",
      "21868.1723097952\n",
      "1470222091.8144634\n",
      "15122.663378965468\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39590662693605416\n",
      "Test Score: 0.3608095387259346\n",
      "21865.64199723668\n",
      "1470107968.935271\n",
      "15159.978048841542\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3963749699913077\n",
      "Test Score: 0.36138047795239636\n",
      "21853.734246516357\n",
      "1468794835.5932522\n",
      "15109.73924457276\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.396613568175061\n",
      "Test Score: 0.3614256228531698\n",
      "21856.896559686138\n",
      "1468691004.446818\n",
      "15122.098484367445\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39686774040605943\n",
      "Test Score: 0.36128517186079934\n",
      "21861.23850319945\n",
      "1469014035.1170776\n",
      "15130.322889381336\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3968793713224048\n",
      "Test Score: 0.3611453314148879\n",
      "21873.07029165462\n",
      "1469335661.5592244\n",
      "15149.589586121067\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3968744558217874\n",
      "Test Score: 0.36096426132759496\n",
      "21878.53795526906\n",
      "1469752114.235528\n",
      "15127.66357468354\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39688743572354557\n",
      "Test Score: 0.36113833196491785\n",
      "21864.11257394123\n",
      "1469351759.9646335\n",
      "15110.22174053872\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3967412035034362\n",
      "Test Score: 0.3610890791332285\n",
      "21867.36313276123\n",
      "1469465039.1587796\n",
      "15081.639334491501\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3965661132470123\n",
      "Test Score: 0.3607212054007365\n",
      "21879.91831803205\n",
      "1470311131.4246445\n",
      "15087.183426708218\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3967008673198177\n",
      "Test Score: 0.3606904593819711\n",
      "21875.037278859247\n",
      "1470381845.820335\n",
      "15090.138203440783\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3968257984425143\n",
      "Test Score: 0.36110969538744553\n",
      "21860.576123233426\n",
      "1469417622.7446585\n",
      "15120.851714764165\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3968598190447751\n",
      "Test Score: 0.3609170332047753\n",
      "21865.141806113133\n",
      "1469860736.6945937\n",
      "15102.202978140338\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39692184824426835\n",
      "Test Score: 0.36101121384445833\n",
      "21866.98508046132\n",
      "1469644125.6571863\n",
      "15134.875787331637\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3969766686341324\n",
      "Test Score: 0.36129284423885555\n",
      "21854.102459827383\n",
      "1468996389.0087507\n",
      "15107.979028171314\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39729074267903686\n",
      "Test Score: 0.36129804323183934\n",
      "21856.463980628818\n",
      "1468984431.5696476\n",
      "15094.24482660935\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39724554532271916\n",
      "Test Score: 0.3612548746043095\n",
      "21858.72872786871\n",
      "1469083717.3806608\n",
      "15089.691706334579\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39718649388414407\n",
      "Test Score: 0.3610634284846814\n",
      "21864.227231387154\n",
      "1469524034.4428494\n",
      "15094.835627328826\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3972171138453666\n",
      "Test Score: 0.3608968788486264\n",
      "21868.515424355213\n",
      "1469907090.7649035\n",
      "15099.645117053591\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3972370001349147\n",
      "Test Score: 0.3609742823943145\n",
      "21874.10985632641\n",
      "1469729066.2538476\n",
      "15117.134678529752\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3974752341669504\n",
      "Test Score: 0.361024518642329\n",
      "21870.72077761776\n",
      "1469613525.248451\n",
      "15128.855352881148\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3974937539086133\n",
      "Test Score: 0.36143525708018687\n",
      "21859.68142937778\n",
      "1468668846.178242\n",
      "15154.25167688828\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39741011461197373\n",
      "Test Score: 0.36149841284576534\n",
      "21855.839949536177\n",
      "1468523590.890677\n",
      "15135.579460933646\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39724263866316833\n",
      "Test Score: 0.36129015603839876\n",
      "21856.50946853445\n",
      "1469002571.7432454\n",
      "15123.056798569132\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39717874190484315\n",
      "Test Score: 0.3612468597374364\n",
      "21862.952664805864\n",
      "1469102151.1971428\n",
      "15121.756054356354\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3971473464101133\n",
      "Test Score: 0.36121757635246077\n",
      "21860.064056464806\n",
      "1469169501.603975\n",
      "15108.984620076062\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.39718516020589845\n",
      "Test Score: 0.36102840758484833\n",
      "21861.611853405204\n",
      "1469604580.8637414\n",
      "15110.483313618626\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3971587367049688\n",
      "Test Score: 0.36093842834841017\n",
      "21858.645649399707\n",
      "1469811528.8714802\n",
      "15130.186661823576\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3971189216605482\n",
      "Test Score: 0.36072654138556937\n",
      "21866.04210579413\n",
      "1470298858.9107378\n",
      "15111.412199049693\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.3972196092253266\n",
      "Test Score: 0.3608078150795824\n",
      "21862.973465654097\n",
      "1470111933.2407346\n",
      "15127.106381159885\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30228/4235745803.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mval1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mmse_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmae_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30228/4149244468.py\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model: {type(reg).__name__}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train score: {reg.score(X_train_scaled, y_train)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mse_list = []\n",
    "mae_list = []\n",
    "median_list = []\n",
    "for i in range(5,30):\n",
    "    for j in range(10, 1001, 10):\n",
    "        val1, val2, val3, ypred, model = test_model(RandomForestRegressor(max_depth = i, n_estimators = j, n_jobs = -1, random_state=12), data)\n",
    "        mse_list.append(val2)\n",
    "        mae_list.append(val1)\n",
    "        median_list.append(val3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ExtraTreesRegressor\n",
      "Train score: 0.9762532400859892\n",
      "Test Score: 0.49999107233005213\n",
      "16951.671624611543\n",
      "1149996994.0746589\n",
      "8577.387154818865\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 69790.67370231, 174326.36130952,  88950.68527537, ...,\n",
       "        39525.43935185,  16490.27777778,  35004.03119845])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1, val2, val3, ypred1, model = test_model(ExtraTreesRegressor(max_depth = 19, n_estimators = 30, n_jobs = -1, random_state=12), data)\n",
    "y_train_pred1 = model.predict(X_train_scaled)\n",
    "y_train_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.8667658453496476\n",
      "Test Score: 0.31090086291147856\n",
      "19716.06561061078\n",
      "2966289197.249835\n",
      "8733.248887866965\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([31091.25395315, 31078.41296296, 54163.17359287, ...,\n",
       "       27478.36908928, 22366.32779146, 80118.27155844])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1, val2, val3, ypred2, model2 = test_model(RandomForestRegressor(max_depth = 14, n_estimators = 15, n_jobs = -1, random_state=12), data)\n",
    "y_train_pred2 = model2.predict(X_train_scaled)\n",
    "y_train_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18483.080015972097\n",
      "2531896079.775616\n",
      "8354.4532503546\n"
     ]
    }
   ],
   "source": [
    "ypred = (ypred1 + ypred2)/2\n",
    "print(mean_absolute_error(y_test, ypred))    \n",
    "print(mean_squared_error(y_test, ypred)) \n",
    "print(np.median(abs(y_test - ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18387.126078794576\n",
      "2618950168.6052322\n",
      "8318.465980455956\n"
     ]
    }
   ],
   "source": [
    "ypred_geo = (ypred1 * ypred2) ** (1/2)\n",
    "print(mean_absolute_error(y_test, ypred_geo))    \n",
    "print(mean_squared_error(y_test, ypred_geo)) \n",
    "print(np.median(abs(y_test - ypred_geo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = [y_train_pred1, y_train_pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Regressor_model.h5'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Regressor_model2.h5'\n",
    "pickle.dump(model2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(max_depth=21, n_estimators=37, n_jobs=-1, random_state=12)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = pickle.load(open(filename, 'rb'))\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17640.247114293583\n",
      "1154056169.9934208\n",
      "7882.603329108697\n"
     ]
    }
   ],
   "source": [
    "print(min(mae_list))\n",
    "print(min(mse_list))\n",
    "print(min(median_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n",
      "902\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "print(mae_list.index(17640.247114293583))\n",
    "print(mse_list.index(1154056169.9934208))\n",
    "print(median_list.index(7882.603329108697))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17640.247114293583\n",
      "1167380442.2911031\n",
      "8227.162527883453\n"
     ]
    }
   ],
   "source": [
    "print(mae_list[907])\n",
    "print(mse_list[907])\n",
    "print(median_list[907])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17140/3555719446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mypred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29624.714500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23580.253205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19688.299360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27549.826223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27178.731188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>66308.581725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>89865.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>58669.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>26093.942321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>16842.022008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0     29624.714500\n",
       "1     23580.253205\n",
       "2     19688.299360\n",
       "3     27549.826223\n",
       "4     27178.731188\n",
       "...            ...\n",
       "1385  66308.581725\n",
       "1386  89865.783784\n",
       "1387  58669.027027\n",
       "1388  26093.942321\n",
       "1389  16842.022008\n",
       "\n",
       "[1390 rows x 1 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_price1 = pd.DataFrame(data=ypred1)\n",
    "X_train_price1 = pd.DataFrame(data=y_train_pred1)\n",
    "X_test_price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_price2 = pd.DataFrame(data=ypred2)\n",
    "X_train_price2 = pd.DataFrame(data=y_train_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_price3 = pd.concat([X_test_price1, X_test_price2], axis=1)\n",
    "X_train_price3 = pd.concat([X_train_price1, X_train_price2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_df = pd.DataFrame(data=X_test_scaled)\n",
    "X_train_scaled_df = pd.DataFrame(data=X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4168, 18)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_price = pd.concat([X_test_price3, X_test_scaled_df], axis=1)\n",
    "X_train_price = pd.concat([X_train_price3, X_train_scaled_df], axis=1)\n",
    "\n",
    "X_train_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [X_train_price, X_test_price, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.9869005422480864\n",
      "Test Score: 0.5681275603331808\n",
      "17441.072024456553\n",
      "1132276326.9546764\n",
      "7849.58623079961\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881963929526026\n",
      "Test Score: 0.5691954549060614\n",
      "17434.934448286713\n",
      "1129476537.8653595\n",
      "7771.6068305517\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875213627443427\n",
      "Test Score: 0.5656383262981348\n",
      "17471.781766008327\n",
      "1138802561.3499694\n",
      "7774.167934742105\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9879446019468496\n",
      "Test Score: 0.5654468527165531\n",
      "17480.71261796157\n",
      "1139304563.7556548\n",
      "7806.698541310932\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9879338360019947\n",
      "Test Score: 0.5659764074038047\n",
      "17474.001540121924\n",
      "1137916185.6580265\n",
      "7818.676837692992\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881491811370824\n",
      "Test Score: 0.5665274482489747\n",
      "17468.937583419407\n",
      "1136471475.4916346\n",
      "7792.343874083046\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881184744169275\n",
      "Test Score: 0.5670004522823816\n",
      "17461.143817772663\n",
      "1135231361.003213\n",
      "7792.073114858842\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881379325591216\n",
      "Test Score: 0.5676146370753872\n",
      "17454.29329604574\n",
      "1133621101.0337825\n",
      "7752.927672218746\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9879251624488624\n",
      "Test Score: 0.5677044465113661\n",
      "17452.520608191036\n",
      "1133385640.075972\n",
      "7742.544057372779\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876647494310807\n",
      "Test Score: 0.5682121162250326\n",
      "17446.91461739049\n",
      "1132054639.6557088\n",
      "7721.490138633382\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876819382067692\n",
      "Test Score: 0.5682334806273643\n",
      "17446.49382328992\n",
      "1131998626.803816\n",
      "7711.124468793776\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9877977501602342\n",
      "Test Score: 0.5679908020763391\n",
      "17445.035354932632\n",
      "1132634877.5879536\n",
      "7684.222586108155\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9877961933212048\n",
      "Test Score: 0.5679117993744734\n",
      "17443.187632782807\n",
      "1132842005.6213078\n",
      "7732.99827819864\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9878039658098767\n",
      "Test Score: 0.5681000194550886\n",
      "17444.084278593928\n",
      "1132348533.192962\n",
      "7743.561181576217\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9877306322844768\n",
      "Test Score: 0.5682763142454799\n",
      "17443.017449618048\n",
      "1131886326.30178\n",
      "7768.051485891907\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876275956320736\n",
      "Test Score: 0.5682485376565476\n",
      "17444.32532767981\n",
      "1131959150.523015\n",
      "7750.768830010384\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876582618283657\n",
      "Test Score: 0.5681123452956752\n",
      "17447.052303785204\n",
      "1132316217.4991963\n",
      "7727.820224336627\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876652524321392\n",
      "Test Score: 0.5681771995787841\n",
      "17445.124835795785\n",
      "1132146183.566208\n",
      "7753.859806277051\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876408803500016\n",
      "Test Score: 0.5682824372859283\n",
      "17442.139173935655\n",
      "1131870273.0112433\n",
      "7735.473812532837\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987671368610282\n",
      "Test Score: 0.5682999510142199\n",
      "17441.454255550016\n",
      "1131824355.795603\n",
      "7733.706705186216\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9877081757127547\n",
      "Test Score: 0.5684713924254188\n",
      "17439.057984762956\n",
      "1131374873.4171722\n",
      "7730.804505698083\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9876449514267971\n",
      "Test Score: 0.568550037085841\n",
      "17437.71881336437\n",
      "1131168684.0912077\n",
      "7748.243039731409\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875422078827383\n",
      "Test Score: 0.5685809841146138\n",
      "17436.527388523322\n",
      "1131087547.6609783\n",
      "7759.724530623193\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875376448329378\n",
      "Test Score: 0.5684137647952152\n",
      "17437.842471136584\n",
      "1131525960.6259515\n",
      "7745.483157122917\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875195428465808\n",
      "Test Score: 0.568489015104779\n",
      "17437.829913600053\n",
      "1131328670.5553446\n",
      "7755.353137431395\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875256812948985\n",
      "Test Score: 0.5683714103865982\n",
      "17437.825420454086\n",
      "1131637004.744109\n",
      "7763.6846869436085\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875928241003962\n",
      "Test Score: 0.5683124480829869\n",
      "17438.372200998438\n",
      "1131791591.1785045\n",
      "7748.079950228217\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987483706434246\n",
      "Test Score: 0.5683678057082528\n",
      "17437.334805884795\n",
      "1131646455.4327424\n",
      "7769.936259119539\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874853917868528\n",
      "Test Score: 0.5683895874620131\n",
      "17437.762971556327\n",
      "1131589348.37548\n",
      "7750.435100369039\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875583336729944\n",
      "Test Score: 0.567656135221126\n",
      "17448.47547281534\n",
      "1133512301.852087\n",
      "7751.990019307916\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875531845671996\n",
      "Test Score: 0.5670443268389898\n",
      "17455.615569584417\n",
      "1135116331.3851125\n",
      "7752.257249926915\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875358547041347\n",
      "Test Score: 0.5671357065607213\n",
      "17455.36855206804\n",
      "1134876753.4769685\n",
      "7792.347514312431\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875112548987813\n",
      "Test Score: 0.5668804176785147\n",
      "17457.13445051507\n",
      "1135546065.8278108\n",
      "7791.764538834799\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.98748862778174\n",
      "Test Score: 0.5669747873705336\n",
      "17456.02416730402\n",
      "1135298648.8628907\n",
      "7797.948929921393\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875079907641793\n",
      "Test Score: 0.5668394502992691\n",
      "17456.540823895753\n",
      "1135653473.454315\n",
      "7784.455582175215\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875052436347661\n",
      "Test Score: 0.566784798644308\n",
      "17456.93123552729\n",
      "1135796758.298305\n",
      "7789.579986549732\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875190324525941\n",
      "Test Score: 0.566840866648108\n",
      "17456.669925930208\n",
      "1135649760.093346\n",
      "7783.137442709041\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874997887648471\n",
      "Test Score: 0.5668425906660188\n",
      "17455.92589552297\n",
      "1135645240.090474\n",
      "7777.637326376618\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875042063877576\n",
      "Test Score: 0.5668265999100313\n",
      "17456.286201086823\n",
      "1135687164.4014323\n",
      "7779.576756407019\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875219130282028\n",
      "Test Score: 0.5667702147989322\n",
      "17456.49659727397\n",
      "1135834993.993289\n",
      "7774.251011911299\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875190650774245\n",
      "Test Score: 0.5666930654542809\n",
      "17456.936528713963\n",
      "1136037262.924032\n",
      "7764.802953240414\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875468764916379\n",
      "Test Score: 0.5667175828349298\n",
      "17456.736726302188\n",
      "1135972983.6434896\n",
      "7772.713683803962\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875278962059968\n",
      "Test Score: 0.5667802877377198\n",
      "17456.016907997757\n",
      "1135808584.9218025\n",
      "7762.448257987264\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875422019074284\n",
      "Test Score: 0.5668738504330837\n",
      "17455.43478522367\n",
      "1135563283.7279403\n",
      "7755.095054090274\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875246006588106\n",
      "Test Score: 0.5669141619452795\n",
      "17454.540711075348\n",
      "1135457595.643287\n",
      "7774.643654487889\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875059939870028\n",
      "Test Score: 0.5668702314186824\n",
      "17455.3760064205\n",
      "1135572772.002618\n",
      "7754.916376110694\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874908687187829\n",
      "Test Score: 0.5669547013980973\n",
      "17454.88079675887\n",
      "1135351309.947518\n",
      "7737.817139015444\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987496938956706\n",
      "Test Score: 0.5670820516563885\n",
      "17453.86581711693\n",
      "1135017425.0559378\n",
      "7722.49252496233\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987439642122481\n",
      "Test Score: 0.5670954818399088\n",
      "17453.921183818155\n",
      "1134982214.0133474\n",
      "7726.164759959458\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874457853253259\n",
      "Test Score: 0.5671712490932953\n",
      "17453.65670318255\n",
      "1134783568.6276078\n",
      "7726.231904215336\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874404005912298\n",
      "Test Score: 0.567224485989041\n",
      "17452.828705195567\n",
      "1134643992.9769368\n",
      "7726.882191737182\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874507776711839\n",
      "Test Score: 0.5672566630498095\n",
      "17452.16021910462\n",
      "1134559631.668289\n",
      "7728.7400239103645\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874446978283096\n",
      "Test Score: 0.5672258449819371\n",
      "17452.168405067536\n",
      "1134640429.990871\n",
      "7728.606787364131\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874770342374412\n",
      "Test Score: 0.567244651197846\n",
      "17451.626283782334\n",
      "1134591124.1516523\n",
      "7721.730874122139\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875089648337039\n",
      "Test Score: 0.567317866042043\n",
      "17451.214589157455\n",
      "1134399170.6319275\n",
      "7722.310674591277\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875015202694314\n",
      "Test Score: 0.5673666881598624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17450.627417643027\n",
      "1134271169.5761502\n",
      "7706.826279643061\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874923921279322\n",
      "Test Score: 0.5672647578625811\n",
      "17451.971042795274\n",
      "1134538408.8162832\n",
      "7716.015101616802\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874827674762403\n",
      "Test Score: 0.5672661999668007\n",
      "17451.913564926792\n",
      "1134534627.9302647\n",
      "7726.851733570618\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875226458360233\n",
      "Test Score: 0.5671891507365094\n",
      "17452.863617679617\n",
      "1134736634.3827634\n",
      "7721.834267835033\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875250477677929\n",
      "Test Score: 0.5672170096760139\n",
      "17452.867434093223\n",
      "1134663594.2561014\n",
      "7718.87822722141\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875115002351919\n",
      "Test Score: 0.567176279378155\n",
      "17453.492062470697\n",
      "1134770380.3063788\n",
      "7724.7590082568295\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875180194932527\n",
      "Test Score: 0.5671132459873087\n",
      "17454.372641400365\n",
      "1134935640.252852\n",
      "7729.547124735413\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875043462755309\n",
      "Test Score: 0.5671603895918762\n",
      "17453.955818789447\n",
      "1134812039.8965518\n",
      "7732.383299076457\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875139515593709\n",
      "Test Score: 0.5670928087044065\n",
      "17454.865167035827\n",
      "1134989222.3976986\n",
      "7735.934157125266\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874964030516327\n",
      "Test Score: 0.5671092515708808\n",
      "17454.323354484266\n",
      "1134946112.7506223\n",
      "7735.640130886892\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875041202618763\n",
      "Test Score: 0.5671545072426455\n",
      "17453.910085671603\n",
      "1134827462.1466634\n",
      "7741.142700348768\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874575503959654\n",
      "Test Score: 0.567201075762798\n",
      "17453.230875335314\n",
      "1134705369.5375805\n",
      "7741.031605963704\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874547899717951\n",
      "Test Score: 0.5672088451963846\n",
      "17452.4365355528\n",
      "1134684999.7595718\n",
      "7739.979698737383\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874565615957461\n",
      "Test Score: 0.567230161541596\n",
      "17452.664979688754\n",
      "1134629112.9030764\n",
      "7736.498533642638\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987449520881438\n",
      "Test Score: 0.5670302135369307\n",
      "17455.33195765175\n",
      "1135153333.4170759\n",
      "7727.267905236602\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874324351001513\n",
      "Test Score: 0.5670172230963948\n",
      "17455.17043886565\n",
      "1135187391.5484698\n",
      "7725.925355323961\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874401557517227\n",
      "Test Score: 0.5670105903758367\n",
      "17455.455086629834\n",
      "1135204781.1102512\n",
      "7733.883272828403\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874612549649447\n",
      "Test Score: 0.5670778898756248\n",
      "17454.67403497985\n",
      "1135028336.346874\n",
      "7730.1956753286195\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874400346695111\n",
      "Test Score: 0.5670765178160833\n",
      "17454.215971180918\n",
      "1135031933.5908642\n",
      "7714.179735646365\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987432077894438\n",
      "Test Score: 0.5670603831364257\n",
      "17454.286482200332\n",
      "1135074235.2386224\n",
      "7696.172121526568\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874389387486278\n",
      "Test Score: 0.5671212592123949\n",
      "17453.483326657613\n",
      "1134914631.3061492\n",
      "7694.063148160694\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874284046418926\n",
      "Test Score: 0.5670908635322582\n",
      "17453.451075281235\n",
      "1134994322.2192502\n",
      "7692.124285679121\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874475895679615\n",
      "Test Score: 0.5670717123138664\n",
      "17453.513785140003\n",
      "1135044532.5805182\n",
      "7693.146335348825\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874700733303631\n",
      "Test Score: 0.567019728207258\n",
      "17453.766798168774\n",
      "1135180823.6884577\n",
      "7693.734217734771\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874843752413959\n",
      "Test Score: 0.5670275301869065\n",
      "17453.53438264406\n",
      "1135160368.581699\n",
      "7697.686515244268\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874975850330493\n",
      "Test Score: 0.5670623747774073\n",
      "17452.882297648077\n",
      "1135069013.585819\n",
      "7702.138359040244\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.987499979753046\n",
      "Test Score: 0.5670921524943844\n",
      "17452.656246192662\n",
      "1134990942.8387487\n",
      "7698.628858107611\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875146644438154\n",
      "Test Score: 0.5671518885705371\n",
      "17452.30686476783\n",
      "1134834327.739751\n",
      "7695.965541921651\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875171209100023\n",
      "Test Score: 0.5671473984821848\n",
      "17452.15873269097\n",
      "1134846099.7823272\n",
      "7694.663329379011\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874942031491364\n",
      "Test Score: 0.567212688090637\n",
      "17451.5625797812\n",
      "1134674924.520244\n",
      "7694.16022893383\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9874994324946456\n",
      "Test Score: 0.5672384042000008\n",
      "17451.46057741583\n",
      "1134607502.4317296\n",
      "7693.311998578916\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875191466971511\n",
      "Test Score: 0.5671922277589113\n",
      "17451.569866379697\n",
      "1134728567.0941308\n",
      "7694.916024986927\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875201980625885\n",
      "Test Score: 0.567242441763856\n",
      "17451.071736409172\n",
      "1134596916.8107178\n",
      "7702.289203794084\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875242579268416\n",
      "Test Score: 0.567271973870346\n",
      "17450.554285034133\n",
      "1134519490.001335\n",
      "7703.423562588945\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875172445643476\n",
      "Test Score: 0.5672935104790948\n",
      "17450.389844358455\n",
      "1134463025.661383\n",
      "7697.969887238523\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875179358905576\n",
      "Test Score: 0.5672727633903185\n",
      "17450.619003427844\n",
      "1134517420.0503666\n",
      "7702.044815202105\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875356257517722\n",
      "Test Score: 0.5673212066576415\n",
      "17449.91163548493\n",
      "1134390412.2588243\n",
      "7706.53170919725\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875394150534694\n",
      "Test Score: 0.5673976988584435\n",
      "17449.25278265171\n",
      "1134189866.217425\n",
      "7711.451296510497\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875492702337428\n",
      "Test Score: 0.5674598267962707\n",
      "17448.613774349964\n",
      "1134026980.1733456\n",
      "7713.728528504518\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875389515779367\n",
      "Test Score: 0.5674198628661812\n",
      "17448.786775774985\n",
      "1134131756.972734\n",
      "7717.4899987357785\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875420005454505\n",
      "Test Score: 0.5674785787452409\n",
      "17448.59492570186\n",
      "1133977816.6103277\n",
      "7717.222457194579\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875463457916698\n",
      "Test Score: 0.5674910477720105\n",
      "17448.283108109277\n",
      "1133945125.5132937\n",
      "7723.4719606908475\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875526939408624\n",
      "Test Score: 0.5675080441011362\n",
      "17447.984600798034\n",
      "1133900564.8065975\n",
      "7720.489769516649\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875415724212868\n",
      "Test Score: 0.5675547475636626\n",
      "17447.405387596104\n",
      "1133778118.4077342\n",
      "7722.153750525818\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9875376858053413\n",
      "Test Score: 0.5675614976265126\n",
      "17447.586006119887\n",
      "1133760421.1997893\n",
      "7721.661909968445\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882424581734901\n",
      "Test Score: 0.5673717026613252\n",
      "17479.40962403597\n",
      "1134258022.6355805\n",
      "7795.384809376096\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886445340462198\n",
      "Test Score: 0.5661489590883576\n",
      "17495.820766043005\n",
      "1137463792.3824883\n",
      "7916.715771837804\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882666915454185\n",
      "Test Score: 0.5660327091514088\n",
      "17498.644782679792\n",
      "1137768574.6272614\n",
      "7951.72710665609\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9884573594461987\n",
      "Test Score: 0.5631031201886543\n",
      "17523.166825259625\n",
      "1145449324.6024013\n",
      "7931.946581738852\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9884761997799909\n",
      "Test Score: 0.5638744964168515\n",
      "17513.183885933344\n",
      "1143426942.6160975\n",
      "7902.3483815781165\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885921080135279\n",
      "Test Score: 0.5647349340195545\n",
      "17509.32757728491\n",
      "1141171060.927713\n",
      "7837.484553471071\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885924653602883\n",
      "Test Score: 0.5654359402720105\n",
      "17503.08039544987\n",
      "1139333173.8300426\n",
      "7893.39706567187\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885314486151615\n",
      "Test Score: 0.565969212226157\n",
      "17496.883423144907\n",
      "1137935049.8609028\n",
      "7847.97392899375\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9884452062334417\n",
      "Test Score: 0.5662499620673519\n",
      "17492.001085144082\n",
      "1137198984.3707633\n",
      "7864.634063342715\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882341462511737\n",
      "Test Score: 0.5666454538715383\n",
      "17486.904320220838\n",
      "1136162090.2181048\n",
      "7869.930282220281\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882283785182862\n",
      "Test Score: 0.5668491428364453\n",
      "17484.95125278257\n",
      "1135628061.7137527\n",
      "7853.895737299377\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882499298225883\n",
      "Test Score: 0.5664936738978533\n",
      "17482.35494897055\n",
      "1136560024.5508487\n",
      "7864.410993860121\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988239740161216\n",
      "Test Score: 0.5664978931039828\n",
      "17480.04958255849\n",
      "1136548962.7029972\n",
      "7769.709006712434\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988239274706152\n",
      "Test Score: 0.566407427025065\n",
      "17479.600541706153\n",
      "1136786145.2368724\n",
      "7808.243383796806\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882333091692627\n",
      "Test Score: 0.5665462758355783\n",
      "17481.21798407479\n",
      "1136422113.6230667\n",
      "7798.116714274325\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881790807427513\n",
      "Test Score: 0.5668028632277466\n",
      "17480.56871999269\n",
      "1135749396.8593588\n",
      "7833.202321208661\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881798077775092\n",
      "Test Score: 0.5668072991501536\n",
      "17479.7940012448\n",
      "1135737766.8282006\n",
      "7815.29347119152\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882074390602071\n",
      "Test Score: 0.5668821285616025\n",
      "17478.99775281123\n",
      "1135541580.2616098\n",
      "7807.341079534352\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882164640751347\n",
      "Test Score: 0.5669547339002565\n",
      "17476.707991990923\n",
      "1135351224.7338712\n",
      "7789.38581180817\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882609807978086\n",
      "Test Score: 0.5668071823035737\n",
      "17477.173981022464\n",
      "1135738073.1747146\n",
      "7778.718679113805\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9883110384485353\n",
      "Test Score: 0.5669010083147126\n",
      "17476.164310586053\n",
      "1135492081.623721\n",
      "7785.142378410301\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882488996048859\n",
      "Test Score: 0.5669591465199114\n",
      "17476.51388984277\n",
      "1135339655.7974997\n",
      "7794.677701944656\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881357298619757\n",
      "Test Score: 0.5669035578285617\n",
      "17476.765633785657\n",
      "1135485397.3486629\n",
      "7793.582128244176\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881482889656817\n",
      "Test Score: 0.5668087839519411\n",
      "17477.946509287976\n",
      "1135733873.9983747\n",
      "7800.620954157275\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881236962728785\n",
      "Test Score: 0.5668248199392736\n",
      "17479.12464495879\n",
      "1135691831.1005924\n",
      "7802.077827661189\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880937277706776\n",
      "Test Score: 0.5666049853972885\n",
      "17481.318786932956\n",
      "1136268189.8233874\n",
      "7801.387750403337\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881497121489302\n",
      "Test Score: 0.566536193025338\n",
      "17481.773393699637\n",
      "1136448548.5753713\n",
      "7798.180394077401\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880707908825099\n",
      "Test Score: 0.5664113514778165\n",
      "17481.961057196393\n",
      "1136775856.1687615\n",
      "7798.912802809424\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880753945815915\n",
      "Test Score: 0.5663408679406042\n",
      "17483.763585332512\n",
      "1136960648.7910626\n",
      "7793.5883651484655\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881725088667627\n",
      "Test Score: 0.5658859351061959\n",
      "17490.82240347465\n",
      "1138153384.4959674\n",
      "7805.066398674495\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881776544729608\n",
      "Test Score: 0.5658016224123786\n",
      "17491.577149409666\n",
      "1138374434.1821773\n",
      "7788.134485910392\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881660884596924\n",
      "Test Score: 0.5657876152273216\n",
      "17491.392537424963\n",
      "1138411157.9982643\n",
      "7793.695865996207\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988143349434417\n",
      "Test Score: 0.5654955597209135\n",
      "17492.38380931121\n",
      "1139176864.502522\n",
      "7746.352337874705\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881027704336536\n",
      "Test Score: 0.5656047591890494\n",
      "17490.9741291386\n",
      "1138890567.0652933\n",
      "7743.4133370106065\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881167781702698\n",
      "Test Score: 0.5655150554569164\n",
      "17490.93120254491\n",
      "1139125750.890434\n",
      "7756.315280649476\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881033990726948\n",
      "Test Score: 0.5654371358769883\n",
      "17491.270830628866\n",
      "1139330039.211835\n",
      "7757.52178398188\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988124239435798\n",
      "Test Score: 0.5655536631008726\n",
      "17490.353766781856\n",
      "1139024529.9805632\n",
      "7765.534417652612\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880846095386744\n",
      "Test Score: 0.5654843553083302\n",
      "17491.16133756983\n",
      "1139206240.0540977\n",
      "7775.195820296805\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881117622733862\n",
      "Test Score: 0.5654671815967023\n",
      "17491.094295100327\n",
      "1139251265.8194306\n",
      "7771.141166560181\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988126224634125\n",
      "Test Score: 0.5654610113420946\n",
      "17490.964968180626\n",
      "1139267442.895303\n",
      "7781.441019949723\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881603068272095\n",
      "Test Score: 0.5652928236549403\n",
      "17492.012145979006\n",
      "1139708394.7115314\n",
      "7774.644973419336\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881822879755497\n",
      "Test Score: 0.5653772976853102\n",
      "17490.691439120612\n",
      "1139486922.0357008\n",
      "7768.142934639258\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881638061767124\n",
      "Test Score: 0.5654764667198906\n",
      "17489.620067685173\n",
      "1139226922.230414\n",
      "7782.766482784928\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881926816213216\n",
      "Test Score: 0.5655510526443711\n",
      "17489.199631266838\n",
      "1139031374.034103\n",
      "7768.793201966335\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881702591527762\n",
      "Test Score: 0.5656299909000715\n",
      "17488.16965235211\n",
      "1138824414.9646852\n",
      "7771.073761303609\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881670198695284\n",
      "Test Score: 0.5656265763190882\n",
      "17488.324453412035\n",
      "1138833367.2590635\n",
      "7763.953332062121\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881574864550678\n",
      "Test Score: 0.5657047324105438\n",
      "17488.008438957295\n",
      "1138628458.855483\n",
      "7769.668119979031\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881621798685712\n",
      "Test Score: 0.5658330472122577\n",
      "17487.30254796852\n",
      "1138292045.139223\n",
      "7758.7993303193325\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881030230673159\n",
      "Test Score: 0.5658489842954078\n",
      "17487.249272735287\n",
      "1138250261.5468614\n",
      "7777.716662848257\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881123572224182\n",
      "Test Score: 0.566010119031908\n",
      "17486.219506848094\n",
      "1137827801.0450282\n",
      "7757.865071270084\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881025082381735\n",
      "Test Score: 0.5660708695609133\n",
      "17485.561443325503\n",
      "1137668526.2695973\n",
      "7756.459366563435\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988105563395562\n",
      "Test Score: 0.566120878515106\n",
      "17484.97173832246\n",
      "1137537413.5850008\n",
      "7754.274452134992\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880932642143039\n",
      "Test Score: 0.5660186213377669\n",
      "17485.805884366644\n",
      "1137805509.8340957\n",
      "7770.2162177532955\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881130258280725\n",
      "Test Score: 0.5659766990500423\n",
      "17485.92081342981\n",
      "1137915421.0245364\n",
      "7781.031190111838\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881345156036738\n",
      "Test Score: 0.5660512106912163\n",
      "17485.565785609073\n",
      "1137720067.5830228\n",
      "7736.8792364857\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881241302170095\n",
      "Test Score: 0.5658335740247507\n",
      "17487.30650631442\n",
      "1138290663.950567\n",
      "7740.085661401192\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988105140443975\n",
      "Test Score: 0.5656710146314105\n",
      "17489.45315359919\n",
      "1138716859.5951543\n",
      "7745.829153978017\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880807017340504\n",
      "Test Score: 0.5657106258319853\n",
      "17489.080755671126\n",
      "1138613007.5764246\n",
      "7744.184255110031\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881190537663772\n",
      "Test Score: 0.5656366938416882\n",
      "17490.39658132846\n",
      "1138806841.2984433\n",
      "7743.032387353915\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881317798784881\n",
      "Test Score: 0.5656201751647847\n",
      "17490.960900823928\n",
      "1138850149.7041037\n",
      "7741.307017685089\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988116928881731\n",
      "Test Score: 0.565566640468006\n",
      "17490.904949308344\n",
      "1138990506.12481\n",
      "7737.677288399851\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881224435966977\n",
      "Test Score: 0.5655151879978171\n",
      "17491.355671337365\n",
      "1139125403.3967986\n",
      "7738.463087916078\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881180054654154\n",
      "Test Score: 0.5656176908190618\n",
      "17490.436516491314\n",
      "1138856663.1223996\n",
      "7752.403870704897\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881196691806523\n",
      "Test Score: 0.5655590167076134\n",
      "17491.100754637446\n",
      "1139010493.9791431\n",
      "7779.286453728977\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881094187986301\n",
      "Test Score: 0.5655696602212874\n",
      "17491.075638337403\n",
      "1138982588.983451\n",
      "7765.407943540975\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881267875845062\n",
      "Test Score: 0.5655727095316357\n",
      "17491.109596740946\n",
      "1138974594.3498418\n",
      "7777.530682098564\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.988106006203682\n",
      "Test Score: 0.5656190216772037\n",
      "17490.38095596562\n",
      "1138853173.8995867\n",
      "7778.6267614390235\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880945266223162\n",
      "Test Score: 0.5655788796550074\n",
      "17490.08910754024\n",
      "1138958417.6180422\n",
      "7747.719974109312\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881030388023152\n",
      "Test Score: 0.5656083663199973\n",
      "17489.789994574905\n",
      "1138881109.9464653\n",
      "7745.323254807034\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881019177559742\n",
      "Test Score: 0.5657083803408511\n",
      "17488.645081921833\n",
      "1138618894.76954\n",
      "7751.092036082024\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9880858267607889\n",
      "Test Score: 0.56575394864109\n",
      "17487.662216173285\n",
      "1138499424.521196\n",
      "7750.893994318321\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881017313532394\n",
      "Test Score: 0.5657669004784442\n",
      "17487.568557426614\n",
      "1138465467.5990126\n",
      "7762.626560206665\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988120408548475\n",
      "Test Score: 0.5657928210128086\n",
      "17487.154980817068\n",
      "1138397509.5522678\n",
      "7767.343984924901\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881013414693665\n",
      "Test Score: 0.5657254560977836\n",
      "17487.476189653633\n",
      "1138574125.8202775\n",
      "7782.954325070004\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881068716251725\n",
      "Test Score: 0.5657106261461318\n",
      "17487.4325379723\n",
      "1138613006.7528007\n",
      "7790.956483244607\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881212735219295\n",
      "Test Score: 0.5657592819937499\n",
      "17486.945729329378\n",
      "1138485441.6216044\n",
      "7788.944620236987\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881075168006329\n",
      "Test Score: 0.5657374601079763\n",
      "17487.199590088854\n",
      "1138542653.8963447\n",
      "7787.481823317974\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881313862097904\n",
      "Test Score: 0.5656982503056381\n",
      "17487.61641779805\n",
      "1138645453.5355308\n",
      "7785.57483091768\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881487413435568\n",
      "Test Score: 0.5655940229423942\n",
      "17487.45476911004\n",
      "1138918715.1868486\n",
      "7786.093960479813\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988162634824553\n",
      "Test Score: 0.5656044100276014\n",
      "17487.303728112835\n",
      "1138891482.4912512\n",
      "7782.960246516546\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881807484776997\n",
      "Test Score: 0.5656240780936403\n",
      "17486.877943233085\n",
      "1138839917.0670025\n",
      "7778.8821436907765\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881783452288913\n",
      "Test Score: 0.5656880818971668\n",
      "17486.245542039058\n",
      "1138672112.9079227\n",
      "7783.058632150471\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881981329417382\n",
      "Test Score: 0.5657081741814619\n",
      "17486.548993514552\n",
      "1138619435.2749639\n",
      "7783.952699743801\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881921534032333\n",
      "Test Score: 0.5656852036797815\n",
      "17486.643795040975\n",
      "1138679658.9727092\n",
      "7784.625465805602\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881767056684914\n",
      "Test Score: 0.5657550966788893\n",
      "17486.040167429535\n",
      "1138496414.6138637\n",
      "7780.035775591563\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881828685107508\n",
      "Test Score: 0.5657694442843946\n",
      "17485.98572331179\n",
      "1138458798.2888339\n",
      "7780.620996499467\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881944783969328\n",
      "Test Score: 0.5657365164230068\n",
      "17486.195139539203\n",
      "1138545128.0346618\n",
      "7781.630331168841\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881983678436875\n",
      "Test Score: 0.5657294245077149\n",
      "17486.49718178071\n",
      "1138563721.505928\n",
      "7784.0366978135935\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882059739034855\n",
      "Test Score: 0.5657642990500347\n",
      "17486.244862427295\n",
      "1138472287.9828434\n",
      "7783.596221450067\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.98819170044942\n",
      "Test Score: 0.565751606793499\n",
      "17486.52044148838\n",
      "1138505564.3401449\n",
      "7780.278799412103\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9881983505227434\n",
      "Test Score: 0.5657378183093306\n",
      "17486.700769745326\n",
      "1138541714.7697036\n",
      "7776.634490864115\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988220870061053\n",
      "Test Score: 0.5657476550461795\n",
      "17486.542585792595\n",
      "1138515924.9687216\n",
      "7770.157987688814\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882183101602593\n",
      "Test Score: 0.5657846483890716\n",
      "17486.15058038194\n",
      "1138418936.4078307\n",
      "7767.57754214811\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988231067629993\n",
      "Test Score: 0.5658404266598422\n",
      "17485.850602990377\n",
      "1138272697.8203428\n",
      "7767.685719493953\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882173930453156\n",
      "Test Score: 0.5658525058079209\n",
      "17485.417977177953\n",
      "1138241028.90109\n",
      "7765.283583845112\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882248009794676\n",
      "Test Score: 0.5659475150005298\n",
      "17484.54174844029\n",
      "1137991935.3036447\n",
      "7765.7216218609665\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882320284460453\n",
      "Test Score: 0.5659904506560587\n",
      "17484.395079074056\n",
      "1137879367.2815335\n",
      "7768.337825873679\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882439493024339\n",
      "Test Score: 0.5657808379279641\n",
      "17486.946442041793\n",
      "1138428926.6144536\n",
      "7773.32448500616\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882241232420591\n",
      "Test Score: 0.5657964246545322\n",
      "17487.009631299083\n",
      "1138388061.5814326\n",
      "7772.136333459115\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9882195429209192\n",
      "Test Score: 0.565807209568658\n",
      "17487.019579930125\n",
      "1138359785.8642733\n",
      "7769.651174795839\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887879444861383\n",
      "Test Score: 0.5643589046551805\n",
      "17564.557717745833\n",
      "1142156928.763709\n",
      "7866.2601655531325\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892836254103737\n",
      "Test Score: 0.5672876997061413\n",
      "17542.056607186576\n",
      "1134478260.2539434\n",
      "7851.872045931701\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886889627464941\n",
      "Test Score: 0.5639681785616055\n",
      "17570.952534529777\n",
      "1143181328.2517147\n",
      "7862.259210481283\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890075008747379\n",
      "Test Score: 0.5634631008156139\n",
      "17580.70173124676\n",
      "1144505533.092151\n",
      "7871.95553998365\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989014143590695\n",
      "Test Score: 0.5636756305418812\n",
      "17582.182029242667\n",
      "1143948326.01959\n",
      "7941.5870041832895\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892075669431801\n",
      "Test Score: 0.5637921335795011\n",
      "17592.1197394132\n",
      "1143642880.1994834\n",
      "7937.772140813284\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891939035419467\n",
      "Test Score: 0.5644417460012758\n",
      "17588.09039078294\n",
      "1141939736.633669\n",
      "7957.226611729535\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892075160850531\n",
      "Test Score: 0.56486454353021\n",
      "17584.010948426985\n",
      "1140831252.7640417\n",
      "7938.543457832075\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890979989202014\n",
      "Test Score: 0.564589960387802\n",
      "17586.569244871847\n",
      "1141551150.5009043\n",
      "7922.821747160011\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888615854236991\n",
      "Test Score: 0.564698139524845\n",
      "17585.26471988451\n",
      "1141267528.1515858\n",
      "7911.984737787432\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988870372575153\n",
      "Test Score: 0.5646293284592919\n",
      "17586.135402173946\n",
      "1141447935.9141614\n",
      "7930.784174799121\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889600983140356\n",
      "Test Score: 0.5638534933002949\n",
      "17590.77079429228\n",
      "1143482008.2546635\n",
      "7916.383797272956\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889293214668832\n",
      "Test Score: 0.56376021720098\n",
      "17589.690778931188\n",
      "1143726558.055541\n",
      "7949.604918157302\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889142086242587\n",
      "Test Score: 0.5637726624480222\n",
      "17588.95290172441\n",
      "1143693929.3038197\n",
      "7940.246529926757\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888877848720599\n",
      "Test Score: 0.5638298761212572\n",
      "17587.98584749384\n",
      "1143543927.4008687\n",
      "7943.884473136895\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887752748807825\n",
      "Test Score: 0.5640545819017946\n",
      "17587.116770266235\n",
      "1142954797.341936\n",
      "7928.716134975111\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888205506351462\n",
      "Test Score: 0.5640344823016374\n",
      "17589.924529905224\n",
      "1143007494.1555064\n",
      "7934.789144444701\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888234416699961\n",
      "Test Score: 0.5643686156371621\n",
      "17589.363370517163\n",
      "1142131468.6648476\n",
      "7927.562005237067\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888423507722975\n",
      "Test Score: 0.5643297178585124\n",
      "17587.562568174315\n",
      "1142233450.2452657\n",
      "7913.135335265926\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888521168871007\n",
      "Test Score: 0.5642359314750033\n",
      "17588.242975401252\n",
      "1142479337.9011672\n",
      "7914.938046108917\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9888567711819274\n",
      "Test Score: 0.5643169214002332\n",
      "17588.163308902887\n",
      "1142266999.7970493\n",
      "7905.981911744946\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887671129558803\n",
      "Test Score: 0.5644165560228136\n",
      "17585.58636919708\n",
      "1142005779.3205125\n",
      "7916.603420184298\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886368237009118\n",
      "Test Score: 0.5642970086437218\n",
      "17586.50707964135\n",
      "1142319206.7469058\n",
      "7902.026261302359\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886618346220721\n",
      "Test Score: 0.5642398494305063\n",
      "17587.20830357131\n",
      "1142469065.86744\n",
      "7919.687427440145\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886398228417718\n",
      "Test Score: 0.5643656433723226\n",
      "17586.41428795438\n",
      "1142139261.301761\n",
      "7909.617686962702\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885895941625203\n",
      "Test Score: 0.5641667534222381\n",
      "17588.70895437747\n",
      "1142660707.8250067\n",
      "7916.847474919197\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988667524475187\n",
      "Test Score: 0.5641593544931969\n",
      "17590.186436180637\n",
      "1142680106.2200625\n",
      "7929.587001346486\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.98858024128808\n",
      "Test Score: 0.5641423064542608\n",
      "17588.38865569579\n",
      "1142724802.498721\n",
      "7915.224126952637\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885656254397314\n",
      "Test Score: 0.5641939597089964\n",
      "17588.362221082523\n",
      "1142589378.8129854\n",
      "7924.143357561175\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886490784432678\n",
      "Test Score: 0.5642278060963016\n",
      "17588.31842366748\n",
      "1142500640.8904445\n",
      "7927.640955486093\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886595674575863\n",
      "Test Score: 0.5641346931173818\n",
      "17589.208848870603\n",
      "1142744763.0248513\n",
      "7937.484893698804\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886545030474838\n",
      "Test Score: 0.5640883929079249\n",
      "17588.953659677114\n",
      "1142866152.1811998\n",
      "7945.698714341506\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886437843476057\n",
      "Test Score: 0.5638283567024922\n",
      "17591.25848976061\n",
      "1143547910.9889386\n",
      "7961.5952123480565\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886072889753668\n",
      "Test Score: 0.5638310814158005\n",
      "17590.23610119749\n",
      "1143540767.3787117\n",
      "7968.577819206814\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886435225559101\n",
      "Test Score: 0.5637464312216895\n",
      "17590.13405733711\n",
      "1143762701.91785\n",
      "7957.919199037422\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988667194377271\n",
      "Test Score: 0.5636846303820691\n",
      "17591.280026134307\n",
      "1143924730.381028\n",
      "7963.563890722224\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988678602910019\n",
      "Test Score: 0.5636613660769536\n",
      "17592.20242099866\n",
      "1143985724.3679695\n",
      "7950.224200620974\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886633788604194\n",
      "Test Score: 0.563466507624182\n",
      "17593.929654699405\n",
      "1144496601.1753676\n",
      "7947.360971168411\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886682836572126\n",
      "Test Score: 0.5634933766357035\n",
      "17593.439114244487\n",
      "1144426156.4262238\n",
      "7953.367716483874\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886836366655436\n",
      "Test Score: 0.5634595851635755\n",
      "17593.65431305675\n",
      "1144514750.373022\n",
      "7951.686815235433\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886851115260408\n",
      "Test Score: 0.5634049981891236\n",
      "17593.86703910761\n",
      "1144657865.638677\n",
      "7960.386909518858\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886991525141089\n",
      "Test Score: 0.5634868854471211\n",
      "17592.155552034626\n",
      "1144443174.9217112\n",
      "7959.8344331880835\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886842006214851\n",
      "Test Score: 0.5635820717645907\n",
      "17591.61115742434\n",
      "1144193616.9411094\n",
      "7959.333549882247\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887094086685492\n",
      "Test Score: 0.5636569415518866\n",
      "17591.79681372117\n",
      "1143997324.517762\n",
      "7963.695432795568\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887163572430216\n",
      "Test Score: 0.5637086128403686\n",
      "17591.07066865433\n",
      "1143861853.5514357\n",
      "7965.825199559835\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887082028780924\n",
      "Test Score: 0.5636373279812879\n",
      "17592.079213391324\n",
      "1144048747.0667284\n",
      "7967.041859401652\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886456564831761\n",
      "Test Score: 0.5637144687762548\n",
      "17591.92709852898\n",
      "1143846500.5514126\n",
      "7962.443037069053\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886427220361463\n",
      "Test Score: 0.5638559812313528\n",
      "17590.484724824724\n",
      "1143475485.436393\n",
      "7969.6661250943525\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885857361668596\n",
      "Test Score: 0.5638087388096577\n",
      "17590.895059160746\n",
      "1143599344.8698747\n",
      "7952.786469337294\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885990774888653\n",
      "Test Score: 0.5639826655555309\n",
      "17589.953449881257\n",
      "1143143346.4803307\n",
      "7951.808476025148\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885807796181064\n",
      "Test Score: 0.5641069553505309\n",
      "17588.819754199096\n",
      "1142817485.4629683\n",
      "7950.915644646224\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885862392451553\n",
      "Test Score: 0.5641219945952867\n",
      "17588.54170546743\n",
      "1142778055.8090978\n",
      "7944.940296025157\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885663341766766\n",
      "Test Score: 0.5640360098249472\n",
      "17588.747944377676\n",
      "1143003489.3190694\n",
      "7950.727296699184\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885881136785853\n",
      "Test Score: 0.564019905278351\n",
      "17588.58927766907\n",
      "1143045711.964444\n",
      "7939.96110761142\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886053424959783\n",
      "Test Score: 0.5640473520659569\n",
      "17588.490470280096\n",
      "1142973752.411107\n",
      "7939.863798933504\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885909024613959\n",
      "Test Score: 0.5638195625076051\n",
      "17589.89541512555\n",
      "1143570967.4699056\n",
      "7934.675058998042\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885809414548993\n",
      "Test Score: 0.5637191529281873\n",
      "17591.38160431902\n",
      "1143834219.716013\n",
      "7935.514165803703\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885546446336485\n",
      "Test Score: 0.5638135666843369\n",
      "17589.942783405484\n",
      "1143586687.2244527\n",
      "7934.384871421673\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885949507922437\n",
      "Test Score: 0.563545240207252\n",
      "17592.854933844785\n",
      "1144290181.3351967\n",
      "7936.7577748617\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886010079067383\n",
      "Test Score: 0.5635732069546411\n",
      "17593.20485583561\n",
      "1144216858.5595295\n",
      "7949.195234475868\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885977355549148\n",
      "Test Score: 0.5635076201363416\n",
      "17593.290383903142\n",
      "1144388813.0416868\n",
      "7941.479866678248\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886051315998626\n",
      "Test Score: 0.5634777282262522\n",
      "17593.519211074647\n",
      "1144467183.178451\n",
      "7934.499254279577\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886043660602148\n",
      "Test Score: 0.5635746067219312\n",
      "17592.800313619267\n",
      "1144213188.6718028\n",
      "7931.347228155493\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885985037013546\n",
      "Test Score: 0.563398163754355\n",
      "17593.55669497352\n",
      "1144675784.0515828\n",
      "7937.887786531965\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885774625335683\n",
      "Test Score: 0.5633819177271517\n",
      "17593.10567831586\n",
      "1144718377.628574\n",
      "7948.887583266478\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885935234698142\n",
      "Test Score: 0.5633845184485766\n",
      "17593.48333275865\n",
      "1144711559.0983047\n",
      "7947.355485155109\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885697460028425\n",
      "Test Score: 0.5634331768237799\n",
      "17592.88398084496\n",
      "1144583987.340326\n",
      "7951.104258508703\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885712038080142\n",
      "Test Score: 0.5634221402797454\n",
      "17592.226308520694\n",
      "1144612922.7767975\n",
      "7948.956013418805\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988575730612923\n",
      "Test Score: 0.5634270274024429\n",
      "17592.537197456186\n",
      "1144600109.7958586\n",
      "7945.451293133223\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885628161957316\n",
      "Test Score: 0.5632453547694458\n",
      "17594.70755632009\n",
      "1145076416.229668\n",
      "7951.7500743388755\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885395635015843\n",
      "Test Score: 0.5632848704034207\n",
      "17594.14924850915\n",
      "1144972814.7659373\n",
      "7944.832837743526\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885518155587203\n",
      "Test Score: 0.5632594751322708\n",
      "17594.555587002455\n",
      "1145039395.6859002\n",
      "7943.698328053473\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885739878147467\n",
      "Test Score: 0.563299339928575\n",
      "17594.118859324295\n",
      "1144934878.793901\n",
      "7950.999595148956\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988550488266358\n",
      "Test Score: 0.5632474837037653\n",
      "17593.76522709275\n",
      "1145070834.623364\n",
      "7948.18485055539\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988555599820475\n",
      "Test Score: 0.5632132596831979\n",
      "17593.80725993805\n",
      "1145160562.6188147\n",
      "7942.490786396367\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885817396158888\n",
      "Test Score: 0.5632505628135919\n",
      "17593.577617417548\n",
      "1145062761.861955\n",
      "7947.622549186935\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9885948696799105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.5632103378637263\n",
      "17594.12385965932\n",
      "1145168222.998861\n",
      "7942.817962287039\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886123727103107\n",
      "Test Score: 0.5632459144020201\n",
      "17593.876057826164\n",
      "1145074948.9938421\n",
      "7938.74375962277\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886303377125957\n",
      "Test Score: 0.563151816472601\n",
      "17593.982186922396\n",
      "1145321653.4558794\n",
      "7919.725133631184\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988655416951782\n",
      "Test Score: 0.56316854735658\n",
      "17593.74284982857\n",
      "1145277788.6890674\n",
      "7923.184799610361\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886738471821422\n",
      "Test Score: 0.5631925325007757\n",
      "17593.4301883764\n",
      "1145214904.8176346\n",
      "7920.459145135447\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886747597250717\n",
      "Test Score: 0.5632269513172943\n",
      "17593.15564995149\n",
      "1145124666.1092422\n",
      "7919.271126461659\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886932359156423\n",
      "Test Score: 0.563248772581454\n",
      "17593.3758479265\n",
      "1145067455.4642396\n",
      "7917.753178359069\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886835957436219\n",
      "Test Score: 0.5631935537182744\n",
      "17593.931484478777\n",
      "1145212227.4057598\n",
      "7918.262577339585\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886524694822861\n",
      "Test Score: 0.563226584357835\n",
      "17593.98635966872\n",
      "1145125628.1977446\n",
      "7917.648922421508\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988662329334278\n",
      "Test Score: 0.5632238046782857\n",
      "17594.44906554035\n",
      "1145132915.9175923\n",
      "7918.154995631146\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886732041525972\n",
      "Test Score: 0.5632348830349387\n",
      "17594.138281326548\n",
      "1145103870.8574595\n",
      "7919.698290483283\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886711153134699\n",
      "Test Score: 0.5632645582439975\n",
      "17593.784601560736\n",
      "1145026068.864027\n",
      "7918.0174789553475\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886795132760776\n",
      "Test Score: 0.5633171475053877\n",
      "17593.411742340075\n",
      "1144888191.1708586\n",
      "7917.339329151571\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886731664494915\n",
      "Test Score: 0.5633115514183806\n",
      "17593.437098629503\n",
      "1144902862.903203\n",
      "7919.538856002599\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886819706506552\n",
      "Test Score: 0.5633074197488976\n",
      "17593.418044465037\n",
      "1144913695.2488604\n",
      "7921.348602776388\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.98870233884458\n",
      "Test Score: 0.5633269814792905\n",
      "17593.234281674027\n",
      "1144862408.6137257\n",
      "7919.451895153076\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9886999582715701\n",
      "Test Score: 0.5633258631558905\n",
      "17593.517945660195\n",
      "1144865340.6163156\n",
      "7919.640020480354\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887240156381648\n",
      "Test Score: 0.5633820761155626\n",
      "17593.350497876025\n",
      "1144717962.3683453\n",
      "7925.224588955722\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887147289419809\n",
      "Test Score: 0.5633905188922739\n",
      "17592.906113336772\n",
      "1144695827.2299898\n",
      "7920.519519559664\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887189715906202\n",
      "Test Score: 0.5634724951912395\n",
      "17592.284411040113\n",
      "1144480903.0668228\n",
      "7930.400165397614\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887233101303294\n",
      "Test Score: 0.5635297331135918\n",
      "17591.968351783475\n",
      "1144330837.58792\n",
      "7929.194157787866\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887334189257867\n",
      "Test Score: 0.563478033137653\n",
      "17592.00129851322\n",
      "1144466383.7665668\n",
      "7932.1979990480595\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887173351317191\n",
      "Test Score: 0.5635192775501987\n",
      "17591.64871592419\n",
      "1144358249.818541\n",
      "7932.209785700832\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887179649289564\n",
      "Test Score: 0.5634974910205143\n",
      "17591.876253546085\n",
      "1144415369.3972464\n",
      "7931.684952843811\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988016868379025\n",
      "Test Score: 0.557556246016069\n",
      "17690.97261218155\n",
      "1159992031.5161834\n",
      "7880.516147218663\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890674703966743\n",
      "Test Score: 0.5629958766789339\n",
      "17640.48487686316\n",
      "1145730493.9388137\n",
      "7846.999435940354\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9887381602511116\n",
      "Test Score: 0.5599114155090412\n",
      "17661.58828364049\n",
      "1153817285.4154239\n",
      "7917.839894145793\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891260744468222\n",
      "Test Score: 0.5580593743197007\n",
      "17678.216618277347\n",
      "1158672937.692872\n",
      "7924.508104661736\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891468107127611\n",
      "Test Score: 0.5592678623767777\n",
      "17668.927900280145\n",
      "1155504542.8319\n",
      "7932.125079805393\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989397896261432\n",
      "Test Score: 0.5600070740607848\n",
      "17669.96097584682\n",
      "1153566489.3384771\n",
      "7926.66074036086\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893936509447195\n",
      "Test Score: 0.5609249592658818\n",
      "17663.30182866649\n",
      "1151159992.4353747\n",
      "7955.739239516335\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9894171910240935\n",
      "Test Score: 0.5618042283390163\n",
      "17652.928661148035\n",
      "1148854738.6958637\n",
      "7951.430427964033\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989253448519044\n",
      "Test Score: 0.5616881212017277\n",
      "17652.88589255987\n",
      "1149159146.5507474\n",
      "7955.9171048696535\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890886071807744\n",
      "Test Score: 0.5620265770042701\n",
      "17647.698505157718\n",
      "1148271788.4844754\n",
      "7994.900683858254\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891304813223921\n",
      "Test Score: 0.5621376519948368\n",
      "17648.433788907223\n",
      "1147980573.8322217\n",
      "7980.741259117502\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892613809151078\n",
      "Test Score: 0.5617995097369243\n",
      "17648.33845468316\n",
      "1148867109.8521464\n",
      "7952.045963344168\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892742157654895\n",
      "Test Score: 0.5617942215893771\n",
      "17645.725170682632\n",
      "1148880974.2336886\n",
      "7997.96372017503\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892889905868362\n",
      "Test Score: 0.5616643795810055\n",
      "17646.111629810057\n",
      "1149221391.9561918\n",
      "8024.295164047771\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892310596463422\n",
      "Test Score: 0.5616626109877363\n",
      "17648.005712489245\n",
      "1149226028.8260329\n",
      "7982.504338071605\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989207982171877\n",
      "Test Score: 0.5620030372363921\n",
      "17644.716431080404\n",
      "1148333504.675327\n",
      "8022.254483076795\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892215848560418\n",
      "Test Score: 0.5619797063716596\n",
      "17647.313695652963\n",
      "1148394673.1672187\n",
      "8046.245993553655\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892208121406972\n",
      "Test Score: 0.5622829500330055\n",
      "17646.49175723787\n",
      "1147599633.7354226\n",
      "8017.925284305416\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892441606617601\n",
      "Test Score: 0.5622706263552761\n",
      "17645.31270841665\n",
      "1147631943.7586434\n",
      "8003.238258561538\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892774221551509\n",
      "Test Score: 0.5622737024668862\n",
      "17645.311263803982\n",
      "1147623878.8579106\n",
      "7999.914161216351\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893172622987725\n",
      "Test Score: 0.5624313259485512\n",
      "17643.602016387475\n",
      "1147210624.1084313\n",
      "7991.4742154245305\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892573389247665\n",
      "Test Score: 0.5624668695294417\n",
      "17642.49035594419\n",
      "1147117436.510611\n",
      "7961.858232533887\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891612694667737\n",
      "Test Score: 0.5625701431335672\n",
      "17639.634574914526\n",
      "1146846675.4098542\n",
      "7939.641649798839\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891458198378341\n",
      "Test Score: 0.5625219692863764\n",
      "17639.686938822895\n",
      "1146972976.8399587\n",
      "7940.473344864935\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891390492985527\n",
      "Test Score: 0.562749886869898\n",
      "17638.015589281633\n",
      "1146375426.1267958\n",
      "7970.941949157037\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891174745569813\n",
      "Test Score: 0.5626241419244007\n",
      "17639.352137187798\n",
      "1146705102.2347007\n",
      "7973.715561363566\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891669318484383\n",
      "Test Score: 0.5627292743407333\n",
      "17639.405664293852\n",
      "1146429467.7295198\n",
      "7988.5523732964175\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890779511699838\n",
      "Test Score: 0.5626814132394167\n",
      "17639.089487022433\n",
      "1146554949.2074409\n",
      "8023.261459490321\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989052181043557\n",
      "Test Score: 0.5627674893354996\n",
      "17640.35404790636\n",
      "1146329276.2610807\n",
      "8020.035854266491\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989133926994796\n",
      "Test Score: 0.5626773775891216\n",
      "17640.94734743183\n",
      "1146565529.811511\n",
      "8011.44997593775\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891261609807853\n",
      "Test Score: 0.5624408678836272\n",
      "17643.75044976431\n",
      "1147185607.214072\n",
      "8008.187047801584\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891047797955934\n",
      "Test Score: 0.5625152747745513\n",
      "17642.882751817004\n",
      "1146990528.4051054\n",
      "8004.598646328526\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890597186436322\n",
      "Test Score: 0.5622656525085323\n",
      "17644.69737412551\n",
      "1147644984.1113143\n",
      "8011.162259947938\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890294132220254\n",
      "Test Score: 0.5623477842959548\n",
      "17642.479146282352\n",
      "1147429652.2909722\n",
      "7979.067991760694\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890380452782005\n",
      "Test Score: 0.5621478532375295\n",
      "17643.745744338834\n",
      "1147953828.3755877\n",
      "7980.895840546025\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890553796833375\n",
      "Test Score: 0.5620856024032018\n",
      "17643.74446551478\n",
      "1148117036.6277673\n",
      "7982.170699423328\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890876317372311\n",
      "Test Score: 0.5621760923086547\n",
      "17642.56650813969\n",
      "1147879791.6258593\n",
      "8000.147277411856\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890611145116439\n",
      "Test Score: 0.5621618005241004\n",
      "17642.645263653758\n",
      "1147917261.6004038\n",
      "7997.905106131595\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890579877379905\n",
      "Test Score: 0.5622103975205632\n",
      "17642.043818594582\n",
      "1147789850.7642357\n",
      "7994.57548827889\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890601949664619\n",
      "Test Score: 0.5621889387850278\n",
      "17641.40808986545\n",
      "1147846110.9374287\n",
      "7982.935237119145\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890400116897238\n",
      "Test Score: 0.562117199395334\n",
      "17641.60132974335\n",
      "1148034196.133889\n",
      "7988.811480829536\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890757266545777\n",
      "Test Score: 0.5620770830037809\n",
      "17640.854892967694\n",
      "1148139372.6543298\n",
      "7995.721828516296\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890473776217598\n",
      "Test Score: 0.5621411418567241\n",
      "17640.32845261072\n",
      "1147971424.1675606\n",
      "8001.666096466783\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890865070764713\n",
      "Test Score: 0.5621961941804936\n",
      "17640.06773211604\n",
      "1147827088.85643\n",
      "8008.910234277617\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890887182574221\n",
      "Test Score: 0.5622765282858863\n",
      "17639.297976195492\n",
      "1147616470.1703813\n",
      "8017.374398505959\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890611789248882\n",
      "Test Score: 0.5623159996880689\n",
      "17638.47522722026\n",
      "1147512984.672864\n",
      "7971.729187818481\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890396127065545\n",
      "Test Score: 0.5623150007338802\n",
      "17640.430001861296\n",
      "1147515603.7151449\n",
      "8006.765269025953\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890438522514103\n",
      "Test Score: 0.5624078784759845\n",
      "17639.72766431383\n",
      "1147272098.3208976\n",
      "7974.087234842082\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889924016788767\n",
      "Test Score: 0.5623616100686275\n",
      "17640.251129600725\n",
      "1147393404.0990033\n",
      "7998.950186095484\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989004526643753\n",
      "Test Score: 0.5625711869152258\n",
      "17638.67355504564\n",
      "1146843938.839622\n",
      "8006.08315310808\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889975523797314\n",
      "Test Score: 0.5626445303447398\n",
      "17638.614839334412\n",
      "1146651648.1969488\n",
      "8006.634930613276\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889983823773671\n",
      "Test Score: 0.5627245559284436\n",
      "17637.525287495417\n",
      "1146441838.3881812\n",
      "7998.217945952201\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889748613362744\n",
      "Test Score: 0.5626273560197156\n",
      "17638.028161630773\n",
      "1146696675.5704749\n",
      "7999.533726092395\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889932038107093\n",
      "Test Score: 0.5626138691834854\n",
      "17638.163857306205\n",
      "1146732035.1442428\n",
      "7984.549986557868\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890374813619444\n",
      "Test Score: 0.5627177632939291\n",
      "17636.506569546546\n",
      "1146459647.2098424\n",
      "7981.014063671268\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890310493467428\n",
      "Test Score: 0.5627270594396436\n",
      "17635.892440034848\n",
      "1146435274.7221403\n",
      "7983.845579823486\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890150612375568\n",
      "Test Score: 0.562519944858227\n",
      "17638.828731271875\n",
      "1146978284.4536395\n",
      "7990.714103385804\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889981555393792\n",
      "Test Score: 0.562553371218846\n",
      "17638.102302714688\n",
      "1146890647.750417\n",
      "7987.60205433503\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890417983377249\n",
      "Test Score: 0.5625628824834228\n",
      "17638.262465059113\n",
      "1146865711.2674868\n",
      "7982.6463884960995\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890536061387232\n",
      "Test Score: 0.5625806626594758\n",
      "17638.743255333644\n",
      "1146819095.4833224\n",
      "7987.839006154485\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890342695620467\n",
      "Test Score: 0.5625175453779212\n",
      "17638.615861342376\n",
      "1146984575.373128\n",
      "7992.2259371649925\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890325200971006\n",
      "Test Score: 0.5625434763353129\n",
      "17638.58450158322\n",
      "1146916589.9994547\n",
      "7988.027304037147\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989026168845397\n",
      "Test Score: 0.5626307036941516\n",
      "17638.282613736865\n",
      "1146687898.6906228\n",
      "7987.766093472026\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890157923575041\n",
      "Test Score: 0.5626170356110987\n",
      "17637.87744912998\n",
      "1146723733.4544423\n",
      "7971.5622855616675\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889937835834772\n",
      "Test Score: 0.5626227633507925\n",
      "17637.92371408923\n",
      "1146708716.5571673\n",
      "7976.076309528504\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890010358244004\n",
      "Test Score: 0.5626077572417902\n",
      "17638.04139461912\n",
      "1146748059.336244\n",
      "7983.474726518958\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889754953481951\n",
      "Test Score: 0.5626877782106974\n",
      "17637.383563780393\n",
      "1146538261.6264772\n",
      "7985.070748060549\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889635775028757\n",
      "Test Score: 0.5627451438865763\n",
      "17635.665422716527\n",
      "1146387861.2054\n",
      "7983.6558719400855\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.98896866416998\n",
      "Test Score: 0.5627924825350445\n",
      "17635.86622821811\n",
      "1146263749.4860876\n",
      "7976.949187660117\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889675359243317\n",
      "Test Score: 0.5628829393781531\n",
      "17634.848888006527\n",
      "1146026591.1665108\n",
      "7971.592910458188\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889542517036629\n",
      "Test Score: 0.5629030254121801\n",
      "17634.062141949875\n",
      "1145973929.9204066\n",
      "7982.936312116835\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889664690248948\n",
      "Test Score: 0.5628580662428357\n",
      "17634.632471867848\n",
      "1146091803.1590126\n",
      "7966.609254190276\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.988985370284622\n",
      "Test Score: 0.5628833232771032\n",
      "17634.61771297675\n",
      "1146025584.6663196\n",
      "7964.907347756285\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889681265989693\n",
      "Test Score: 0.5628671146109563\n",
      "17634.026508625244\n",
      "1146068080.290685\n",
      "7971.668592565678\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889720129037565\n",
      "Test Score: 0.5628448155786929\n",
      "17634.212514404564\n",
      "1146126543.54054\n",
      "7972.850951892608\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889895256273692\n",
      "Test Score: 0.5629146691775325\n",
      "17634.019500366583\n",
      "1145943402.4806945\n",
      "7968.238007029482\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9889887865547361\n",
      "Test Score: 0.5628175446235724\n",
      "17635.264727173744\n",
      "1146198042.09905\n",
      "7974.837338373924\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890145867791365\n",
      "Test Score: 0.5628398204153767\n",
      "17635.135865974215\n",
      "1146139639.7806628\n",
      "7971.395439323576\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890284086933029\n",
      "Test Score: 0.562746030510112\n",
      "17635.498970207598\n",
      "1146385536.669847\n",
      "7974.965650609551\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890355408682477\n",
      "Test Score: 0.5627239110129456\n",
      "17635.689716717774\n",
      "1146443529.2174265\n",
      "7958.997355447318\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890499487316095\n",
      "Test Score: 0.562727941339633\n",
      "17635.5153489038\n",
      "1146432962.5707066\n",
      "7957.7777850064085\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890510064538063\n",
      "Test Score: 0.5627282486713732\n",
      "17635.53366562491\n",
      "1146432156.8132145\n",
      "7954.325060145904\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890782732470961\n",
      "Test Score: 0.5627783789821303\n",
      "17635.630346196536\n",
      "1146300725.9578972\n",
      "7953.652864071766\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890799603228169\n",
      "Test Score: 0.5627845434438845\n",
      "17635.04776858362\n",
      "1146284564.069637\n",
      "7952.088643879841\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890502568627193\n",
      "Test Score: 0.5628349606801497\n",
      "17634.648420422807\n",
      "1146152380.9575646\n",
      "7943.780665287755\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890568134709234\n",
      "Test Score: 0.5628263987226414\n",
      "17635.019271648027\n",
      "1146174828.5622473\n",
      "7951.771249940051\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890683791090442\n",
      "Test Score: 0.5628589953156226\n",
      "17634.425657692314\n",
      "1146089367.3306844\n",
      "7950.967861250738\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890724830383023\n",
      "Test Score: 0.562895136917025\n",
      "17633.904573126136\n",
      "1145994611.8521507\n",
      "7942.124061869792\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890793108344926\n",
      "Test Score: 0.562825812056684\n",
      "17635.30136390776\n",
      "1146176366.673769\n",
      "7943.882300522724\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890687461507504\n",
      "Test Score: 0.5628317177431947\n",
      "17635.157978499938\n",
      "1146160883.2383463\n",
      "7946.674168530204\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890761412686822\n",
      "Test Score: 0.562790147946018\n",
      "17636.08028352933\n",
      "1146269870.2746477\n",
      "7957.866796471899\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890943681828439\n",
      "Test Score: 0.5628261550871201\n",
      "17635.19475658044\n",
      "1146175467.3220012\n",
      "7959.117355001079\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890954112931328\n",
      "Test Score: 0.5628442327034948\n",
      "17634.9509761485\n",
      "1146128071.7135093\n",
      "7952.870439642626\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891168928565541\n",
      "Test Score: 0.5628917897695016\n",
      "17634.700186242084\n",
      "1146003387.3505514\n",
      "7954.546367715138\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891072718048883\n",
      "Test Score: 0.5629150141037491\n",
      "17634.133336033323\n",
      "1145942498.1585991\n",
      "7962.772437995409\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891136398957456\n",
      "Test Score: 0.5629768929772995\n",
      "17633.641351289913\n",
      "1145780265.1072984\n",
      "7960.673042794457\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891149010778102\n",
      "Test Score: 0.5629750266823426\n",
      "17633.589839622782\n",
      "1145785158.1298783\n",
      "7964.736076958143\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891202921956489\n",
      "Test Score: 0.5627652059831575\n",
      "17635.990839528095\n",
      "1146335262.7181118\n",
      "7961.127599261046\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891072215716278\n",
      "Test Score: 0.5628010644693544\n",
      "17635.715642452535\n",
      "1146241249.5065427\n",
      "7964.500166642727\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891051694712633\n",
      "Test Score: 0.5628251468449895\n",
      "17635.658628707395\n",
      "1146178110.715261\n",
      "7964.477299285769\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9890063653429918\n",
      "Test Score: 0.5643531029094933\n",
      "17619.723863496085\n",
      "1142172139.688726\n",
      "7970.282636756447\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9899360398469488\n",
      "Test Score: 0.5650315482868319\n",
      "17626.502104171323\n",
      "1140393402.3363607\n",
      "7947.023592059035\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9895671839284911\n",
      "Test Score: 0.5659924278426609\n",
      "17618.201880376633\n",
      "1137874183.524993\n",
      "7964.240404277736\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9897490756064221\n",
      "Test Score: 0.5640340776478329\n",
      "17640.885625631203\n",
      "1143008555.0704465\n",
      "8002.067345247959\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9896976789813535\n",
      "Test Score: 0.5639397400040689\n",
      "17644.913057134436\n",
      "1143255888.0117595\n",
      "8006.776126014038\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9898952406985466\n",
      "Test Score: 0.5637072893675383\n",
      "17656.66025315119\n",
      "1143865323.4115548\n",
      "8005.4075501545885\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9898298756894413\n",
      "Test Score: 0.5636998495886525\n",
      "17652.860972761606\n",
      "1143884828.9060862\n",
      "8017.9192604276095\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9898170209491796\n",
      "Test Score: 0.5638300396507014\n",
      "17654.868600771802\n",
      "1143543498.6619604\n",
      "8003.954336776364\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9896802731084535\n",
      "Test Score: 0.5637010817887579\n",
      "17652.40037171719\n",
      "1143881598.3433523\n",
      "7996.849861821416\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893335014745726\n",
      "Test Score: 0.5638819818070069\n",
      "17648.031658859683\n",
      "1143407317.5386617\n",
      "8018.5833426732515\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893791068578104\n",
      "Test Score: 0.5638618098374849\n",
      "17651.647622166594\n",
      "1143460204.0890868\n",
      "7995.320117295903\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.98946259581898\n",
      "Test Score: 0.5632653748370421\n",
      "17652.178258075266\n",
      "1145023927.9333072\n",
      "8002.373360479158\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9894769654074735\n",
      "Test Score: 0.563121601225653\n",
      "17649.904540203548\n",
      "1145400871.3121028\n",
      "8013.977763061887\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9894178648174151\n",
      "Test Score: 0.5629630576283229\n",
      "17651.70346481333\n",
      "1145816538.4062693\n",
      "8008.401871830333\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893930982078569\n",
      "Test Score: 0.5629494620771833\n",
      "17653.179915019362\n",
      "1145852183.0070667\n",
      "7967.805607239532\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893331164511311\n",
      "Test Score: 0.5631615545448212\n",
      "17654.67181802835\n",
      "1145296122.3322594\n",
      "7966.926293770009\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893729439723153\n",
      "Test Score: 0.5631588713443059\n",
      "17657.147653840384\n",
      "1145303157.104903\n",
      "7994.766533760307\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893709759724749\n",
      "Test Score: 0.5635264409308489\n",
      "17654.484953435414\n",
      "1144339468.980529\n",
      "7973.981778562042\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893728154558452\n",
      "Test Score: 0.5633786952327144\n",
      "17654.822344519434\n",
      "1144726826.3134863\n",
      "7974.855529893399\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893745129767862\n",
      "Test Score: 0.563119725098192\n",
      "17656.61269038132\n",
      "1145405790.113386\n",
      "7967.891088828841\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9894178736605277\n",
      "Test Score: 0.5632794384171009\n",
      "17654.700908637456\n",
      "1144987056.261697\n",
      "7964.933571208021\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9893476793547004\n",
      "Test Score: 0.5633992744979373\n",
      "17651.951441036934\n",
      "1144672871.921639\n",
      "7953.759179875082\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891988176360816\n",
      "Test Score: 0.5631695618431161\n",
      "17655.236270234578\n",
      "1145275128.9243238\n",
      "7951.453493034298\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892250537784766\n",
      "Test Score: 0.5630458679456779\n",
      "17656.218115309417\n",
      "1145599427.62689\n",
      "7943.54591051006\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892056033965193\n",
      "Test Score: 0.5632262086786025\n",
      "17655.50108167691\n",
      "1145126613.1476104\n",
      "7945.706128011603\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892157318107706\n",
      "Test Score: 0.5630306430375467\n",
      "17657.76926006324\n",
      "1145639344.0500596\n",
      "7957.35824796957\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892804093657638\n",
      "Test Score: 0.5629100603940147\n",
      "17660.368209011267\n",
      "1145955485.716377\n",
      "7966.012754500771\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891946901113048\n",
      "Test Score: 0.5629701172644233\n",
      "17657.37534234493\n",
      "1145798029.5640767\n",
      "7959.473334143357\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891849380335447\n",
      "Test Score: 0.5629438972860079\n",
      "17658.46974863537\n",
      "1145866772.6884952\n",
      "7959.131227657837\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892796721113158\n",
      "Test Score: 0.5628579411976884\n",
      "17659.23189163573\n",
      "1146092131.0004003\n",
      "7958.351192741682\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892732866788725\n",
      "Test Score: 0.5623176380493117\n",
      "17665.35725392997\n",
      "1147508689.243288\n",
      "7958.644606439795\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892497423861992\n",
      "Test Score: 0.5622861929840611\n",
      "17665.355594195888\n",
      "1147591131.4176722\n",
      "7966.093302836736\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892115051728914\n",
      "Test Score: 0.5619945527469475\n",
      "17668.113284392664\n",
      "1148355749.1754665\n",
      "7964.970548855865\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891735969723683\n",
      "Test Score: 0.5620870256192312\n",
      "17665.554908690392\n",
      "1148113305.262507\n",
      "7968.105394579859\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891916447726675\n",
      "Test Score: 0.5620370804320838\n",
      "17664.8240783979\n",
      "1148244250.7636738\n",
      "7958.375650741951\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989210760346049\n",
      "Test Score: 0.5618757249182976\n",
      "17666.4277686673\n",
      "1148667290.0959003\n",
      "7963.406158150123\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892379414740041\n",
      "Test Score: 0.5619405791184429\n",
      "17666.301763654676\n",
      "1148497256.3804247\n",
      "7965.868863958245\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892204046007511\n",
      "Test Score: 0.5618012393378734\n",
      "17667.758764933824\n",
      "1148862575.2117524\n",
      "7958.893132798899\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892180574695034\n",
      "Test Score: 0.5616579007322642\n",
      "17669.350205073788\n",
      "1149238378.0992794\n",
      "7970.919877459406\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892305097638855\n",
      "Test Score: 0.5615503375491208\n",
      "17668.79724878454\n",
      "1149520385.5504127\n",
      "7970.750698064323\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892329977745241\n",
      "Test Score: 0.5614517279121185\n",
      "17670.372183817435\n",
      "1149778918.7359836\n",
      "7970.347838216992\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892461827245538\n",
      "Test Score: 0.5614688581562323\n",
      "17669.51749689893\n",
      "1149734006.9330912\n",
      "7962.246149698575\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892172732153877\n",
      "Test Score: 0.5615897321803945\n",
      "17668.73853340147\n",
      "1149417101.329649\n",
      "7977.608550310415\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892438618297927\n",
      "Test Score: 0.561653433958132\n",
      "17668.45032362506\n",
      "1149250089.0170023\n",
      "7971.169376048674\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892508367293182\n",
      "Test Score: 0.5617132978607651\n",
      "17667.697780367827\n",
      "1149093138.7845616\n",
      "7975.374360994076\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892409632386673\n",
      "Test Score: 0.5616201947498436\n",
      "17668.288199557937\n",
      "1149337235.0472069\n",
      "7970.4876397500675\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989210609264746\n",
      "Test Score: 0.5616662883881496\n",
      "17669.314460116362\n",
      "1149216387.475833\n",
      "7972.030519562044\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989217099899955\n",
      "Test Score: 0.5617249930858617\n",
      "17669.26691028862\n",
      "1149062476.4285066\n",
      "7966.066928110737\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891314874701134\n",
      "Test Score: 0.5617668196918275\n",
      "17669.39026559485\n",
      "1148952816.0949864\n",
      "7964.554464903629\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891428707068526\n",
      "Test Score: 0.5619450829116706\n",
      "17668.853478807527\n",
      "1148485448.4066231\n",
      "7973.896697475807\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989138953620011\n",
      "Test Score: 0.5620830394123136\n",
      "17667.716217139194\n",
      "1148123756.2367125\n",
      "7968.886163950584\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891451784026014\n",
      "Test Score: 0.5621243887224794\n",
      "17667.176289969502\n",
      "1148015347.2697668\n",
      "7974.537165150097\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989134415918309\n",
      "Test Score: 0.561953406377169\n",
      "17668.677022991753\n",
      "1148463626.076517\n",
      "7971.541563032409\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891537974433556\n",
      "Test Score: 0.5619033708173072\n",
      "17668.965231129987\n",
      "1148594808.515436\n",
      "7969.6112417569475\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891930211966145\n",
      "Test Score: 0.5619754325100947\n",
      "17667.708936214476\n",
      "1148405878.309826\n",
      "7971.085334583166\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891757262957789\n",
      "Test Score: 0.561741956677644\n",
      "17669.342324792873\n",
      "1149018001.552059\n",
      "7969.515787949202\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891699841649328\n",
      "Test Score: 0.5615942286821775\n",
      "17671.839100257283\n",
      "1149405312.472442\n",
      "7975.120381136148\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891604501232689\n",
      "Test Score: 0.5616764986006331\n",
      "17670.761219831544\n",
      "1149189618.5023437\n",
      "7975.5587580975125\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989204419612439\n",
      "Test Score: 0.561659197900096\n",
      "17671.120441704592\n",
      "1149234977.2051885\n",
      "7979.0484610984295\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892027318368014\n",
      "Test Score: 0.5617117990398572\n",
      "17670.755276649936\n",
      "1149097068.3694952\n",
      "7980.409513195802\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989194488258461\n",
      "Test Score: 0.5616454460712501\n",
      "17669.94866077784\n",
      "1149271031.532403\n",
      "7981.368393511062\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892087343690629\n",
      "Test Score: 0.5615646323334745\n",
      "17671.22877272962\n",
      "1149482907.7110415\n",
      "7983.0988714993455\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891961556499681\n",
      "Test Score: 0.5616055047589623\n",
      "17671.62910229139\n",
      "1149375749.0327966\n",
      "7981.508761868757\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892003776192438\n",
      "Test Score: 0.5615775429360554\n",
      "17671.638372103334\n",
      "1149449058.8975346\n",
      "7980.513193883049\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891864848096799\n",
      "Test Score: 0.5615677872228084\n",
      "17671.58869056028\n",
      "1149474636.272119\n",
      "7971.590442242278\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892062996304696\n",
      "Test Score: 0.5615684276283615\n",
      "17671.88103746036\n",
      "1149472957.2669759\n",
      "7974.556744273384\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989162312114903\n",
      "Test Score: 0.5616542859909519\n",
      "17671.683828274872\n",
      "1149247855.1708405\n",
      "7976.384627323972\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891512204833207\n",
      "Test Score: 0.5616982922615041\n",
      "17670.62744937757\n",
      "1149132480.227206\n",
      "7992.4480262226225\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891542604165267\n",
      "Test Score: 0.5616933432202504\n",
      "17671.013740890587\n",
      "1149145455.545235\n",
      "7992.402446065635\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891557934797601\n",
      "Test Score: 0.56179363861415\n",
      "17670.00062807499\n",
      "1148882502.6689124\n",
      "7991.209450119473\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891401644811868\n",
      "Test Score: 0.5618002822439592\n",
      "17669.773354210265\n",
      "1148865084.5054288\n",
      "7991.182794346989\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891552658267231\n",
      "Test Score: 0.5618129424499501\n",
      "17669.59266107753\n",
      "1148831892.1777387\n",
      "7984.8004343924185\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891786983123125\n",
      "Test Score: 0.5618325800853474\n",
      "17669.84888218771\n",
      "1148780406.536064\n",
      "7986.862358676411\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891603140903462\n",
      "Test Score: 0.5617792063088067\n",
      "17669.725345973635\n",
      "1148920341.0586367\n",
      "7984.389546176015\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891585330856576\n",
      "Test Score: 0.561767583183985\n",
      "17669.79084747722\n",
      "1148950814.3833323\n",
      "7982.709558809322\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891690559645473\n",
      "Test Score: 0.5618316060265887\n",
      "17669.446816961754\n",
      "1148782960.307901\n",
      "7988.994234657619\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.989175581260099\n",
      "Test Score: 0.5618006097666306\n",
      "17670.231590006668\n",
      "1148864225.8116724\n",
      "7990.77327924422\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9891897662817053\n",
      "Test Score: 0.5617648672827059\n",
      "17670.84799696392\n",
      "1148957934.8903203\n",
      "7988.007566907043\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892083590870306\n",
      "Test Score: 0.5616286598924898\n",
      "17671.501647251942\n",
      "1149315041.270197\n",
      "7981.531710901585\n",
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Train score: 0.9892209932621964\n",
      "Test Score: 0.5616652296016438\n",
      "17671.0715710634\n",
      "1149219163.385536\n",
      "7981.737821960804\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17140/4248062688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mval1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mmse_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmae_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17140/4149244468.py\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model: {type(reg).__name__}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train score: {reg.score(X_train_scaled, y_train)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mse_list = []\n",
    "mae_list = []\n",
    "median_list = []\n",
    "for i in range(5,30):\n",
    "    for j in range(10, 1001, 10):\n",
    "        val1, val2, val3, ypred, model = test_model(RandomForestRegressor(max_depth = i, n_estimators = j, n_jobs = -1, random_state=12), data2)\n",
    "        mse_list.append(val2)\n",
    "        mae_list.append(val1)\n",
    "        median_list.append(val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = []\n",
    "mae_list = []\n",
    "median_list = []\n",
    "for i in range(5,30):\n",
    "    for j in range(10, 1001, 10):\n",
    "        val1, val2, val3, ypred, model = test_model(ExtraTreesRegressor(max_depth = i, n_estimators = j, n_jobs = -1, random_state=12), data2)\n",
    "        mse_list.append(val2)\n",
    "        mae_list.append(val1)\n",
    "        median_list.append(val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loss: 1134900096.0\n",
      "10, 10, 10\n",
      "0\n",
      "MAE: 17468.87109375\n",
      "10, 10, 10\n",
      "1\n",
      "Loss: 1132404864.0\n",
      "20, 10, 10\n",
      "1\n",
      "MAE: 17404.00390625\n",
      "20, 10, 10\n",
      "2\n",
      "MAE: 17266.31640625\n",
      "30, 10, 10\n",
      "3\n",
      "Loss: 1129400576.0\n",
      "40, 10, 10\n",
      "3\n",
      "MAE: 17138.580078125\n",
      "40, 10, 10\n",
      "5\n",
      "MAE: 17116.943359375\n",
      "60, 10, 10\n",
      "7\n",
      "Loss: 1122630656.0\n",
      "80, 10, 10\n",
      "18\n",
      "MAE: 17055.93359375\n",
      "90, 20, 10\n",
      "79\n",
      "Loss: 1121592960.0\n",
      "100, 80, 10\n",
      "79\n",
      "MAE: 17020.73828125\n",
      "100, 80, 10\n",
      "127\n",
      "Loss: 1121553920.0\n",
      "80, 30, 20\n",
      "173\n",
      "Loss: 1121113600.0\n",
      "40, 80, 20\n",
      "188\n",
      "Loss: 1116379136.0\n",
      "90, 90, 20\n",
      "197\n",
      "MAE: 16975.5859375\n",
      "80, 100, 20\n",
      "200\n",
      "Loss: 1107466240.0\n",
      "10, 10, 30\n",
      "633\n",
      "MAE: 16970.791015625\n",
      "40, 40, 70\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17140/3265319407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                     \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0mmodel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_price\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Tests which parameters are best\n",
    "loss_list = []\n",
    "mae_list = []\n",
    "loss_min = 99999999999999999999999999999999999999999999999999999999\n",
    "mae_min = 99999999999999999999999999999999999999999999999999999999\n",
    "for i in range(10, 101, 10):\n",
    "    for j in range(10, 101, 10):\n",
    "        for k in range(10, 101, 10):\n",
    "                    nn = tf.keras.models.Sequential()\n",
    "                    # First hidden layer\n",
    "                    nn.add(tf.keras.layers.Dense(units=19, activation='selu', input_dim=18))\n",
    "                    # Second hidden layer\n",
    "                    nn.add(tf.keras.layers.Dense(units=k, activation='selu'))\n",
    "                    nn.add(tf.keras.layers.Dense(units=j, activation='selu'))\n",
    "                    nn.add(tf.keras.layers.Dense(units=i, activation='selu'))\n",
    "                    # Output layer\n",
    "                    nn.add(tf.keras.layers.Dense(units=1))\n",
    "                    # Compile the model\n",
    "                    nn.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"mae\"])\n",
    "\n",
    "                    # Train the model\n",
    "                    fit_model = nn.fit(X_train_price, y_train, epochs=5, verbose=0)\n",
    "                    model_loss, model_mae = nn.evaluate(X_test_price,y_test,verbose=0)\n",
    "                    loss_list.append(model_loss)\n",
    "                    mae_list.append(model_mae)\n",
    "                    if loss_min > min(loss_list):\n",
    "                        loss_min = min(loss_list)\n",
    "                        print(loss_list.index(loss_min))\n",
    "                        print(f'Loss: {loss_min}')\n",
    "                        print(f'{k}, {j}, {i}')\n",
    "                    if mae_min > min(mae_list):\n",
    "                        mae_min = min(mae_list)\n",
    "                        print(mae_list.index(mae_min))\n",
    "                        print(f'MAE: {mae_min}')\n",
    "                        print(f'{k}, {j}, {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27250.837890625"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7388"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mae_list.index(27479.46484375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000532480.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5768"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss_list.index(4000532480.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.models.Sequential()\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=19, activation='selu', input_dim=18))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=40, activation='selu'))\n",
    "nn.add(tf.keras.layers.Dense(units=40, activation='selu'))\n",
    "nn.add(tf.keras.layers.Dense(units=70, activation='selu'))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "131/131 - 1s - loss: 413819840.0000 - mae: 10008.5850 - 504ms/epoch - 4ms/step\n",
      "Epoch 2/500\n",
      "131/131 - 0s - loss: 66641056.0000 - mae: 3777.0562 - 90ms/epoch - 685us/step\n",
      "Epoch 3/500\n",
      "131/131 - 0s - loss: 48175364.0000 - mae: 3008.6182 - 90ms/epoch - 685us/step\n",
      "Epoch 4/500\n",
      "131/131 - 0s - loss: 51403864.0000 - mae: 2906.7361 - 88ms/epoch - 670us/step\n",
      "Epoch 5/500\n",
      "131/131 - 0s - loss: 44937288.0000 - mae: 2887.0657 - 89ms/epoch - 678us/step\n",
      "Epoch 6/500\n",
      "131/131 - 0s - loss: 47302872.0000 - mae: 2858.3147 - 87ms/epoch - 662us/step\n",
      "Epoch 7/500\n",
      "131/131 - 0s - loss: 44919276.0000 - mae: 2689.7791 - 87ms/epoch - 662us/step\n",
      "Epoch 8/500\n",
      "131/131 - 0s - loss: 46037480.0000 - mae: 2807.3005 - 88ms/epoch - 670us/step\n",
      "Epoch 9/500\n",
      "131/131 - 0s - loss: 42861116.0000 - mae: 2743.7244 - 91ms/epoch - 693us/step\n",
      "Epoch 10/500\n",
      "131/131 - 0s - loss: 42888072.0000 - mae: 2809.6077 - 89ms/epoch - 680us/step\n",
      "Epoch 11/500\n",
      "131/131 - 0s - loss: 46495404.0000 - mae: 2806.9805 - 88ms/epoch - 670us/step\n",
      "Epoch 12/500\n",
      "131/131 - 0s - loss: 43507212.0000 - mae: 2739.3542 - 86ms/epoch - 655us/step\n",
      "Epoch 13/500\n",
      "131/131 - 0s - loss: 42882500.0000 - mae: 2766.5715 - 90ms/epoch - 685us/step\n",
      "Epoch 14/500\n",
      "131/131 - 0s - loss: 45520024.0000 - mae: 2872.3037 - 88ms/epoch - 675us/step\n",
      "Epoch 15/500\n",
      "131/131 - 0s - loss: 42902352.0000 - mae: 2653.0781 - 87ms/epoch - 662us/step\n",
      "Epoch 16/500\n",
      "131/131 - 0s - loss: 43621136.0000 - mae: 2657.6621 - 87ms/epoch - 662us/step\n",
      "Epoch 17/500\n",
      "131/131 - 0s - loss: 44247780.0000 - mae: 2751.8127 - 89ms/epoch - 678us/step\n",
      "Epoch 18/500\n",
      "131/131 - 0s - loss: 43548308.0000 - mae: 2721.8381 - 90ms/epoch - 687us/step\n",
      "Epoch 19/500\n",
      "131/131 - 0s - loss: 43888612.0000 - mae: 2674.4121 - 87ms/epoch - 662us/step\n",
      "Epoch 20/500\n",
      "131/131 - 0s - loss: 44881980.0000 - mae: 2710.6406 - 89ms/epoch - 681us/step\n",
      "Epoch 21/500\n",
      "131/131 - 0s - loss: 41744320.0000 - mae: 2640.3101 - 87ms/epoch - 662us/step\n",
      "Epoch 22/500\n",
      "131/131 - 0s - loss: 41323788.0000 - mae: 2696.1543 - 88ms/epoch - 672us/step\n",
      "Epoch 23/500\n",
      "131/131 - 0s - loss: 43454580.0000 - mae: 2704.4375 - 90ms/epoch - 690us/step\n",
      "Epoch 24/500\n",
      "131/131 - 0s - loss: 43217804.0000 - mae: 2590.9883 - 90ms/epoch - 685us/step\n",
      "Epoch 25/500\n",
      "131/131 - 0s - loss: 40887164.0000 - mae: 2586.3887 - 89ms/epoch - 679us/step\n",
      "Epoch 26/500\n",
      "131/131 - 0s - loss: 42273424.0000 - mae: 2712.9612 - 90ms/epoch - 684us/step\n",
      "Epoch 27/500\n",
      "131/131 - 0s - loss: 41104728.0000 - mae: 2535.2334 - 89ms/epoch - 678us/step\n",
      "Epoch 28/500\n",
      "131/131 - 0s - loss: 42739400.0000 - mae: 2641.5024 - 89ms/epoch - 679us/step\n",
      "Epoch 29/500\n",
      "131/131 - 0s - loss: 41739272.0000 - mae: 2720.3381 - 88ms/epoch - 670us/step\n",
      "Epoch 30/500\n",
      "131/131 - 0s - loss: 42421396.0000 - mae: 2598.1233 - 87ms/epoch - 662us/step\n",
      "Epoch 31/500\n",
      "131/131 - 0s - loss: 46387460.0000 - mae: 2555.8574 - 92ms/epoch - 703us/step\n",
      "Epoch 32/500\n",
      "131/131 - 0s - loss: 40836572.0000 - mae: 2654.5996 - 92ms/epoch - 700us/step\n",
      "Epoch 33/500\n",
      "131/131 - 0s - loss: 40758684.0000 - mae: 2714.8386 - 88ms/epoch - 670us/step\n",
      "Epoch 34/500\n",
      "131/131 - 0s - loss: 40786812.0000 - mae: 2589.1726 - 93ms/epoch - 708us/step\n",
      "Epoch 35/500\n",
      "131/131 - 0s - loss: 42833364.0000 - mae: 2562.4121 - 89ms/epoch - 678us/step\n",
      "Epoch 36/500\n",
      "131/131 - 0s - loss: 41593488.0000 - mae: 2517.2537 - 88ms/epoch - 670us/step\n",
      "Epoch 37/500\n",
      "131/131 - 0s - loss: 40710196.0000 - mae: 2563.0837 - 88ms/epoch - 670us/step\n",
      "Epoch 38/500\n",
      "131/131 - 0s - loss: 42162848.0000 - mae: 2548.6125 - 89ms/epoch - 678us/step\n",
      "Epoch 39/500\n",
      "131/131 - 0s - loss: 42430960.0000 - mae: 2519.8699 - 92ms/epoch - 700us/step\n",
      "Epoch 40/500\n",
      "131/131 - 0s - loss: 40680708.0000 - mae: 2486.0491 - 89ms/epoch - 678us/step\n",
      "Epoch 41/500\n",
      "131/131 - 0s - loss: 44508668.0000 - mae: 2497.2227 - 96ms/epoch - 736us/step\n",
      "Epoch 42/500\n",
      "131/131 - 0s - loss: 40686592.0000 - mae: 2516.9146 - 88ms/epoch - 670us/step\n",
      "Epoch 43/500\n",
      "131/131 - 0s - loss: 40388752.0000 - mae: 2586.3271 - 91ms/epoch - 691us/step\n",
      "Epoch 44/500\n",
      "131/131 - 0s - loss: 44901376.0000 - mae: 2535.2161 - 93ms/epoch - 713us/step\n",
      "Epoch 45/500\n",
      "131/131 - 0s - loss: 40522316.0000 - mae: 2597.7793 - 92ms/epoch - 700us/step\n",
      "Epoch 46/500\n",
      "131/131 - 0s - loss: 40036520.0000 - mae: 2544.1042 - 94ms/epoch - 716us/step\n",
      "Epoch 47/500\n",
      "131/131 - 0s - loss: 40840404.0000 - mae: 2508.0723 - 96ms/epoch - 731us/step\n",
      "Epoch 48/500\n",
      "131/131 - 0s - loss: 39930560.0000 - mae: 2553.4841 - 89ms/epoch - 679us/step\n",
      "Epoch 49/500\n",
      "131/131 - 0s - loss: 43086468.0000 - mae: 2447.5149 - 89ms/epoch - 676us/step\n",
      "Epoch 50/500\n",
      "131/131 - 0s - loss: 40293828.0000 - mae: 2577.6677 - 88ms/epoch - 670us/step\n",
      "Epoch 51/500\n",
      "131/131 - 0s - loss: 40748076.0000 - mae: 2569.1904 - 90ms/epoch - 685us/step\n",
      "Epoch 52/500\n",
      "131/131 - 0s - loss: 39745208.0000 - mae: 2554.2886 - 88ms/epoch - 670us/step\n",
      "Epoch 53/500\n",
      "131/131 - 0s - loss: 40020636.0000 - mae: 2595.2739 - 88ms/epoch - 670us/step\n",
      "Epoch 54/500\n",
      "131/131 - 0s - loss: 40496688.0000 - mae: 2552.0586 - 87ms/epoch - 662us/step\n",
      "Epoch 55/500\n",
      "131/131 - 0s - loss: 39875936.0000 - mae: 2575.9792 - 88ms/epoch - 670us/step\n",
      "Epoch 56/500\n",
      "131/131 - 0s - loss: 40066508.0000 - mae: 2542.6970 - 91ms/epoch - 693us/step\n",
      "Epoch 57/500\n",
      "131/131 - 0s - loss: 39013492.0000 - mae: 2436.3586 - 89ms/epoch - 678us/step\n",
      "Epoch 58/500\n",
      "131/131 - 0s - loss: 37814120.0000 - mae: 2522.6543 - 89ms/epoch - 678us/step\n",
      "Epoch 59/500\n",
      "131/131 - 0s - loss: 39410436.0000 - mae: 2524.7087 - 88ms/epoch - 670us/step\n",
      "Epoch 60/500\n",
      "131/131 - 0s - loss: 40311900.0000 - mae: 2487.8701 - 88ms/epoch - 670us/step\n",
      "Epoch 61/500\n",
      "131/131 - 0s - loss: 39963672.0000 - mae: 2540.9509 - 89ms/epoch - 678us/step\n",
      "Epoch 62/500\n",
      "131/131 - 0s - loss: 40429512.0000 - mae: 2568.9080 - 87ms/epoch - 662us/step\n",
      "Epoch 63/500\n",
      "131/131 - 0s - loss: 39679004.0000 - mae: 2476.1267 - 91ms/epoch - 693us/step\n",
      "Epoch 64/500\n",
      "131/131 - 0s - loss: 43975068.0000 - mae: 2430.7292 - 90ms/epoch - 689us/step\n",
      "Epoch 65/500\n",
      "131/131 - 0s - loss: 40201876.0000 - mae: 2534.8508 - 88ms/epoch - 670us/step\n",
      "Epoch 66/500\n",
      "131/131 - 0s - loss: 40189788.0000 - mae: 2457.3857 - 89ms/epoch - 679us/step\n",
      "Epoch 67/500\n",
      "131/131 - 0s - loss: 40361292.0000 - mae: 2450.7891 - 90ms/epoch - 683us/step\n",
      "Epoch 68/500\n",
      "131/131 - 0s - loss: 40221856.0000 - mae: 2475.8398 - 90ms/epoch - 691us/step\n",
      "Epoch 69/500\n",
      "131/131 - 0s - loss: 39143328.0000 - mae: 2533.9385 - 89ms/epoch - 678us/step\n",
      "Epoch 70/500\n",
      "131/131 - 0s - loss: 40293440.0000 - mae: 2483.6138 - 90ms/epoch - 690us/step\n",
      "Epoch 71/500\n",
      "131/131 - 0s - loss: 39619700.0000 - mae: 2459.7974 - 89ms/epoch - 681us/step\n",
      "Epoch 72/500\n",
      "131/131 - 0s - loss: 42075688.0000 - mae: 2534.7041 - 92ms/epoch - 704us/step\n",
      "Epoch 73/500\n",
      "131/131 - 0s - loss: 40102884.0000 - mae: 2526.6602 - 87ms/epoch - 662us/step\n",
      "Epoch 74/500\n",
      "131/131 - 0s - loss: 39877896.0000 - mae: 2443.8269 - 89ms/epoch - 678us/step\n",
      "Epoch 75/500\n",
      "131/131 - 0s - loss: 40483652.0000 - mae: 2414.8455 - 89ms/epoch - 676us/step\n",
      "Epoch 76/500\n",
      "131/131 - 0s - loss: 38828076.0000 - mae: 2603.2744 - 87ms/epoch - 668us/step\n",
      "Epoch 77/500\n",
      "131/131 - 0s - loss: 39831712.0000 - mae: 2490.1755 - 90ms/epoch - 686us/step\n",
      "Epoch 78/500\n",
      "131/131 - 0s - loss: 39193572.0000 - mae: 2478.1135 - 88ms/epoch - 670us/step\n",
      "Epoch 79/500\n",
      "131/131 - 0s - loss: 38797916.0000 - mae: 2502.5605 - 90ms/epoch - 686us/step\n",
      "Epoch 80/500\n",
      "131/131 - 0s - loss: 41515852.0000 - mae: 2445.8501 - 86ms/epoch - 655us/step\n",
      "Epoch 81/500\n",
      "131/131 - 0s - loss: 40205276.0000 - mae: 2490.6028 - 89ms/epoch - 683us/step\n",
      "Epoch 82/500\n",
      "131/131 - 0s - loss: 39313952.0000 - mae: 2494.6846 - 87ms/epoch - 662us/step\n",
      "Epoch 83/500\n",
      "131/131 - 0s - loss: 38814276.0000 - mae: 2492.3049 - 93ms/epoch - 709us/step\n",
      "Epoch 84/500\n",
      "131/131 - 0s - loss: 39414824.0000 - mae: 2403.2961 - 91ms/epoch - 693us/step\n",
      "Epoch 85/500\n",
      "131/131 - 0s - loss: 39971260.0000 - mae: 2410.1311 - 88ms/epoch - 670us/step\n",
      "Epoch 86/500\n",
      "131/131 - 0s - loss: 40402912.0000 - mae: 2486.5869 - 88ms/epoch - 675us/step\n",
      "Epoch 87/500\n",
      "131/131 - 0s - loss: 38121772.0000 - mae: 2465.6345 - 91ms/epoch - 695us/step\n",
      "Epoch 88/500\n",
      "131/131 - 0s - loss: 39410692.0000 - mae: 2440.6987 - 90ms/epoch - 687us/step\n",
      "Epoch 89/500\n",
      "131/131 - 0s - loss: 40093572.0000 - mae: 2504.3855 - 91ms/epoch - 695us/step\n",
      "Epoch 90/500\n",
      "131/131 - 0s - loss: 38922040.0000 - mae: 2463.7461 - 89ms/epoch - 678us/step\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 - 0s - loss: 40217116.0000 - mae: 2501.6499 - 89ms/epoch - 678us/step\n",
      "Epoch 92/500\n",
      "131/131 - 0s - loss: 38890988.0000 - mae: 2432.4072 - 88ms/epoch - 670us/step\n",
      "Epoch 93/500\n",
      "131/131 - 0s - loss: 38829612.0000 - mae: 2466.9846 - 89ms/epoch - 678us/step\n",
      "Epoch 94/500\n",
      "131/131 - 0s - loss: 39157160.0000 - mae: 2428.0146 - 89ms/epoch - 680us/step\n",
      "Epoch 95/500\n",
      "131/131 - 0s - loss: 40021308.0000 - mae: 2511.1584 - 87ms/epoch - 663us/step\n",
      "Epoch 96/500\n",
      "131/131 - 0s - loss: 38188224.0000 - mae: 2302.0029 - 88ms/epoch - 670us/step\n",
      "Epoch 97/500\n",
      "131/131 - 0s - loss: 40745340.0000 - mae: 2396.6331 - 93ms/epoch - 708us/step\n",
      "Epoch 98/500\n",
      "131/131 - 0s - loss: 39442832.0000 - mae: 2446.2456 - 89ms/epoch - 678us/step\n",
      "Epoch 99/500\n",
      "131/131 - 0s - loss: 39584692.0000 - mae: 2413.5842 - 91ms/epoch - 694us/step\n",
      "Epoch 100/500\n",
      "131/131 - 0s - loss: 38742256.0000 - mae: 2492.0171 - 93ms/epoch - 708us/step\n",
      "Epoch 101/500\n",
      "131/131 - 0s - loss: 38650044.0000 - mae: 2486.7151 - 89ms/epoch - 679us/step\n",
      "Epoch 102/500\n",
      "131/131 - 0s - loss: 39548244.0000 - mae: 2485.2585 - 89ms/epoch - 678us/step\n",
      "Epoch 103/500\n",
      "131/131 - 0s - loss: 39216380.0000 - mae: 2402.5447 - 89ms/epoch - 678us/step\n",
      "Epoch 104/500\n",
      "131/131 - 0s - loss: 39352132.0000 - mae: 2451.1025 - 90ms/epoch - 685us/step\n",
      "Epoch 105/500\n",
      "131/131 - 0s - loss: 40626288.0000 - mae: 2391.3792 - 92ms/epoch - 700us/step\n",
      "Epoch 106/500\n",
      "131/131 - 0s - loss: 39129916.0000 - mae: 2443.5774 - 88ms/epoch - 670us/step\n",
      "Epoch 107/500\n",
      "131/131 - 0s - loss: 41309516.0000 - mae: 2443.9893 - 89ms/epoch - 678us/step\n",
      "Epoch 108/500\n",
      "131/131 - 0s - loss: 38739780.0000 - mae: 2444.5154 - 90ms/epoch - 685us/step\n",
      "Epoch 109/500\n",
      "131/131 - 0s - loss: 38981320.0000 - mae: 2420.9609 - 87ms/epoch - 662us/step\n",
      "Epoch 110/500\n",
      "131/131 - 0s - loss: 38453348.0000 - mae: 2443.8511 - 87ms/epoch - 662us/step\n",
      "Epoch 111/500\n",
      "131/131 - 0s - loss: 38333260.0000 - mae: 2410.0537 - 89ms/epoch - 678us/step\n",
      "Epoch 112/500\n",
      "131/131 - 0s - loss: 38908456.0000 - mae: 2454.6379 - 94ms/epoch - 716us/step\n",
      "Epoch 113/500\n",
      "131/131 - 0s - loss: 40660420.0000 - mae: 2436.3167 - 88ms/epoch - 670us/step\n",
      "Epoch 114/500\n",
      "131/131 - 0s - loss: 38440440.0000 - mae: 2476.5581 - 88ms/epoch - 670us/step\n",
      "Epoch 115/500\n",
      "131/131 - 0s - loss: 39178088.0000 - mae: 2407.8792 - 89ms/epoch - 678us/step\n",
      "Epoch 116/500\n",
      "131/131 - 0s - loss: 42739152.0000 - mae: 2431.5449 - 88ms/epoch - 670us/step\n",
      "Epoch 117/500\n",
      "131/131 - 0s - loss: 37709952.0000 - mae: 2404.8906 - 88ms/epoch - 670us/step\n",
      "Epoch 118/500\n",
      "131/131 - 0s - loss: 39838896.0000 - mae: 2524.5410 - 92ms/epoch - 700us/step\n",
      "Epoch 119/500\n",
      "131/131 - 0s - loss: 38400052.0000 - mae: 2449.2480 - 88ms/epoch - 670us/step\n",
      "Epoch 120/500\n",
      "131/131 - 0s - loss: 37974124.0000 - mae: 2423.8022 - 90ms/epoch - 690us/step\n",
      "Epoch 121/500\n",
      "131/131 - 0s - loss: 38507028.0000 - mae: 2474.5813 - 88ms/epoch - 670us/step\n",
      "Epoch 122/500\n",
      "131/131 - 0s - loss: 39870124.0000 - mae: 2462.6262 - 88ms/epoch - 675us/step\n",
      "Epoch 123/500\n",
      "131/131 - 0s - loss: 37845804.0000 - mae: 2458.9634 - 91ms/epoch - 693us/step\n",
      "Epoch 124/500\n",
      "131/131 - 0s - loss: 40478872.0000 - mae: 2399.2986 - 91ms/epoch - 693us/step\n",
      "Epoch 125/500\n",
      "131/131 - 0s - loss: 38203152.0000 - mae: 2422.5530 - 91ms/epoch - 692us/step\n",
      "Epoch 126/500\n",
      "131/131 - 0s - loss: 38082248.0000 - mae: 2449.3120 - 88ms/epoch - 673us/step\n",
      "Epoch 127/500\n",
      "131/131 - 0s - loss: 40003688.0000 - mae: 2478.3540 - 87ms/epoch - 662us/step\n",
      "Epoch 128/500\n",
      "131/131 - 0s - loss: 38454288.0000 - mae: 2460.3118 - 91ms/epoch - 691us/step\n",
      "Epoch 129/500\n",
      "131/131 - 0s - loss: 37684708.0000 - mae: 2424.1511 - 90ms/epoch - 683us/step\n",
      "Epoch 130/500\n",
      "131/131 - 0s - loss: 39086828.0000 - mae: 2501.5537 - 93ms/epoch - 708us/step\n",
      "Epoch 131/500\n",
      "131/131 - 0s - loss: 38710752.0000 - mae: 2473.3894 - 91ms/epoch - 695us/step\n",
      "Epoch 132/500\n",
      "131/131 - 0s - loss: 39496772.0000 - mae: 2448.2109 - 91ms/epoch - 693us/step\n",
      "Epoch 133/500\n",
      "131/131 - 0s - loss: 37427948.0000 - mae: 2454.2388 - 90ms/epoch - 685us/step\n",
      "Epoch 134/500\n",
      "131/131 - 0s - loss: 38273580.0000 - mae: 2418.5581 - 90ms/epoch - 686us/step\n",
      "Epoch 135/500\n",
      "131/131 - 0s - loss: 41863444.0000 - mae: 2355.2075 - 90ms/epoch - 684us/step\n",
      "Epoch 136/500\n",
      "131/131 - 0s - loss: 39090872.0000 - mae: 2398.9492 - 89ms/epoch - 678us/step\n",
      "Epoch 137/500\n",
      "131/131 - 0s - loss: 38189596.0000 - mae: 2485.4426 - 90ms/epoch - 687us/step\n",
      "Epoch 138/500\n",
      "131/131 - 0s - loss: 38884900.0000 - mae: 2512.2500 - 90ms/epoch - 685us/step\n",
      "Epoch 139/500\n",
      "131/131 - 0s - loss: 39141260.0000 - mae: 2446.0471 - 88ms/epoch - 669us/step\n",
      "Epoch 140/500\n",
      "131/131 - 0s - loss: 39200272.0000 - mae: 2486.7524 - 88ms/epoch - 671us/step\n",
      "Epoch 141/500\n",
      "131/131 - 0s - loss: 38771636.0000 - mae: 2446.8618 - 86ms/epoch - 655us/step\n",
      "Epoch 142/500\n",
      "131/131 - 0s - loss: 38261384.0000 - mae: 2374.9202 - 90ms/epoch - 684us/step\n",
      "Epoch 143/500\n",
      "131/131 - 0s - loss: 38282328.0000 - mae: 2417.5942 - 88ms/epoch - 673us/step\n",
      "Epoch 144/500\n",
      "131/131 - 0s - loss: 37824800.0000 - mae: 2374.9177 - 87ms/epoch - 662us/step\n",
      "Epoch 145/500\n",
      "131/131 - 0s - loss: 38305764.0000 - mae: 2424.5024 - 89ms/epoch - 680us/step\n",
      "Epoch 146/500\n",
      "131/131 - 0s - loss: 38130248.0000 - mae: 2421.6375 - 88ms/epoch - 670us/step\n",
      "Epoch 147/500\n",
      "131/131 - 0s - loss: 38859156.0000 - mae: 2378.5029 - 91ms/epoch - 693us/step\n",
      "Epoch 148/500\n",
      "131/131 - 0s - loss: 39249088.0000 - mae: 2441.9236 - 88ms/epoch - 670us/step\n",
      "Epoch 149/500\n",
      "131/131 - 0s - loss: 37939828.0000 - mae: 2401.1694 - 88ms/epoch - 670us/step\n",
      "Epoch 150/500\n",
      "131/131 - 0s - loss: 38235508.0000 - mae: 2420.2673 - 89ms/epoch - 678us/step\n",
      "Epoch 151/500\n",
      "131/131 - 0s - loss: 37278756.0000 - mae: 2416.6018 - 88ms/epoch - 674us/step\n",
      "Epoch 152/500\n",
      "131/131 - 0s - loss: 38555712.0000 - mae: 2449.8921 - 88ms/epoch - 670us/step\n",
      "Epoch 153/500\n",
      "131/131 - 0s - loss: 38739980.0000 - mae: 2379.3411 - 89ms/epoch - 678us/step\n",
      "Epoch 154/500\n",
      "131/131 - 0s - loss: 37000052.0000 - mae: 2377.4351 - 88ms/epoch - 670us/step\n",
      "Epoch 155/500\n",
      "131/131 - 0s - loss: 38854284.0000 - mae: 2383.7563 - 89ms/epoch - 678us/step\n",
      "Epoch 156/500\n",
      "131/131 - 0s - loss: 37277852.0000 - mae: 2372.1863 - 88ms/epoch - 670us/step\n",
      "Epoch 157/500\n",
      "131/131 - 0s - loss: 38085440.0000 - mae: 2354.7336 - 90ms/epoch - 685us/step\n",
      "Epoch 158/500\n",
      "131/131 - 0s - loss: 37289456.0000 - mae: 2423.9128 - 87ms/epoch - 667us/step\n",
      "Epoch 159/500\n",
      "131/131 - 0s - loss: 38137812.0000 - mae: 2450.2073 - 89ms/epoch - 679us/step\n",
      "Epoch 160/500\n",
      "131/131 - 0s - loss: 39174976.0000 - mae: 2408.2095 - 91ms/epoch - 692us/step\n",
      "Epoch 161/500\n",
      "131/131 - 0s - loss: 40183324.0000 - mae: 2345.6987 - 88ms/epoch - 670us/step\n",
      "Epoch 162/500\n",
      "131/131 - 0s - loss: 39015832.0000 - mae: 2462.4690 - 87ms/epoch - 662us/step\n",
      "Epoch 163/500\n",
      "131/131 - 0s - loss: 39078024.0000 - mae: 2420.5564 - 87ms/epoch - 662us/step\n",
      "Epoch 164/500\n",
      "131/131 - 0s - loss: 37778236.0000 - mae: 2349.3398 - 91ms/epoch - 698us/step\n",
      "Epoch 165/500\n",
      "131/131 - 0s - loss: 39206576.0000 - mae: 2367.3044 - 92ms/epoch - 700us/step\n",
      "Epoch 166/500\n",
      "131/131 - 0s - loss: 38153468.0000 - mae: 2402.1360 - 89ms/epoch - 678us/step\n",
      "Epoch 167/500\n",
      "131/131 - 0s - loss: 38097892.0000 - mae: 2458.7922 - 88ms/epoch - 668us/step\n",
      "Epoch 168/500\n",
      "131/131 - 0s - loss: 37304308.0000 - mae: 2364.2922 - 90ms/epoch - 686us/step\n",
      "Epoch 169/500\n",
      "131/131 - 0s - loss: 38558492.0000 - mae: 2396.4185 - 88ms/epoch - 671us/step\n",
      "Epoch 170/500\n",
      "131/131 - 0s - loss: 36906664.0000 - mae: 2404.3584 - 90ms/epoch - 686us/step\n",
      "Epoch 171/500\n",
      "131/131 - 0s - loss: 38595448.0000 - mae: 2395.7681 - 89ms/epoch - 678us/step\n",
      "Epoch 172/500\n",
      "131/131 - 0s - loss: 37621916.0000 - mae: 2477.7671 - 88ms/epoch - 670us/step\n",
      "Epoch 173/500\n",
      "131/131 - 0s - loss: 38042856.0000 - mae: 2403.6179 - 90ms/epoch - 687us/step\n",
      "Epoch 174/500\n",
      "131/131 - 0s - loss: 39495528.0000 - mae: 2357.2732 - 88ms/epoch - 670us/step\n",
      "Epoch 175/500\n",
      "131/131 - 0s - loss: 38254096.0000 - mae: 2400.8928 - 90ms/epoch - 689us/step\n",
      "Epoch 176/500\n",
      "131/131 - 0s - loss: 39555996.0000 - mae: 2399.5107 - 88ms/epoch - 670us/step\n",
      "Epoch 177/500\n",
      "131/131 - 0s - loss: 38008352.0000 - mae: 2406.6243 - 92ms/epoch - 706us/step\n",
      "Epoch 178/500\n",
      "131/131 - 0s - loss: 36903356.0000 - mae: 2440.4202 - 90ms/epoch - 685us/step\n",
      "Epoch 179/500\n",
      "131/131 - 0s - loss: 37355312.0000 - mae: 2379.5120 - 95ms/epoch - 721us/step\n",
      "Epoch 180/500\n",
      "131/131 - 0s - loss: 38589808.0000 - mae: 2371.5728 - 88ms/epoch - 670us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "131/131 - 0s - loss: 39654400.0000 - mae: 2406.8438 - 91ms/epoch - 693us/step\n",
      "Epoch 182/500\n",
      "131/131 - 0s - loss: 37949360.0000 - mae: 2374.6157 - 88ms/epoch - 670us/step\n",
      "Epoch 183/500\n",
      "131/131 - 0s - loss: 38605644.0000 - mae: 2439.1436 - 87ms/epoch - 662us/step\n",
      "Epoch 184/500\n",
      "131/131 - 0s - loss: 38321696.0000 - mae: 2415.4446 - 88ms/epoch - 670us/step\n",
      "Epoch 185/500\n",
      "131/131 - 0s - loss: 36508160.0000 - mae: 2363.6411 - 89ms/epoch - 678us/step\n",
      "Epoch 186/500\n",
      "131/131 - 0s - loss: 38180608.0000 - mae: 2382.3889 - 88ms/epoch - 675us/step\n",
      "Epoch 187/500\n",
      "131/131 - 0s - loss: 38464940.0000 - mae: 2378.0342 - 87ms/epoch - 662us/step\n",
      "Epoch 188/500\n",
      "131/131 - 0s - loss: 37749464.0000 - mae: 2489.4805 - 89ms/epoch - 682us/step\n",
      "Epoch 189/500\n",
      "131/131 - 0s - loss: 38586588.0000 - mae: 2403.4395 - 91ms/epoch - 697us/step\n",
      "Epoch 190/500\n",
      "131/131 - 0s - loss: 38345424.0000 - mae: 2388.1331 - 91ms/epoch - 693us/step\n",
      "Epoch 191/500\n",
      "131/131 - 0s - loss: 39399644.0000 - mae: 2480.9602 - 91ms/epoch - 694us/step\n",
      "Epoch 192/500\n",
      "131/131 - 0s - loss: 38743688.0000 - mae: 2435.0251 - 90ms/epoch - 689us/step\n",
      "Epoch 193/500\n",
      "131/131 - 0s - loss: 38817248.0000 - mae: 2446.7886 - 92ms/epoch - 700us/step\n",
      "Epoch 194/500\n",
      "131/131 - 0s - loss: 38467448.0000 - mae: 2347.4275 - 93ms/epoch - 708us/step\n",
      "Epoch 195/500\n",
      "131/131 - 0s - loss: 38292168.0000 - mae: 2350.0227 - 89ms/epoch - 678us/step\n",
      "Epoch 196/500\n",
      "131/131 - 0s - loss: 37986084.0000 - mae: 2410.5022 - 89ms/epoch - 678us/step\n",
      "Epoch 197/500\n",
      "131/131 - 0s - loss: 37902864.0000 - mae: 2378.3215 - 89ms/epoch - 678us/step\n",
      "Epoch 198/500\n",
      "131/131 - 0s - loss: 38491320.0000 - mae: 2421.0212 - 88ms/epoch - 675us/step\n",
      "Epoch 199/500\n",
      "131/131 - 0s - loss: 37825916.0000 - mae: 2403.8269 - 89ms/epoch - 678us/step\n",
      "Epoch 200/500\n",
      "131/131 - 0s - loss: 39706024.0000 - mae: 2388.5728 - 88ms/epoch - 671us/step\n",
      "Epoch 201/500\n",
      "131/131 - 0s - loss: 37556496.0000 - mae: 2354.8455 - 88ms/epoch - 670us/step\n",
      "Epoch 202/500\n",
      "131/131 - 0s - loss: 38290100.0000 - mae: 2439.1604 - 89ms/epoch - 678us/step\n",
      "Epoch 203/500\n",
      "131/131 - 0s - loss: 38391440.0000 - mae: 2445.1938 - 90ms/epoch - 685us/step\n",
      "Epoch 204/500\n",
      "131/131 - 0s - loss: 38537260.0000 - mae: 2363.3035 - 89ms/epoch - 676us/step\n",
      "Epoch 205/500\n",
      "131/131 - 0s - loss: 37583396.0000 - mae: 2387.9717 - 87ms/epoch - 662us/step\n",
      "Epoch 206/500\n",
      "131/131 - 0s - loss: 38175772.0000 - mae: 2354.7891 - 86ms/epoch - 655us/step\n",
      "Epoch 207/500\n",
      "131/131 - 0s - loss: 37950420.0000 - mae: 2390.2312 - 87ms/epoch - 662us/step\n",
      "Epoch 208/500\n",
      "131/131 - 0s - loss: 37262888.0000 - mae: 2318.8186 - 87ms/epoch - 662us/step\n",
      "Epoch 209/500\n",
      "131/131 - 0s - loss: 36651080.0000 - mae: 2479.5872 - 88ms/epoch - 670us/step\n",
      "Epoch 210/500\n",
      "131/131 - 0s - loss: 37661496.0000 - mae: 2342.9983 - 87ms/epoch - 662us/step\n",
      "Epoch 211/500\n",
      "131/131 - 0s - loss: 39260692.0000 - mae: 2345.2849 - 88ms/epoch - 670us/step\n",
      "Epoch 212/500\n",
      "131/131 - 0s - loss: 38271704.0000 - mae: 2342.6255 - 87ms/epoch - 662us/step\n",
      "Epoch 213/500\n",
      "131/131 - 0s - loss: 38678936.0000 - mae: 2419.3796 - 87ms/epoch - 662us/step\n",
      "Epoch 214/500\n",
      "131/131 - 0s - loss: 38653352.0000 - mae: 2266.1528 - 87ms/epoch - 662us/step\n",
      "Epoch 215/500\n",
      "131/131 - 0s - loss: 37947172.0000 - mae: 2387.6858 - 89ms/epoch - 677us/step\n",
      "Epoch 216/500\n",
      "131/131 - 0s - loss: 36931032.0000 - mae: 2470.5952 - 89ms/epoch - 678us/step\n",
      "Epoch 217/500\n",
      "131/131 - 0s - loss: 38819728.0000 - mae: 2424.6870 - 87ms/epoch - 668us/step\n",
      "Epoch 218/500\n",
      "131/131 - 0s - loss: 39362356.0000 - mae: 2391.8252 - 88ms/epoch - 670us/step\n",
      "Epoch 219/500\n",
      "131/131 - 0s - loss: 39036452.0000 - mae: 2401.8965 - 88ms/epoch - 670us/step\n",
      "Epoch 220/500\n",
      "131/131 - 0s - loss: 37818844.0000 - mae: 2398.0864 - 89ms/epoch - 678us/step\n",
      "Epoch 221/500\n",
      "131/131 - 0s - loss: 38392888.0000 - mae: 2435.2644 - 87ms/epoch - 662us/step\n",
      "Epoch 222/500\n",
      "131/131 - 0s - loss: 38768404.0000 - mae: 2402.1929 - 89ms/epoch - 678us/step\n",
      "Epoch 223/500\n",
      "131/131 - 0s - loss: 37231040.0000 - mae: 2348.5935 - 88ms/epoch - 670us/step\n",
      "Epoch 224/500\n",
      "131/131 - 0s - loss: 37291160.0000 - mae: 2378.4788 - 91ms/epoch - 693us/step\n",
      "Epoch 225/500\n",
      "131/131 - 0s - loss: 38168008.0000 - mae: 2396.4097 - 94ms/epoch - 715us/step\n",
      "Epoch 226/500\n",
      "131/131 - 0s - loss: 37536196.0000 - mae: 2388.2917 - 88ms/epoch - 670us/step\n",
      "Epoch 227/500\n",
      "131/131 - 0s - loss: 37873044.0000 - mae: 2378.2029 - 93ms/epoch - 708us/step\n",
      "Epoch 228/500\n",
      "131/131 - 0s - loss: 38191636.0000 - mae: 2340.0708 - 87ms/epoch - 661us/step\n",
      "Epoch 229/500\n",
      "131/131 - 0s - loss: 36769348.0000 - mae: 2377.5964 - 88ms/epoch - 670us/step\n",
      "Epoch 230/500\n",
      "131/131 - 0s - loss: 38679316.0000 - mae: 2409.2090 - 92ms/epoch - 700us/step\n",
      "Epoch 231/500\n",
      "131/131 - 0s - loss: 37407664.0000 - mae: 2376.1118 - 91ms/epoch - 693us/step\n",
      "Epoch 232/500\n",
      "131/131 - 0s - loss: 37224568.0000 - mae: 2395.2837 - 93ms/epoch - 708us/step\n",
      "Epoch 233/500\n",
      "131/131 - 0s - loss: 37191284.0000 - mae: 2380.6719 - 89ms/epoch - 677us/step\n",
      "Epoch 234/500\n",
      "131/131 - 0s - loss: 36873104.0000 - mae: 2360.7253 - 87ms/epoch - 662us/step\n",
      "Epoch 235/500\n",
      "131/131 - 0s - loss: 37513748.0000 - mae: 2384.4995 - 88ms/epoch - 670us/step\n",
      "Epoch 236/500\n",
      "131/131 - 0s - loss: 36806376.0000 - mae: 2336.2566 - 89ms/epoch - 678us/step\n",
      "Epoch 237/500\n",
      "131/131 - 0s - loss: 37052664.0000 - mae: 2393.7986 - 86ms/epoch - 655us/step\n",
      "Epoch 238/500\n",
      "131/131 - 0s - loss: 37371660.0000 - mae: 2351.3567 - 89ms/epoch - 682us/step\n",
      "Epoch 239/500\n",
      "131/131 - 0s - loss: 37898592.0000 - mae: 2387.8955 - 90ms/epoch - 683us/step\n",
      "Epoch 240/500\n",
      "131/131 - 0s - loss: 37341036.0000 - mae: 2398.3691 - 87ms/epoch - 662us/step\n",
      "Epoch 241/500\n",
      "131/131 - 0s - loss: 37815352.0000 - mae: 2366.3669 - 89ms/epoch - 678us/step\n",
      "Epoch 242/500\n",
      "131/131 - 0s - loss: 37763152.0000 - mae: 2348.8750 - 88ms/epoch - 670us/step\n",
      "Epoch 243/500\n",
      "131/131 - 0s - loss: 37217216.0000 - mae: 2378.8525 - 88ms/epoch - 670us/step\n",
      "Epoch 244/500\n",
      "131/131 - 0s - loss: 37173536.0000 - mae: 2333.7229 - 87ms/epoch - 662us/step\n",
      "Epoch 245/500\n",
      "131/131 - 0s - loss: 37480160.0000 - mae: 2330.7412 - 88ms/epoch - 670us/step\n",
      "Epoch 246/500\n",
      "131/131 - 0s - loss: 37568364.0000 - mae: 2369.9321 - 87ms/epoch - 662us/step\n",
      "Epoch 247/500\n",
      "131/131 - 0s - loss: 39114476.0000 - mae: 2350.5542 - 90ms/epoch - 688us/step\n",
      "Epoch 248/500\n",
      "131/131 - 0s - loss: 37475848.0000 - mae: 2292.5471 - 89ms/epoch - 679us/step\n",
      "Epoch 249/500\n",
      "131/131 - 0s - loss: 38941068.0000 - mae: 2323.9692 - 87ms/epoch - 662us/step\n",
      "Epoch 250/500\n",
      "131/131 - 0s - loss: 37745244.0000 - mae: 2331.3904 - 89ms/epoch - 678us/step\n",
      "Epoch 251/500\n",
      "131/131 - 0s - loss: 37573508.0000 - mae: 2371.5847 - 94ms/epoch - 717us/step\n",
      "Epoch 252/500\n",
      "131/131 - 0s - loss: 37408092.0000 - mae: 2399.4055 - 89ms/epoch - 678us/step\n",
      "Epoch 253/500\n",
      "131/131 - 0s - loss: 37741400.0000 - mae: 2330.1973 - 88ms/epoch - 670us/step\n",
      "Epoch 254/500\n",
      "131/131 - 0s - loss: 39139920.0000 - mae: 2363.8892 - 91ms/epoch - 695us/step\n",
      "Epoch 255/500\n",
      "131/131 - 0s - loss: 37855172.0000 - mae: 2371.6909 - 89ms/epoch - 678us/step\n",
      "Epoch 256/500\n",
      "131/131 - 0s - loss: 38519736.0000 - mae: 2334.6387 - 88ms/epoch - 670us/step\n",
      "Epoch 257/500\n",
      "131/131 - 0s - loss: 37058224.0000 - mae: 2359.1907 - 91ms/epoch - 693us/step\n",
      "Epoch 258/500\n",
      "131/131 - 0s - loss: 38128360.0000 - mae: 2372.0552 - 95ms/epoch - 723us/step\n",
      "Epoch 259/500\n",
      "131/131 - 0s - loss: 37774220.0000 - mae: 2292.9775 - 90ms/epoch - 685us/step\n",
      "Epoch 260/500\n",
      "131/131 - 0s - loss: 37387616.0000 - mae: 2361.3433 - 91ms/epoch - 693us/step\n",
      "Epoch 261/500\n",
      "131/131 - 0s - loss: 38714348.0000 - mae: 2429.2744 - 94ms/epoch - 716us/step\n",
      "Epoch 262/500\n",
      "131/131 - 0s - loss: 37243724.0000 - mae: 2413.8833 - 89ms/epoch - 678us/step\n",
      "Epoch 263/500\n",
      "131/131 - 0s - loss: 37033624.0000 - mae: 2362.3696 - 89ms/epoch - 678us/step\n",
      "Epoch 264/500\n",
      "131/131 - 0s - loss: 37773280.0000 - mae: 2304.0376 - 88ms/epoch - 670us/step\n",
      "Epoch 265/500\n",
      "131/131 - 0s - loss: 37630884.0000 - mae: 2372.6462 - 88ms/epoch - 668us/step\n",
      "Epoch 266/500\n",
      "131/131 - 0s - loss: 37463960.0000 - mae: 2371.0547 - 89ms/epoch - 676us/step\n",
      "Epoch 267/500\n",
      "131/131 - 0s - loss: 37034100.0000 - mae: 2374.2478 - 89ms/epoch - 677us/step\n",
      "Epoch 268/500\n",
      "131/131 - 0s - loss: 37818996.0000 - mae: 2360.4045 - 87ms/epoch - 662us/step\n",
      "Epoch 269/500\n",
      "131/131 - 0s - loss: 37066736.0000 - mae: 2400.6431 - 89ms/epoch - 678us/step\n",
      "Epoch 270/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 - 0s - loss: 37224536.0000 - mae: 2397.6257 - 92ms/epoch - 700us/step\n",
      "Epoch 271/500\n",
      "131/131 - 0s - loss: 37572240.0000 - mae: 2374.0938 - 89ms/epoch - 679us/step\n",
      "Epoch 272/500\n",
      "131/131 - 0s - loss: 37713112.0000 - mae: 2322.3884 - 89ms/epoch - 682us/step\n",
      "Epoch 273/500\n",
      "131/131 - 0s - loss: 37339140.0000 - mae: 2394.3398 - 89ms/epoch - 679us/step\n",
      "Epoch 274/500\n",
      "131/131 - 0s - loss: 37257252.0000 - mae: 2311.7178 - 91ms/epoch - 693us/step\n",
      "Epoch 275/500\n",
      "131/131 - 0s - loss: 37765976.0000 - mae: 2352.2695 - 93ms/epoch - 708us/step\n",
      "Epoch 276/500\n",
      "131/131 - 0s - loss: 38106376.0000 - mae: 2317.5693 - 90ms/epoch - 685us/step\n",
      "Epoch 277/500\n",
      "131/131 - 0s - loss: 37953416.0000 - mae: 2371.6924 - 89ms/epoch - 678us/step\n",
      "Epoch 278/500\n",
      "131/131 - 0s - loss: 36298732.0000 - mae: 2408.2239 - 90ms/epoch - 691us/step\n",
      "Epoch 279/500\n",
      "131/131 - 0s - loss: 37052972.0000 - mae: 2368.9995 - 88ms/epoch - 670us/step\n",
      "Epoch 280/500\n",
      "131/131 - 0s - loss: 37961348.0000 - mae: 2369.3528 - 92ms/epoch - 700us/step\n",
      "Epoch 281/500\n",
      "131/131 - 0s - loss: 36047392.0000 - mae: 2390.1279 - 90ms/epoch - 685us/step\n",
      "Epoch 282/500\n",
      "131/131 - 0s - loss: 37308304.0000 - mae: 2342.6958 - 88ms/epoch - 670us/step\n",
      "Epoch 283/500\n",
      "131/131 - 0s - loss: 38104456.0000 - mae: 2398.4321 - 91ms/epoch - 693us/step\n",
      "Epoch 284/500\n",
      "131/131 - 0s - loss: 36948052.0000 - mae: 2360.2236 - 91ms/epoch - 693us/step\n",
      "Epoch 285/500\n",
      "131/131 - 0s - loss: 36684648.0000 - mae: 2406.8191 - 93ms/epoch - 708us/step\n",
      "Epoch 286/500\n",
      "131/131 - 0s - loss: 37971376.0000 - mae: 2381.4883 - 90ms/epoch - 685us/step\n",
      "Epoch 287/500\n",
      "131/131 - 0s - loss: 39570300.0000 - mae: 2340.4653 - 89ms/epoch - 678us/step\n",
      "Epoch 288/500\n",
      "131/131 - 0s - loss: 36579056.0000 - mae: 2428.2664 - 92ms/epoch - 700us/step\n",
      "Epoch 289/500\n",
      "131/131 - 0s - loss: 37646876.0000 - mae: 2356.0649 - 92ms/epoch - 700us/step\n",
      "Epoch 290/500\n",
      "131/131 - 0s - loss: 37112820.0000 - mae: 2348.1772 - 95ms/epoch - 723us/step\n",
      "Epoch 291/500\n",
      "131/131 - 0s - loss: 37021584.0000 - mae: 2406.3291 - 91ms/epoch - 693us/step\n",
      "Epoch 292/500\n",
      "131/131 - 0s - loss: 38155004.0000 - mae: 2369.3276 - 89ms/epoch - 678us/step\n",
      "Epoch 293/500\n",
      "131/131 - 0s - loss: 36915576.0000 - mae: 2395.4253 - 89ms/epoch - 677us/step\n",
      "Epoch 294/500\n",
      "131/131 - 0s - loss: 37934760.0000 - mae: 2325.8850 - 92ms/epoch - 700us/step\n",
      "Epoch 295/500\n",
      "131/131 - 0s - loss: 37940824.0000 - mae: 2430.5535 - 92ms/epoch - 700us/step\n",
      "Epoch 296/500\n",
      "131/131 - 0s - loss: 37395800.0000 - mae: 2328.8025 - 88ms/epoch - 670us/step\n",
      "Epoch 297/500\n",
      "131/131 - 0s - loss: 39100908.0000 - mae: 2367.5156 - 88ms/epoch - 670us/step\n",
      "Epoch 298/500\n",
      "131/131 - 0s - loss: 37436852.0000 - mae: 2396.7874 - 87ms/epoch - 662us/step\n",
      "Epoch 299/500\n",
      "131/131 - 0s - loss: 37517504.0000 - mae: 2352.6580 - 87ms/epoch - 662us/step\n",
      "Epoch 300/500\n",
      "131/131 - 0s - loss: 37244808.0000 - mae: 2344.6653 - 88ms/epoch - 670us/step\n",
      "Epoch 301/500\n",
      "131/131 - 0s - loss: 37055704.0000 - mae: 2370.8506 - 87ms/epoch - 664us/step\n",
      "Epoch 302/500\n",
      "131/131 - 0s - loss: 37312632.0000 - mae: 2389.1130 - 91ms/epoch - 692us/step\n",
      "Epoch 303/500\n",
      "131/131 - 0s - loss: 37592436.0000 - mae: 2306.6450 - 89ms/epoch - 681us/step\n",
      "Epoch 304/500\n",
      "131/131 - 0s - loss: 38400036.0000 - mae: 2395.9211 - 87ms/epoch - 662us/step\n",
      "Epoch 305/500\n",
      "131/131 - 0s - loss: 38157288.0000 - mae: 2371.1699 - 88ms/epoch - 670us/step\n",
      "Epoch 306/500\n",
      "131/131 - 0s - loss: 37142936.0000 - mae: 2370.7783 - 87ms/epoch - 667us/step\n",
      "Epoch 307/500\n",
      "131/131 - 0s - loss: 37646384.0000 - mae: 2356.1765 - 89ms/epoch - 677us/step\n",
      "Epoch 308/500\n",
      "131/131 - 0s - loss: 37686992.0000 - mae: 2332.6931 - 88ms/epoch - 670us/step\n",
      "Epoch 309/500\n",
      "131/131 - 0s - loss: 37651648.0000 - mae: 2374.6404 - 90ms/epoch - 685us/step\n",
      "Epoch 310/500\n",
      "131/131 - 0s - loss: 38521264.0000 - mae: 2416.7021 - 89ms/epoch - 678us/step\n",
      "Epoch 311/500\n",
      "131/131 - 0s - loss: 38877640.0000 - mae: 2373.7100 - 87ms/epoch - 662us/step\n",
      "Epoch 312/500\n",
      "131/131 - 0s - loss: 37926664.0000 - mae: 2365.7371 - 89ms/epoch - 680us/step\n",
      "Epoch 313/500\n",
      "131/131 - 0s - loss: 37234132.0000 - mae: 2391.2231 - 89ms/epoch - 677us/step\n",
      "Epoch 314/500\n",
      "131/131 - 0s - loss: 37800016.0000 - mae: 2253.4106 - 90ms/epoch - 688us/step\n",
      "Epoch 315/500\n",
      "131/131 - 0s - loss: 37799996.0000 - mae: 2442.7410 - 89ms/epoch - 678us/step\n",
      "Epoch 316/500\n",
      "131/131 - 0s - loss: 36717868.0000 - mae: 2425.9636 - 88ms/epoch - 670us/step\n",
      "Epoch 317/500\n",
      "131/131 - 0s - loss: 37493240.0000 - mae: 2427.2319 - 87ms/epoch - 662us/step\n",
      "Epoch 318/500\n",
      "131/131 - 0s - loss: 37121960.0000 - mae: 2401.5266 - 90ms/epoch - 685us/step\n",
      "Epoch 319/500\n",
      "131/131 - 0s - loss: 37721456.0000 - mae: 2420.5925 - 91ms/epoch - 692us/step\n",
      "Epoch 320/500\n",
      "131/131 - 0s - loss: 37423464.0000 - mae: 2485.6262 - 87ms/epoch - 662us/step\n",
      "Epoch 321/500\n",
      "131/131 - 0s - loss: 37663836.0000 - mae: 2396.0620 - 89ms/epoch - 678us/step\n",
      "Epoch 322/500\n",
      "131/131 - 0s - loss: 37445444.0000 - mae: 2397.4976 - 88ms/epoch - 670us/step\n",
      "Epoch 323/500\n",
      "131/131 - 0s - loss: 38572256.0000 - mae: 2419.7798 - 89ms/epoch - 681us/step\n",
      "Epoch 324/500\n",
      "131/131 - 0s - loss: 38992644.0000 - mae: 2342.2800 - 87ms/epoch - 662us/step\n",
      "Epoch 325/500\n",
      "131/131 - 0s - loss: 36939252.0000 - mae: 2366.9617 - 89ms/epoch - 678us/step\n",
      "Epoch 326/500\n",
      "131/131 - 0s - loss: 38180840.0000 - mae: 2441.9265 - 89ms/epoch - 676us/step\n",
      "Epoch 327/500\n",
      "131/131 - 0s - loss: 37054816.0000 - mae: 2426.9355 - 88ms/epoch - 674us/step\n",
      "Epoch 328/500\n",
      "131/131 - 0s - loss: 37970944.0000 - mae: 2348.7476 - 89ms/epoch - 678us/step\n",
      "Epoch 329/500\n",
      "131/131 - 0s - loss: 37281112.0000 - mae: 2405.5952 - 89ms/epoch - 676us/step\n",
      "Epoch 330/500\n",
      "131/131 - 0s - loss: 37228132.0000 - mae: 2335.3879 - 92ms/epoch - 700us/step\n",
      "Epoch 331/500\n",
      "131/131 - 0s - loss: 38215968.0000 - mae: 2403.0144 - 93ms/epoch - 708us/step\n",
      "Epoch 332/500\n",
      "131/131 - 0s - loss: 38165028.0000 - mae: 2426.2605 - 88ms/epoch - 673us/step\n",
      "Epoch 333/500\n",
      "131/131 - 0s - loss: 37253100.0000 - mae: 2328.1975 - 89ms/epoch - 678us/step\n",
      "Epoch 334/500\n",
      "131/131 - 0s - loss: 37674476.0000 - mae: 2400.3328 - 91ms/epoch - 697us/step\n",
      "Epoch 335/500\n",
      "131/131 - 0s - loss: 37823872.0000 - mae: 2357.9851 - 89ms/epoch - 678us/step\n",
      "Epoch 336/500\n",
      "131/131 - 0s - loss: 38320740.0000 - mae: 2389.6177 - 90ms/epoch - 684us/step\n",
      "Epoch 337/500\n",
      "131/131 - 0s - loss: 37577652.0000 - mae: 2327.2229 - 88ms/epoch - 670us/step\n",
      "Epoch 338/500\n",
      "131/131 - 0s - loss: 36650912.0000 - mae: 2348.0752 - 89ms/epoch - 680us/step\n",
      "Epoch 339/500\n",
      "131/131 - 0s - loss: 36987212.0000 - mae: 2373.6128 - 87ms/epoch - 666us/step\n",
      "Epoch 340/500\n",
      "131/131 - 0s - loss: 37483980.0000 - mae: 2315.4895 - 91ms/epoch - 693us/step\n",
      "Epoch 341/500\n",
      "131/131 - 0s - loss: 37148852.0000 - mae: 2416.8459 - 96ms/epoch - 736us/step\n",
      "Epoch 342/500\n",
      "131/131 - 0s - loss: 40324864.0000 - mae: 2351.9990 - 89ms/epoch - 678us/step\n",
      "Epoch 343/500\n",
      "131/131 - 0s - loss: 36558600.0000 - mae: 2361.4111 - 94ms/epoch - 716us/step\n",
      "Epoch 344/500\n",
      "131/131 - 0s - loss: 37750656.0000 - mae: 2293.5598 - 93ms/epoch - 708us/step\n",
      "Epoch 345/500\n",
      "131/131 - 0s - loss: 37803136.0000 - mae: 2334.6208 - 89ms/epoch - 681us/step\n",
      "Epoch 346/500\n",
      "131/131 - 0s - loss: 38248232.0000 - mae: 2366.4460 - 90ms/epoch - 685us/step\n",
      "Epoch 347/500\n",
      "131/131 - 0s - loss: 38927296.0000 - mae: 2319.8987 - 90ms/epoch - 690us/step\n",
      "Epoch 348/500\n",
      "131/131 - 0s - loss: 36639136.0000 - mae: 2363.1697 - 88ms/epoch - 670us/step\n",
      "Epoch 349/500\n",
      "131/131 - 0s - loss: 38618096.0000 - mae: 2387.1689 - 91ms/epoch - 693us/step\n",
      "Epoch 350/500\n",
      "131/131 - 0s - loss: 37684324.0000 - mae: 2347.7183 - 91ms/epoch - 695us/step\n",
      "Epoch 351/500\n",
      "131/131 - 0s - loss: 38306936.0000 - mae: 2346.6401 - 88ms/epoch - 670us/step\n",
      "Epoch 352/500\n",
      "131/131 - 0s - loss: 36306728.0000 - mae: 2325.6047 - 90ms/epoch - 684us/step\n",
      "Epoch 353/500\n",
      "131/131 - 0s - loss: 37469904.0000 - mae: 2438.4712 - 92ms/epoch - 701us/step\n",
      "Epoch 354/500\n",
      "131/131 - 0s - loss: 36180480.0000 - mae: 2374.5664 - 87ms/epoch - 662us/step\n",
      "Epoch 355/500\n",
      "131/131 - 0s - loss: 37293592.0000 - mae: 2314.3879 - 89ms/epoch - 683us/step\n",
      "Epoch 356/500\n",
      "131/131 - 0s - loss: 38134872.0000 - mae: 2387.0020 - 91ms/epoch - 691us/step\n",
      "Epoch 357/500\n",
      "131/131 - 0s - loss: 37409028.0000 - mae: 2344.4519 - 95ms/epoch - 721us/step\n",
      "Epoch 358/500\n",
      "131/131 - 0s - loss: 37915376.0000 - mae: 2330.2795 - 89ms/epoch - 677us/step\n",
      "Epoch 359/500\n",
      "131/131 - 0s - loss: 37320100.0000 - mae: 2348.6875 - 92ms/epoch - 701us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      "131/131 - 0s - loss: 37718304.0000 - mae: 2387.7483 - 89ms/epoch - 678us/step\n",
      "Epoch 361/500\n",
      "131/131 - 0s - loss: 37738604.0000 - mae: 2302.4521 - 93ms/epoch - 708us/step\n",
      "Epoch 362/500\n",
      "131/131 - 0s - loss: 38550548.0000 - mae: 2355.4578 - 90ms/epoch - 685us/step\n",
      "Epoch 363/500\n",
      "131/131 - 0s - loss: 37490660.0000 - mae: 2379.7080 - 89ms/epoch - 678us/step\n",
      "Epoch 364/500\n",
      "131/131 - 0s - loss: 37216828.0000 - mae: 2352.4529 - 89ms/epoch - 678us/step\n",
      "Epoch 365/500\n",
      "131/131 - 0s - loss: 37247172.0000 - mae: 2379.9424 - 96ms/epoch - 732us/step\n",
      "Epoch 366/500\n",
      "131/131 - 0s - loss: 41782952.0000 - mae: 2375.9265 - 95ms/epoch - 723us/step\n",
      "Epoch 367/500\n",
      "131/131 - 0s - loss: 39647084.0000 - mae: 2347.2629 - 95ms/epoch - 723us/step\n",
      "Epoch 368/500\n",
      "131/131 - 0s - loss: 36660816.0000 - mae: 2341.7207 - 93ms/epoch - 708us/step\n",
      "Epoch 369/500\n",
      "131/131 - 0s - loss: 37135020.0000 - mae: 2327.4302 - 93ms/epoch - 708us/step\n",
      "Epoch 370/500\n",
      "131/131 - 0s - loss: 36516380.0000 - mae: 2339.2478 - 93ms/epoch - 708us/step\n",
      "Epoch 371/500\n",
      "131/131 - 0s - loss: 37254580.0000 - mae: 2348.5493 - 91ms/epoch - 693us/step\n",
      "Epoch 372/500\n",
      "131/131 - 0s - loss: 37017920.0000 - mae: 2343.9744 - 92ms/epoch - 700us/step\n",
      "Epoch 373/500\n",
      "131/131 - 0s - loss: 40099608.0000 - mae: 2261.0344 - 91ms/epoch - 693us/step\n",
      "Epoch 374/500\n",
      "131/131 - 0s - loss: 36223688.0000 - mae: 2330.4734 - 96ms/epoch - 731us/step\n",
      "Epoch 375/500\n",
      "131/131 - 0s - loss: 37018520.0000 - mae: 2409.8936 - 92ms/epoch - 700us/step\n",
      "Epoch 376/500\n",
      "131/131 - 0s - loss: 37488696.0000 - mae: 2402.5898 - 94ms/epoch - 716us/step\n",
      "Epoch 377/500\n",
      "131/131 - 0s - loss: 37359764.0000 - mae: 2317.8464 - 96ms/epoch - 731us/step\n",
      "Epoch 378/500\n",
      "131/131 - 0s - loss: 37520364.0000 - mae: 2298.8542 - 92ms/epoch - 704us/step\n",
      "Epoch 379/500\n",
      "131/131 - 0s - loss: 37843716.0000 - mae: 2398.9631 - 92ms/epoch - 701us/step\n",
      "Epoch 380/500\n",
      "131/131 - 0s - loss: 37017708.0000 - mae: 2336.8062 - 93ms/epoch - 708us/step\n",
      "Epoch 381/500\n",
      "131/131 - 0s - loss: 38535172.0000 - mae: 2379.3669 - 89ms/epoch - 678us/step\n",
      "Epoch 382/500\n",
      "131/131 - 0s - loss: 37628308.0000 - mae: 2294.7263 - 89ms/epoch - 678us/step\n",
      "Epoch 383/500\n",
      "131/131 - 0s - loss: 36523432.0000 - mae: 2436.3572 - 90ms/epoch - 685us/step\n",
      "Epoch 384/500\n",
      "131/131 - 0s - loss: 38380264.0000 - mae: 2381.4111 - 93ms/epoch - 708us/step\n",
      "Epoch 385/500\n",
      "131/131 - 0s - loss: 38654900.0000 - mae: 2366.6016 - 92ms/epoch - 700us/step\n",
      "Epoch 386/500\n",
      "131/131 - 0s - loss: 37825420.0000 - mae: 2366.3420 - 94ms/epoch - 720us/step\n",
      "Epoch 387/500\n",
      "131/131 - 0s - loss: 38517632.0000 - mae: 2343.7124 - 88ms/epoch - 670us/step\n",
      "Epoch 388/500\n",
      "131/131 - 0s - loss: 36954580.0000 - mae: 2446.9004 - 90ms/epoch - 684us/step\n",
      "Epoch 389/500\n",
      "131/131 - 0s - loss: 37397296.0000 - mae: 2359.1377 - 88ms/epoch - 670us/step\n",
      "Epoch 390/500\n",
      "131/131 - 0s - loss: 35894956.0000 - mae: 2412.7517 - 87ms/epoch - 662us/step\n",
      "Epoch 391/500\n",
      "131/131 - 0s - loss: 36866048.0000 - mae: 2376.4866 - 87ms/epoch - 662us/step\n",
      "Epoch 392/500\n",
      "131/131 - 0s - loss: 36938080.0000 - mae: 2316.1062 - 90ms/epoch - 685us/step\n",
      "Epoch 393/500\n",
      "131/131 - 0s - loss: 37226272.0000 - mae: 2305.5408 - 89ms/epoch - 678us/step\n",
      "Epoch 394/500\n",
      "131/131 - 0s - loss: 37400928.0000 - mae: 2385.6545 - 89ms/epoch - 678us/step\n",
      "Epoch 395/500\n",
      "131/131 - 0s - loss: 37369320.0000 - mae: 2346.7761 - 90ms/epoch - 685us/step\n",
      "Epoch 396/500\n",
      "131/131 - 0s - loss: 37396672.0000 - mae: 2405.6172 - 91ms/epoch - 692us/step\n",
      "Epoch 397/500\n",
      "131/131 - 0s - loss: 37077744.0000 - mae: 2354.5598 - 88ms/epoch - 670us/step\n",
      "Epoch 398/500\n",
      "131/131 - 0s - loss: 37496688.0000 - mae: 2342.3774 - 92ms/epoch - 700us/step\n",
      "Epoch 399/500\n",
      "131/131 - 0s - loss: 37601204.0000 - mae: 2453.6487 - 90ms/epoch - 685us/step\n",
      "Epoch 400/500\n",
      "131/131 - 0s - loss: 38061184.0000 - mae: 2361.2905 - 90ms/epoch - 685us/step\n",
      "Epoch 401/500\n",
      "131/131 - 0s - loss: 38602952.0000 - mae: 2301.1338 - 95ms/epoch - 723us/step\n",
      "Epoch 402/500\n",
      "131/131 - 0s - loss: 37863384.0000 - mae: 2345.0317 - 91ms/epoch - 693us/step\n",
      "Epoch 403/500\n",
      "131/131 - 0s - loss: 37050356.0000 - mae: 2301.8987 - 90ms/epoch - 685us/step\n",
      "Epoch 404/500\n",
      "131/131 - 0s - loss: 36910672.0000 - mae: 2295.0730 - 89ms/epoch - 678us/step\n",
      "Epoch 405/500\n",
      "131/131 - 0s - loss: 37365100.0000 - mae: 2350.5981 - 89ms/epoch - 678us/step\n",
      "Epoch 406/500\n",
      "131/131 - 0s - loss: 37119564.0000 - mae: 2344.1064 - 88ms/epoch - 670us/step\n",
      "Epoch 407/500\n",
      "131/131 - 0s - loss: 37967564.0000 - mae: 2373.6450 - 91ms/epoch - 693us/step\n",
      "Epoch 408/500\n",
      "131/131 - 0s - loss: 37168956.0000 - mae: 2416.6995 - 90ms/epoch - 685us/step\n",
      "Epoch 409/500\n",
      "131/131 - 0s - loss: 37680968.0000 - mae: 2400.2336 - 96ms/epoch - 731us/step\n",
      "Epoch 410/500\n",
      "131/131 - 0s - loss: 39874036.0000 - mae: 2386.7227 - 92ms/epoch - 701us/step\n",
      "Epoch 411/500\n",
      "131/131 - 0s - loss: 35721384.0000 - mae: 2259.7854 - 90ms/epoch - 685us/step\n",
      "Epoch 412/500\n",
      "131/131 - 0s - loss: 36776104.0000 - mae: 2311.4402 - 92ms/epoch - 700us/step\n",
      "Epoch 413/500\n",
      "131/131 - 0s - loss: 37036372.0000 - mae: 2371.0938 - 89ms/epoch - 678us/step\n",
      "Epoch 414/500\n",
      "131/131 - 0s - loss: 35324980.0000 - mae: 2309.7349 - 90ms/epoch - 685us/step\n",
      "Epoch 415/500\n",
      "131/131 - 0s - loss: 37488708.0000 - mae: 2334.6985 - 90ms/epoch - 685us/step\n",
      "Epoch 416/500\n",
      "131/131 - 0s - loss: 36443316.0000 - mae: 2386.0566 - 90ms/epoch - 685us/step\n",
      "Epoch 417/500\n",
      "131/131 - 0s - loss: 36481940.0000 - mae: 2341.6567 - 90ms/epoch - 685us/step\n",
      "Epoch 418/500\n",
      "131/131 - 0s - loss: 37676348.0000 - mae: 2307.3474 - 90ms/epoch - 685us/step\n",
      "Epoch 419/500\n",
      "131/131 - 0s - loss: 36269032.0000 - mae: 2314.1643 - 90ms/epoch - 685us/step\n",
      "Epoch 420/500\n",
      "131/131 - 0s - loss: 35531444.0000 - mae: 2279.3984 - 91ms/epoch - 693us/step\n",
      "Epoch 421/500\n",
      "131/131 - 0s - loss: 36377224.0000 - mae: 2372.6982 - 90ms/epoch - 685us/step\n",
      "Epoch 422/500\n",
      "131/131 - 0s - loss: 36259476.0000 - mae: 2388.1982 - 90ms/epoch - 685us/step\n",
      "Epoch 423/500\n",
      "131/131 - 0s - loss: 37132084.0000 - mae: 2326.8643 - 89ms/epoch - 678us/step\n",
      "Epoch 424/500\n",
      "131/131 - 0s - loss: 37244532.0000 - mae: 2336.1985 - 90ms/epoch - 685us/step\n",
      "Epoch 425/500\n",
      "131/131 - 0s - loss: 35391656.0000 - mae: 2272.3867 - 90ms/epoch - 685us/step\n",
      "Epoch 426/500\n",
      "131/131 - 0s - loss: 37152564.0000 - mae: 2344.4001 - 89ms/epoch - 678us/step\n",
      "Epoch 427/500\n",
      "131/131 - 0s - loss: 36569144.0000 - mae: 2278.1396 - 89ms/epoch - 678us/step\n",
      "Epoch 428/500\n",
      "131/131 - 0s - loss: 36899316.0000 - mae: 2323.8130 - 91ms/epoch - 693us/step\n",
      "Epoch 429/500\n",
      "131/131 - 0s - loss: 37325928.0000 - mae: 2314.6311 - 90ms/epoch - 685us/step\n",
      "Epoch 430/500\n",
      "131/131 - 0s - loss: 36614028.0000 - mae: 2256.1716 - 93ms/epoch - 708us/step\n",
      "Epoch 431/500\n",
      "131/131 - 0s - loss: 37087760.0000 - mae: 2371.4473 - 90ms/epoch - 685us/step\n",
      "Epoch 432/500\n",
      "131/131 - 0s - loss: 36685168.0000 - mae: 2279.0459 - 90ms/epoch - 685us/step\n",
      "Epoch 433/500\n",
      "131/131 - 0s - loss: 36381380.0000 - mae: 2276.9148 - 89ms/epoch - 678us/step\n",
      "Epoch 434/500\n",
      "131/131 - 0s - loss: 37511252.0000 - mae: 2270.5747 - 89ms/epoch - 678us/step\n",
      "Epoch 435/500\n",
      "131/131 - 0s - loss: 37220000.0000 - mae: 2358.7480 - 88ms/epoch - 670us/step\n",
      "Epoch 436/500\n",
      "131/131 - 0s - loss: 37600704.0000 - mae: 2355.8914 - 89ms/epoch - 677us/step\n",
      "Epoch 437/500\n",
      "131/131 - 0s - loss: 36670276.0000 - mae: 2316.8079 - 90ms/epoch - 685us/step\n",
      "Epoch 438/500\n",
      "131/131 - 0s - loss: 37773856.0000 - mae: 2457.7195 - 92ms/epoch - 700us/step\n",
      "Epoch 439/500\n",
      "131/131 - 0s - loss: 37725488.0000 - mae: 2348.7722 - 90ms/epoch - 685us/step\n",
      "Epoch 440/500\n",
      "131/131 - 0s - loss: 38594916.0000 - mae: 2360.3049 - 91ms/epoch - 693us/step\n",
      "Epoch 441/500\n",
      "131/131 - 0s - loss: 37713056.0000 - mae: 2392.2644 - 90ms/epoch - 685us/step\n",
      "Epoch 442/500\n",
      "131/131 - 0s - loss: 37880996.0000 - mae: 2352.7405 - 90ms/epoch - 685us/step\n",
      "Epoch 443/500\n",
      "131/131 - 0s - loss: 38244720.0000 - mae: 2400.5249 - 95ms/epoch - 723us/step\n",
      "Epoch 444/500\n",
      "131/131 - 0s - loss: 37854336.0000 - mae: 2361.3835 - 95ms/epoch - 723us/step\n",
      "Epoch 445/500\n",
      "131/131 - 0s - loss: 36849304.0000 - mae: 2409.8652 - 90ms/epoch - 685us/step\n",
      "Epoch 446/500\n",
      "131/131 - 0s - loss: 38550760.0000 - mae: 2433.1172 - 92ms/epoch - 703us/step\n",
      "Epoch 447/500\n",
      "131/131 - 0s - loss: 36812876.0000 - mae: 2368.2812 - 90ms/epoch - 685us/step\n",
      "Epoch 448/500\n",
      "131/131 - 0s - loss: 38984708.0000 - mae: 2342.2190 - 90ms/epoch - 685us/step\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 - 0s - loss: 36905724.0000 - mae: 2338.1851 - 90ms/epoch - 685us/step\n",
      "Epoch 450/500\n",
      "131/131 - 0s - loss: 36617456.0000 - mae: 2299.0286 - 89ms/epoch - 678us/step\n",
      "Epoch 451/500\n",
      "131/131 - 0s - loss: 37464584.0000 - mae: 2332.9363 - 89ms/epoch - 678us/step\n",
      "Epoch 452/500\n",
      "131/131 - 0s - loss: 37146408.0000 - mae: 2334.0417 - 91ms/epoch - 693us/step\n",
      "Epoch 453/500\n",
      "131/131 - 0s - loss: 38855976.0000 - mae: 2281.7390 - 90ms/epoch - 685us/step\n",
      "Epoch 454/500\n",
      "131/131 - 0s - loss: 36667900.0000 - mae: 2413.9070 - 93ms/epoch - 708us/step\n",
      "Epoch 455/500\n",
      "131/131 - 0s - loss: 37638084.0000 - mae: 2373.6309 - 90ms/epoch - 685us/step\n",
      "Epoch 456/500\n",
      "131/131 - 0s - loss: 36522516.0000 - mae: 2407.9114 - 90ms/epoch - 685us/step\n",
      "Epoch 457/500\n",
      "131/131 - 0s - loss: 36821332.0000 - mae: 2344.7773 - 89ms/epoch - 678us/step\n",
      "Epoch 458/500\n",
      "131/131 - 0s - loss: 38204028.0000 - mae: 2398.5383 - 92ms/epoch - 700us/step\n",
      "Epoch 459/500\n",
      "131/131 - 0s - loss: 38871876.0000 - mae: 2322.1282 - 92ms/epoch - 700us/step\n",
      "Epoch 460/500\n",
      "131/131 - 0s - loss: 37038512.0000 - mae: 2326.1699 - 90ms/epoch - 685us/step\n",
      "Epoch 461/500\n",
      "131/131 - 0s - loss: 37163704.0000 - mae: 2369.4919 - 92ms/epoch - 700us/step\n",
      "Epoch 462/500\n",
      "131/131 - 0s - loss: 37584164.0000 - mae: 2338.5120 - 91ms/epoch - 693us/step\n",
      "Epoch 463/500\n",
      "131/131 - 0s - loss: 37973064.0000 - mae: 2341.6042 - 90ms/epoch - 685us/step\n",
      "Epoch 464/500\n",
      "131/131 - 0s - loss: 37678600.0000 - mae: 2393.7751 - 91ms/epoch - 693us/step\n",
      "Epoch 465/500\n",
      "131/131 - 0s - loss: 36472528.0000 - mae: 2353.9712 - 92ms/epoch - 702us/step\n",
      "Epoch 466/500\n",
      "131/131 - 0s - loss: 37111892.0000 - mae: 2375.9629 - 91ms/epoch - 693us/step\n",
      "Epoch 467/500\n",
      "131/131 - 0s - loss: 37878836.0000 - mae: 2428.2595 - 94ms/epoch - 716us/step\n",
      "Epoch 468/500\n",
      "131/131 - 0s - loss: 36787896.0000 - mae: 2307.1104 - 89ms/epoch - 678us/step\n",
      "Epoch 469/500\n",
      "131/131 - 0s - loss: 36060124.0000 - mae: 2329.9211 - 90ms/epoch - 685us/step\n",
      "Epoch 470/500\n",
      "131/131 - 0s - loss: 35987592.0000 - mae: 2369.1904 - 91ms/epoch - 693us/step\n",
      "Epoch 471/500\n",
      "131/131 - 0s - loss: 37849048.0000 - mae: 2383.4653 - 92ms/epoch - 701us/step\n",
      "Epoch 472/500\n",
      "131/131 - 0s - loss: 36469776.0000 - mae: 2302.8455 - 90ms/epoch - 685us/step\n",
      "Epoch 473/500\n",
      "131/131 - 0s - loss: 37246768.0000 - mae: 2310.5247 - 89ms/epoch - 678us/step\n",
      "Epoch 474/500\n",
      "131/131 - 0s - loss: 36453484.0000 - mae: 2337.6755 - 90ms/epoch - 685us/step\n",
      "Epoch 475/500\n",
      "131/131 - 0s - loss: 36902668.0000 - mae: 2337.8672 - 89ms/epoch - 678us/step\n",
      "Epoch 476/500\n",
      "131/131 - 0s - loss: 36545976.0000 - mae: 2337.9084 - 90ms/epoch - 685us/step\n",
      "Epoch 477/500\n",
      "131/131 - 0s - loss: 36726932.0000 - mae: 2328.6008 - 89ms/epoch - 678us/step\n",
      "Epoch 478/500\n",
      "131/131 - 0s - loss: 37051992.0000 - mae: 2315.1472 - 89ms/epoch - 678us/step\n",
      "Epoch 479/500\n",
      "131/131 - 0s - loss: 36958068.0000 - mae: 2343.0205 - 90ms/epoch - 685us/step\n",
      "Epoch 480/500\n",
      "131/131 - 0s - loss: 36306276.0000 - mae: 2313.9221 - 90ms/epoch - 685us/step\n",
      "Epoch 481/500\n",
      "131/131 - 0s - loss: 37509172.0000 - mae: 2307.2156 - 92ms/epoch - 700us/step\n",
      "Epoch 482/500\n",
      "131/131 - 0s - loss: 35745372.0000 - mae: 2275.2295 - 91ms/epoch - 693us/step\n",
      "Epoch 483/500\n",
      "131/131 - 0s - loss: 37412516.0000 - mae: 2259.3523 - 91ms/epoch - 693us/step\n",
      "Epoch 484/500\n",
      "131/131 - 0s - loss: 36312336.0000 - mae: 2306.7439 - 90ms/epoch - 685us/step\n",
      "Epoch 485/500\n",
      "131/131 - 0s - loss: 37748180.0000 - mae: 2329.7585 - 91ms/epoch - 693us/step\n",
      "Epoch 486/500\n",
      "131/131 - 0s - loss: 36154032.0000 - mae: 2320.8984 - 89ms/epoch - 678us/step\n",
      "Epoch 487/500\n",
      "131/131 - 0s - loss: 36096308.0000 - mae: 2299.9053 - 90ms/epoch - 685us/step\n",
      "Epoch 488/500\n",
      "131/131 - 0s - loss: 35868748.0000 - mae: 2330.4431 - 93ms/epoch - 713us/step\n",
      "Epoch 489/500\n",
      "131/131 - 0s - loss: 36169840.0000 - mae: 2299.5425 - 91ms/epoch - 693us/step\n",
      "Epoch 490/500\n",
      "131/131 - 0s - loss: 36250080.0000 - mae: 2311.0786 - 90ms/epoch - 685us/step\n",
      "Epoch 491/500\n",
      "131/131 - 0s - loss: 37318308.0000 - mae: 2331.1926 - 89ms/epoch - 678us/step\n",
      "Epoch 492/500\n",
      "131/131 - 0s - loss: 38379580.0000 - mae: 2493.9570 - 90ms/epoch - 685us/step\n",
      "Epoch 493/500\n",
      "131/131 - 0s - loss: 36037388.0000 - mae: 2309.1206 - 90ms/epoch - 685us/step\n",
      "Epoch 494/500\n",
      "131/131 - 0s - loss: 36545048.0000 - mae: 2334.3464 - 90ms/epoch - 685us/step\n",
      "Epoch 495/500\n",
      "131/131 - 0s - loss: 38079224.0000 - mae: 2351.6047 - 90ms/epoch - 686us/step\n",
      "Epoch 496/500\n",
      "131/131 - 0s - loss: 37605224.0000 - mae: 2273.3572 - 90ms/epoch - 685us/step\n",
      "Epoch 497/500\n",
      "131/131 - 0s - loss: 36832864.0000 - mae: 2284.6497 - 90ms/epoch - 685us/step\n",
      "Epoch 498/500\n",
      "131/131 - 0s - loss: 38655724.0000 - mae: 2340.9617 - 92ms/epoch - 700us/step\n",
      "Epoch 499/500\n",
      "131/131 - 0s - loss: 38679360.0000 - mae: 2470.5173 - 90ms/epoch - 685us/step\n",
      "Epoch 500/500\n",
      "131/131 - 0s - loss: 37168828.0000 - mae: 2339.2192 - 90ms/epoch - 685us/step\n",
      "Best epoch: 314\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"mae\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_price, y_train, epochs=500, verbose=2)\n",
    "val_acc_per_epoch = fit_model.history['mae']\n",
    "best_epoch = val_acc_per_epoch.index(min(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 - 0s - loss: 1130997760.0000 - mae: 17124.2051 - 104ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_price,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 592us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2340.8865],\n",
       "       [41151.098 ],\n",
       "       [37933.75  ],\n",
       "       ...,\n",
       "       [72315.44  ],\n",
       "       [31617.916 ],\n",
       "       [ 2340.8865]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6421     25659.113525\n",
       "5681      1848.902344\n",
       "4678     93066.250000\n",
       "4834     37983.644531\n",
       "5652      6324.679688\n",
       "            ...      \n",
       "555      15159.113525\n",
       "5095    112293.828125\n",
       "3614    -47065.437500\n",
       "6611    -14617.916016\n",
       "1485    178666.113525\n",
       "Name: final_price, Length: 1777, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = y_test - y_pred[:, 0]\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21799.76953125"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(abs(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6421     28000.0\n",
       "5681     43000.0\n",
       "4678    131000.0\n",
       "4834     93000.0\n",
       "5652     56500.0\n",
       "          ...   \n",
       "555      17500.0\n",
       "5095    201000.0\n",
       "3614     25250.0\n",
       "6611     17000.0\n",
       "1485    181007.0\n",
       "Name: final_price, Length: 1777, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "44c84064d006807177f4d43dc2fb94f3cbd405eecc9890b8e78f4aa6080cdef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
